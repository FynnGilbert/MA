{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a53f08",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# ROADEF challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5197c623",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e86b1f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T19:50:37.974162Z",
     "start_time": "2023-05-16T19:50:37.951982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e3c3ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-15T13:45:57.550178Z",
     "start_time": "2023-04-15T13:45:57.542364Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict, namedtuple\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from gurobipy import *\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951e30b",
   "metadata": {},
   "source": [
    "### Following names are reserverd only for one usage\n",
    "\n",
    "tt: ID of truck as in the data, i.e. the original id\n",
    "\n",
    "ii: ID if item as in the data\n",
    "\n",
    "jjT: Counter index for truck\n",
    "\n",
    "jjI: Counter index for item\n",
    "\n",
    "\n",
    "### Naming conventions:\n",
    "\n",
    "Sets start with uppercase: I, IOrdered, T\n",
    "\n",
    "Parameter start with lowercase: num, il, tl\n",
    "\n",
    "### Parameters created by ourself follow the additional naming conventions:\n",
    "\n",
    "Try to use names that are self describing\n",
    "\n",
    "If multiple words describe the parameter, each word besides the first word start with an uppercase: numTrucks, numItems, vol2D, numItemsLoaded\n",
    "\n",
    "Dictionaries are indicated by an underscore followed by the key: num_Item, num_Truck\n",
    "\n",
    "If multiple keys, each key starts with an uppercase: num_TruckItem, vol2D_TruckGroup\n",
    "\n",
    "Nested dictionaries are seperated by an underscore, the order of the dictionaries is from left to right: num_Truck_Item -> First dict has tt as index, second dict has ii as index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1c74b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data objects\n",
    "\n",
    "Data objects for trucks, items and parameter (factors, time) storing the information of the instance, as well as defined or calculated parameters from us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc642c",
   "metadata": {},
   "source": [
    "## DataTrucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69dbea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTrucks(object):\n",
    "    def __init__(self):\n",
    "        # Sets\n",
    "        self.T = set()  # Trucks\n",
    "        self.U = set()  # Suppliers\n",
    "        self.K = set()  # Supplier docks\n",
    "        self.P = set()  # Plants\n",
    "        self.G = set()  # Plant docks\n",
    "        self.Gamma = set()  # Products\n",
    "        \n",
    "        self.TR = dict()  # Products that can be picked up by Truck t (subset of Y)\n",
    "        self.TU = dict()  # Suppliers that will be visited by Truck t (subset of U)\n",
    "        self.TK = dict()  # Supplier docks that will be visited by Truck t of supplier u (subset of K)\n",
    "        self.TG = dict()  # Plant docks that will be visited by Truck t of plant (subset of G)\n",
    "\n",
    "        # Parameter\n",
    "        self.tl = dict()  # Length\n",
    "        self.tw = dict()  # Width\n",
    "        self.th = dict()  # Height\n",
    "        self.tm = dict()  # Maximum loading Weight\n",
    "        self.tp = dict()  # Destination plant\n",
    "        self.tda = dict()  # Arrival time\n",
    "        self.tmm = dict()  # Maximum weight of a stack above the bottom item of product gamma, key: (t, gamma)\n",
    "        self.tf = dict()  # Multi stack\n",
    "        self.tem = dict()  # Maximum density of stacks\n",
    "        self.tc = dict()  # Cost\n",
    "        self.te = dict()  # Loading order for supplier u, key: (t, u)\n",
    "        self.tke = dict()  # Loading order for dock k of supplier u, key: (t, u, k)\n",
    "        self.tge = dict()  # Loading order for dock g of plant p, key: (t, p, g)\n",
    "        \n",
    "        # Parameter weights for truck (consist of tractor and trailer)\n",
    "        # Tractor\n",
    "        self.cm = dict()  # Weight\n",
    "        self.cjfm = dict()  # Distance between front and middle axis\n",
    "        self.cjfc = dict()  # Distance between front axle and center of gravity\n",
    "        self.cjfh = dict()  # Distance between front axle and harness\n",
    "        # Trailer\n",
    "        self.em = dict()  # Weight of empty trailer\n",
    "        self.ejhr = dict()  # Distance between harness and rear axis\n",
    "        self.ejcr = dict()  # Distance between center of gravity and rear axis\n",
    "        self.ejeh = dict()  # Distance between start of trailer and harness\n",
    "        self.emmr = dict()  # Max weight on rear axle\n",
    "        self.emmm = dict()  # Max weight on middle axle\n",
    "        \n",
    "        self.tcPseudo = dict()\n",
    "        self.tvol2D = dict()  # in m²\n",
    "        self.tvol3D = dict()  # in m³\n",
    "\n",
    "    def read_instances(self, path, dataP):\n",
    "        with open(path,'r') as fp:\n",
    "            for line in fp.readlines()[1:]:\n",
    "                new_line = line.rstrip().split(';')\n",
    "                tt = new_line[9]\n",
    "                uu = new_line[0]\n",
    "                kk = None if new_line[2] == \"\" else new_line[2]\n",
    "                pp = new_line[4]\n",
    "                gg = new_line[5]\n",
    "                gamma = new_line[7]\n",
    "                \n",
    "                self.T.add(tt)\n",
    "                self.U.add(uu)\n",
    "                self.K.add(kk)\n",
    "                self.P.add(pp)\n",
    "                self.G.add(gg)\n",
    "                self.Gamma.add(gamma)\n",
    "                \n",
    "                self.tp[tt] = pp\n",
    "                self.te[tt,uu] = int(new_line[1])\n",
    "                self.tke[tt,uu,kk] = 0 if kk == None else int(new_line[3])  # If Supplier Dock unknown, place at the start (index = 0)\n",
    "\n",
    "                if tt not in self.TU:\n",
    "                    self.TU[tt] = {uu}\n",
    "                else:\n",
    "                    self.TU[tt].add(uu)\n",
    "\n",
    "                if (tt,uu) not in self.TK:\n",
    "                    self.TK[tt,uu] = {kk}\n",
    "                else:\n",
    "                    self.TK[tt,uu].add(kk)   \n",
    "\n",
    "                if (tt,pp) not in self.TG:\n",
    "                    self.TG[tt,pp] = {gg}\n",
    "                else:\n",
    "                    self.TG[tt,pp].add(gg)     \n",
    "\n",
    "                self.tge[tt,pp,gg] = int(new_line[6])\n",
    "\n",
    "                if tt not in self.TR:\n",
    "                    self.TR[tt] = {gamma}\n",
    "                else:\n",
    "                    self.TR[tt].add(gamma)     \n",
    "\n",
    "                self.tda[tt] = string_to_date(new_line[8])\n",
    "                self.tl[tt], self.tw[tt], self.th[tt], self.tm[tt] = [int(xx) for xx in new_line[10:14]]\n",
    "                self.tf[tt], self.tem[tt], self.tmm[tt, gamma] = [int(xx) for xx in new_line[14:17]]   \n",
    "                self.tc[tt] = dataP.alphaT * int(new_line[17])\n",
    "                self.tcPseudo[tt] = dataP.alphaT * (1 + dataP.alphaE) * int(new_line[17])   \n",
    "                self.emmm[tt], self.emmr[tt] = [int(xx) for xx in new_line[18:20]]                \n",
    "                self.cm[tt] = float(new_line[20].replace(',','.'))\n",
    "                self.cjfm[tt], self.cjfc[tt], self.cjfh[tt] = [int(xx) for xx in new_line[21:24]]                \n",
    "                self.em[tt] = float(new_line[24].replace(',','.'))                \n",
    "                self.ejhr[tt], self.ejcr[tt], self.ejeh[tt] = [int(xx) for xx in new_line[25:]]\n",
    "\n",
    "                ##Helpers\n",
    "                self.tvol2D[tt] = (self.tl[tt] * self.tw[tt]) / 1_000_000\n",
    "                self.tvol3D[tt] = (self.tl[tt] * self.tw[tt] * self.th[tt]) / 1_000_000_000\n",
    "        \n",
    "        self.T = sorted(self.T)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a724c92",
   "metadata": {},
   "source": [
    "## DataItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2876e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataItems(object):\n",
    "    def __init__(self):\n",
    "        # Sets\n",
    "        self.I = set()  # Items\n",
    "        #self.Gamma = set()  # Products #TODOattention\n",
    "\n",
    "        # Parameter\n",
    "        self.il = dict()  # Length\n",
    "        self.iw = dict()  # Width\n",
    "        self.ih = dict()  # Height\n",
    "        self.ihn = dict()  # Nested height\n",
    "        self.im = dict()  # Weight\n",
    "        self.ist = dict()  # (is) Stackability code\n",
    "        self.ism = dict()  # Maximal stackability\n",
    "        self.ir = dict()  # Product type\n",
    "        self.io = dict()  # Orientation\n",
    "        self.ide = dict()  # Earliest arrival\n",
    "        self.idl = dict()  # Latest arrival\n",
    "        self.ip = dict()  # Destination plant\n",
    "        self.ig = dict()  # Destination dock\n",
    "        self.iu = dict()  # Supplier\n",
    "        self.ik = dict()  # Supplier dock\n",
    "        self.ic = dict()  # Inventory cost\n",
    "        \n",
    "        self.num_Item = dict()\n",
    "        self.ivol2D = dict()  # in m²\n",
    "        self.ivol3D = dict()  # in m³\n",
    "        self.ivol3DO = dict()  # in m³        \n",
    "\n",
    "    def read_instances(self, path):\n",
    "        with open(path,'r') as fp:\n",
    "            for line in fp.readlines()[1:]:\n",
    "                new_line = line.rstrip().split(';')\n",
    "\n",
    "                ii = new_line[0]\n",
    "                self.I.add(ii)\n",
    "                self.iu[ii], self.ik[ii], self.ip[ii], self.ig[ii], self.ir[ii] = new_line[1:6]\n",
    "                self.ik[ii] = None if self.ik[ii]=='' else self.ik[ii]\n",
    "                self.num_Item[ii], self.il[ii], self.iw[ii], self.ih[ii] = [int(xx) for xx in new_line[7:11]]\n",
    "                self.im[ii] = float(new_line[11].replace(',','.'))\n",
    "                self.ihn[ii] = int(new_line[12])\n",
    "                self.ist[ii], self.io[ii] = new_line[13:15]\n",
    "                self.ide[ii], self.idl[ii] = [string_to_date(xx) for xx in new_line[15:17]]\n",
    "                self.ic[ii], self.ism[ii] = [int(xx) for xx in new_line[17:]]                    \n",
    "\n",
    "                ##Helpers\n",
    "                self.ivol2D[ii] = (self.il[ii] * self.iw[ii]) / 1_000_000\n",
    "                self.ivol3D[ii] = (self.il[ii] * self.iw[ii] * (self.ih[ii] - self.ihn[ii])) / 1_000_000_000\n",
    "                self.ivol3DO[ii] = (self.il[ii] * self.iw[ii] * self.ih[ii]) / 1_000_000_000\n",
    "\n",
    "        self.I = sorted(self.I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0abb1e4",
   "metadata": {},
   "source": [
    "## DataParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de83eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataParameters(object): # Better name? Everything is a parameter\n",
    "    def __init__(self):\n",
    "        self.alphaT = 0  # Coefficient transportation cost\n",
    "        self.alphaI = 0  # Coefficient inventory cost\n",
    "        self.alphaE = 0  # Coefficient extra trucks\n",
    "        self.runtime = 0  # Runtime\n",
    "        \n",
    "        self.tROADEF = None\n",
    "        self.tInitial = None\n",
    "        self.tPacking = None\n",
    "\n",
    "        self.tSimplePacking = 2\n",
    "        \n",
    "        ###Parameter Packing\n",
    "        self.fStackRatio3DPP = 0.4\n",
    "        self.fTime2DSP = 0.5        \n",
    "        self.t2DSP = 1                     #Runtime Limit Stacking        \n",
    "        self.tTruckMin = 2\n",
    "        self.tTruckMax = 15\n",
    "        self.fHeuristicPacking = 0.90     #Wenn 2D Füllmenge größer als dieser Wert wird für das Packing die Heuristische Lösung akzeptiert          \n",
    "        \n",
    "        ###Parameter AP0 und AP1\n",
    "        self.fAPReductionWeight = 5       #Wenn Items innerhalb dieses Faktos identisch sind, werden sie für das AP0 aggergegiert\n",
    "        self.fAPReductionIC = 10          #Wenn Items innerhalb dieses Faktos identisch sind, werden sie für das AP0 aggergegiert\n",
    "        self.TighterGroups = True\n",
    "        self.fTrucklimitAP01 = 1.0\n",
    "        \n",
    "        ###Parameter um LNS zu steuern\n",
    "        self.ftAPLNS = 0.05               #Runtime die maximal für das APLNS verwendet werden darf        \n",
    "        self.fTFullthreshold = 1.0       #ALle Trucks mit einem größeren Füllgrad bekommen im LNS ein Upsilon        \n",
    "        self.fLNSReduction = 0.01         #Reduzierung der maximalen Füllmenge          \n",
    "        \n",
    "        \n",
    "        \n",
    "        ####Parameter wenn Runtime entscheidend ist -> bei unbegrenzten Limits Werte auf 1.0 bzw. False setzen\n",
    "        self.fAPLNSTrucklimits = 0.97         \n",
    "        self.ReductionInfeasibleTrucks = True\n",
    "        \n",
    "\n",
    "    def read_instances(self, path):\n",
    "        with open(path,'r') as fp:\n",
    "            fp.readline() ###Jump over header\n",
    "            self.alphaI, self.alphaT, self.alphaE, self.runtime = [float(xx) for xx in fp.readline().rstrip().replace(',','.').split(';')]\n",
    "        \n",
    "        self.tROADEF = 1.0 * self.runtime\n",
    "        \n",
    "        \n",
    "    \n",
    "    def set_Params(self, dataT, dataI, dataO, timePresolve):\n",
    "        \n",
    "        timeRemain = self.tROADEF - timePresolve\n",
    "        \n",
    "        \n",
    "        if len(dataT.T) <= 100:\n",
    "            self.fHeuristicPacking = 0.96\n",
    "            \n",
    "            self.fAPLNSTrucklimits = 1.0         \n",
    "            self.ReductionInfeasibleTrucks = False \n",
    "            \n",
    "            self.fLNSReduction = 0.0025         #Reduzierung der maximalen Füllmenge \n",
    "            self.tTruckMax = 30\n",
    "            \n",
    "\n",
    "        self.tInitial = 0.90 * timeRemain          \n",
    "\n",
    "        self.tAP0 = 0.2 * self.tInitial     #Runtime für Initial Solution - AP0 und AP1\n",
    "        self.tPacking  = 0.75 * timeRemain   #Runtime für Initial Solution - Packing\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873256e0",
   "metadata": {},
   "source": [
    "## DataOwnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b49c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataOwnData(object):\n",
    "    def __init__(self, T, I):\n",
    "        self.I_Truck = {tt:[] for tt in T}  # Set of Items that can be delivered by truck tt\n",
    "        self.T_Item = {ii: [] for ii in I}  # Set of trucks that can deliver item ii\n",
    "        \n",
    "        self.I_Item = dict() #Dictionary used for reduction represents all items which belong to head item\n",
    "\n",
    "        self.identicalTrucks = []\n",
    "        self.limit_Truck = dict()\n",
    "        self.limit_TruckVol = dict()\n",
    "        self.limit_TruckWeight = dict()\n",
    "        \n",
    "        self.ic_TruckItem = dict()\n",
    "        self.ivol3D_TruckItem = dict()  # in m³\n",
    "        self.numMax_TruckItem = dict()\n",
    "        # Groups\n",
    "        self.GI_Truck = {tt: [] for tt in T}  # Group 1\n",
    "        self.GIWidthGroup_Truck = {tt: [] for tt in T}  # Subgroups 2 \n",
    "        self.GIWidthPair_Truck = {tt: [] for tt in T}  # Subgroups 3\n",
    "        self.GIWidthOrientation_Truck = {tt: [] for tt in T}  # Subgroups 4\n",
    "        self.GIVol2DUp_Truck = {tt: [] for tt in T}  # Subgroups 5\n",
    "        self.GIWidthK_Truck = {tt: [] for tt in T}  # Subgroups 6\n",
    "        self.GIWidthKGroup_Truck = {tt: [] for tt in T}  # Subgroups 7  \n",
    "        self.GIsWidthGroups_Truck = {tt: [] for tt in T}  # Subgroups 8 \n",
    "        \n",
    "        \n",
    "        self.I_TruckGroupitems = dict()\n",
    "        \n",
    "        self.gi_TruckItem = dict()\n",
    "        self.gist_TruckGroupitems = dict()\n",
    "        self.gism_TruckGroupitems = dict()\n",
    "        self.giu_TruckGroupitems = dict()\n",
    "        self.gip_TruckGroupitems = dict()\n",
    "        self.gik_TruckGroupitems = dict()\n",
    "        self.gig_TruckGroupitems = dict()\n",
    "        self.gie_TruckGroupitems = dict()\n",
    "        self.gike_TruckGroupitems = dict()\n",
    "        self.gige_TruckGroupitems = dict()        \n",
    "        self.gih_TruckGroupitems = dict()\n",
    "        self.gihn_TruckGroupitems = dict()        \n",
    "        self.gio_TruckGroupitems = dict()        \n",
    "        self.givol2D_TruckGroupitems = dict()\n",
    "        self.gimm_TruckGroupitems = dict()\n",
    "        self.numItems_TruckGroupitems = dict() \n",
    "        \n",
    "        self.giMinWidth_Truck = dict()\n",
    "        \n",
    "        \n",
    "        self.gp_TruckGroupitems = dict()  # Destination plant\n",
    "        self.gg_TruckGroupitems = dict()  # Destination dock\n",
    "        self.gu_TruckGroupitems = dict()  # Supplier\n",
    "        self.gk_TruckGroupitems = dict()  # Supplier dock        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Nested to get easier access for group values\n",
    "        self.giwMin_Truck_Groupitems = {tt: {} for tt in T}\n",
    "        self.giwMax_Truck_Groupitems = {tt: {} for tt in T} \n",
    "        self.gilMin_Truck_Groupitems = {tt: {} for tt in T} \n",
    "        self.gilMax_Truck_Groupitems = {tt: {} for tt in T}         \n",
    "        \n",
    "        \n",
    "        # Parameters for AP\n",
    "        self.givol2D_TruckGroupitemsNum = dict()\n",
    "        self.gilWidthGroup_TruckGroupitemsNum = dict()\n",
    "        self.gilWidthPair_TruckGroupitemsNum = dict()\n",
    "        self.gilWidthOrientation_TruckGroupitemsNum = dict()\n",
    "        self.giVol2DUp_TruckGroupitemsNum = dict()\n",
    "        self.gilWidthK_TruckGroupitemsNum = dict()   \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.GIWidthSuperGroup_Truck = dict()\n",
    "        \n",
    "        \n",
    "        self.gilGroup_TruckGroupitemsNum = dict()\n",
    "        \n",
    "        # Parameter for linearization\n",
    "        self.giLvol2DM = dict()\n",
    "        self.giLvol2DB = dict()         \n",
    "        self.giLWidthGroupM = dict()\n",
    "        self.giLWidthGroupB = dict()\n",
    "        self.giLWidthPairM = dict()\n",
    "        self.giLWidthPairB = dict()\n",
    "        self.giLWidthOrientationM = dict()\n",
    "        self.giLWidthOrientationB = dict() \n",
    "        self.giLVol2DUpM = dict()\n",
    "        self.giLVol2DUpB = dict()    \n",
    "        self.giLWidthKM = dict()\n",
    "        self.giLWidthKB = dict()           \n",
    "        \n",
    "        # Offset for AP2\n",
    "        self.tOffset2D = dict()\n",
    "        self.tOffset2DUp = dict()\n",
    "        self.tOffset3D = dict()\n",
    "        self.tOffsetM = dict()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.Fix_Item_Truck = dict()\n",
    "        self.Fix_Pseudo = dict()\n",
    "        self.Fix_Trucks = dict()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ###Für Stacking AP\n",
    "        self.SI = set()\n",
    "        self.ST_Item = dict() #{ii: [] for ii in I}\n",
    "        self.Sc_TruckItem = dict()\n",
    "        self.Sm = dict()  # Weight\n",
    "        \n",
    "        self.Sh  = dict()\n",
    "        self.Shn = dict()\n",
    "        self.Sst  = dict()\n",
    "        self.Ssm = dict()        \n",
    "        \n",
    "        \n",
    "        self.Svol2D = dict()  # in m² \n",
    "        self.Svol2DUP = dict()  # in m² \n",
    "        self.Svol2DUPGreedy = dict()  # in m² \n",
    "        self.SI_Truck = {tt:[] for tt in T}\n",
    "        self.num_Stacks = dict()\n",
    "        \n",
    "        self.MaxAmountinStack_SI = dict()\n",
    "        self.MinAmountinStack_SI = dict()\n",
    "        \n",
    "        self.AmountinStack_SI = dict()\n",
    "        \n",
    "        \n",
    "        self.SlMax = dict()\n",
    "        self.SlMin = dict()\n",
    "        self.SwMax = dict()\n",
    "        self.SwMin = dict()\n",
    "        \n",
    "        \n",
    "        self.So = dict()\n",
    "        self.Sl = dict()\n",
    "        self.Sw = dict()  \n",
    "        \n",
    "        \n",
    "        self.SlAP = dict()\n",
    "        \n",
    "        self.SlAPGreedy = dict()\n",
    "        \n",
    "        \n",
    "        self.APStackSolution_Truck_Item = dict()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.FixPseudosTest = dict()\n",
    "        self.FixTruckTest = set()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #####Gruppierung der reduzierten Items für AP0\n",
    "        self.SGroup_Truck = {tt: [] for tt in T} #Alle Itemgruppen in Truck\n",
    "        self.Items_SGroupTruck = dict() #Alle Items die in einer Stacking Gruppe zusammengefasst werden können\n",
    "        self.SGroup_ItemsTruck = dict() \n",
    "        self.u_SGroupTruck = dict()#Supplier der Gruppe\n",
    "        self.k_SGroupTruck = dict() #Supplier Dock der Gruppe\n",
    "        self.p_SGroupTruck = dict()  # Destination plant\n",
    "        self.g_SGroupTruck = dict()  # Destination dock\n",
    "        self.h_SGroupTruck = dict()  # Height\n",
    "        self.hn_SGroupTruck = dict()  # Nested height\n",
    "        self.o_SGroupTruck = dict()  # Orientation\n",
    "        self.st_SGroupTruck = dict()  # (is) Stackability code\n",
    "        self.sm_SGroupTruck = dict()  # Maximal stackability\n",
    "        self.Maxl_SGroupTruck = {tt: {} for tt in T} #Max Länge\n",
    "        self.Maxw_SGroupTruck = {tt: {} for tt in T}#Max Weite\n",
    "        self.Minl_SGroupTruck = {tt: {} for tt in T} #Min Länge\n",
    "        self.Minw_SGroupTruck = {tt: {} for tt in T}#Min Weite\n",
    "        self.mm_SGroupTruck = dict() # Maximum weight of a stack above the bottom item of product gamma, key: (t, gamma) \n",
    "        self.vol2D_SGroupTruck = dict()\n",
    "        \n",
    "        \n",
    "        self.I_StackingItem = dict() #Wird benötigt um im AP1 wieder die originalen Items korrekt in der Startlösung zusammenzufügen\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.itemsPerStack_SGroupTruck = dict() #Nenner durch den im AP0 die Entscheidungsvariablen(iotas) geteilt werden\n",
    "        \n",
    "        \n",
    "        self.l_SuperGroup = {tt: {} for tt in T}#Länge der Super Group -> Parameter für Optimierung der neuen Entscheidungsvariablen\n",
    "        self.wStack_SuperGroup = {tt: {} for tt in T}\n",
    "        self.StacksinRow_SuperGroup = {tt: {} for tt in T}\n",
    "\n",
    "        self.SGroup_SuperGroupTruck = dict()\n",
    "        self.SuperGroup_SGroupTruck = dict()\n",
    "\n",
    "        self.SuperGroup_Truck = {tt: [] for tt in T} #Alle Supergroups in Truck\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.SI_SI = dict() #Weil Items nochmal in a un b Stacks aufgesplittet werden, muss Verbindung zwischen Items nachvollziehbar sein\n",
    "          \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e8897",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Solution objects\n",
    "\n",
    "Solution objects for items, stacks, trucks and a solution itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42036280",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item(object):\n",
    "    \"\"\"\n",
    "    Class describing the placement of an item in a truck.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.idx = None\n",
    "        self.code = None\n",
    "        self.xo = None\n",
    "        self.yo = None\n",
    "        self.zo = None\n",
    "        self.xe = None\n",
    "        self.ye = None\n",
    "        self.ze = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        text = f\"Item {self.idx} with code {self.code} is placed at position {self.xo},{self.yo},{self.zo} filling up to {self.xe},{self.ye},{self.ze}.\"\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def repr_Item(self):\n",
    "        text = f\"Item {self.idx} with code {self.code} is placed at position {self.xo},{self.yo},{self.zo} filling up to {self.xe},{self.ye},{self.ze}.\\n\"\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593dc6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack(object):\n",
    "    \"\"\"\n",
    "    Class describing the placement of a stack in a truck and contains the items of the stack.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.idx = None\n",
    "        self.oidx = None\n",
    "        self.code = None\n",
    "        self.xo = None\n",
    "        self.yo = None\n",
    "        self.zo = None\n",
    "        self.xe = None\n",
    "        self.ye = None\n",
    "        self.ze = None\n",
    "        \n",
    "        self.Items = []\n",
    "        \n",
    "    def __str__(self):\n",
    "        text = f\"Stack {self.idx}({self.oidx}) with code {self.code} is placed at position {self.xo},{self.yo},{self.zo} filling up to {self.xe},{self.ye},{self.ze}.\\n\"\n",
    "        text += f\"The Stack contains the following items: {', '.join([str(ii.idx) for ii in self.Items])}\"\n",
    "        return text\n",
    "    \n",
    "    def repr_Stack(self):\n",
    "        text = f\"Stack {self.idx}({self.oidx}) with code {self.code} is placed at position {self.xo},{self.yo},{self.zo} filling up to {self.xe},{self.ye},{self.ze}.\\n\"\n",
    "        text += \"-\" * 10 + \"\\n\"\n",
    "        for item in self.Items:\n",
    "            text += item.repr_Item()\n",
    "        text += \"+\" * 50 + \"\\n\"\n",
    "        return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "729e4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Truck(object):\n",
    "    \"\"\"\n",
    "    Class describing the packing of a truck and contains the stacks in the truck. Further are information\n",
    "    about the packad items and numbers as well as information about the utilization stored.\n",
    "    \"\"\"\n",
    "    def __init__(self, ttIdx, tt):\n",
    "        self.idx = ttIdx\n",
    "        self.oidx = tt\n",
    "        \n",
    "        self.I = set()\n",
    "        self.num_Item = defaultdict(int)\n",
    "        self.loadedLength = 0\n",
    "        self.loadedWeight = 0\n",
    "        self.loadedVolume = 0\n",
    "        self.emm = 0\n",
    "        self.emr = 0\n",
    "        \n",
    "        self.Stacks = []\n",
    "\n",
    "    def __str__(self):\n",
    "        text = \"/\\ \" * 50 + \"\\n\"\n",
    "        text += f\"Truck {self.idx} has a loaded length of {self.loadedLength} mm, a loaded weight of {self.loadedWeight} kg and a loaded volume of {self.loadedVolume} m³.\\nThe weight on the middle axle of the trailer (emm) is {self.emm} kg and the weight on the rear axle of the trailer (emr) is {self.emr} kg.\\n\"\n",
    "        text += f\"The truck has loaded the following stacks: {', '.join([str(ss.idx) for ss in self.Stacks])}\\n\"\n",
    "        for stack in self.Stacks:\n",
    "            text += \"+\" * 50 + \"\\n\"\n",
    "            text += stack.repr_Stack()\n",
    "        text += \"\\/ \" * 50 + \"\\n\"\n",
    "        return text\n",
    "    \n",
    "    def check_weight(self, dataT, dataI):\n",
    "      #  print(\"Weight Check for\", self.oidx)\n",
    "        \"\"\"\n",
    "        Function to check if the weight restrictions of the truck are violated. Necessary if not all items could pe packed into a truck.\n",
    "        \"\"\"        \n",
    "        \n",
    "        if not self.Stacks:\n",
    "            return True    \n",
    "        \n",
    "        self.I = set()\n",
    "        self.num_Item = defaultdict(int)\n",
    "        self.loadedLength = 0\n",
    "        self.loadedWeight = 0\n",
    "        self.loadedVolume = 0\n",
    "        self.emm = 0\n",
    "        self.emr = 0\n",
    "        \n",
    "        # Determin items in truck, loadedLength, loadedWeight and loadedVolume of truck\n",
    "        for stack in self.Stacks:\n",
    "            self.loadedVolume += (stack.xe - stack.xo) * (stack.ye - stack.yo) * stack.ze / 1_000_000_000\n",
    "\n",
    "            for item in stack.Items:\n",
    "                self.I.add(item.idx)\n",
    "                self.num_Item[item.idx] += 1\n",
    "                self.loadedWeight += dataI.im[item.idx]\n",
    "                \n",
    "                if item.xe > self.loadedLength:\n",
    "                    self.loadedLength = item.xe\n",
    "        if round(self.loadedWeight, 2) > dataT.tm[self.oidx]:\n",
    "         #   print(\"Hier ist ein riesen Problem\")\n",
    "         #   print(self)\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        eje, ejr, emh, emr, emm = dict(), dict(), dict(), dict(), dict()\n",
    "        \n",
    "        # Order suplliers truck visits\n",
    "        UOrdered = set([dataI.iu[ii] for ii in self.I])\n",
    "        UOrdered = sorted(UOrdered, key=lambda x: dataT.te[self.oidx, x])\n",
    "        \n",
    "        # Assign items to supplier\n",
    "        I_Supplier = {uu: [] for uu in  UOrdered}\n",
    "        for stack in self.Stacks:\n",
    "            for item in stack.Items:\n",
    "                I_Supplier[dataI.iu[item.idx]].append(item)\n",
    "    \n",
    "        # Calculate weight per supplier\n",
    "        tm = {uuu: max(1e-5, sum([dataI.im[item.idx] for uu in UOrdered[:pos+1] for item in I_Supplier[uu]])) for pos, uuu in enumerate(UOrdered)}\n",
    "        for pos, uuu in enumerate(UOrdered):\n",
    "            eje[uuu] = sum([(item.xo + (item.xe - item.xo) / 2) * dataI.im[item.idx] for uu in UOrdered[:pos+1] for item in I_Supplier[uu]]) / tm[uuu]\n",
    "            ejr[uuu] = dataT.ejeh[self.oidx] + dataT.ejhr[self.oidx] - eje[uuu]\n",
    "            emh[uuu] = (tm[uuu] * ejr[uuu] + dataT.em[self.oidx] * dataT.ejcr[self.oidx]) / dataT.ejhr[self.oidx]\n",
    "            emr[uuu] = tm[uuu] + dataT.em[self.oidx] - emh[uuu]\n",
    "            emm[uuu] = (dataT.cm[self.oidx] * dataT.cjfc[self.oidx] + emh[uuu] * dataT.cjfh[self.oidx]) / dataT.cjfm[self.oidx]\n",
    "        \n",
    "        # Constraint W2\n",
    "        for pos, uu in enumerate(UOrdered):\n",
    "            if not round(emm[uu],2) <= dataT.emmm[self.oidx] or not round(emr[uu], 2) <= dataT.emmr[self.oidx]:\n",
    "              #  print(f\"break because emm/emr does not match for truck {self.oidx} and supplier {uu}\")\n",
    "              #  print(\"emm\", emm)\n",
    "              #  print(\"emr\", emr)\n",
    "                return False\n",
    "        \n",
    "        self.emm = round(emm[UOrdered[-1]], 2)\n",
    "        self.emr = round(emr[UOrdered[-1]], 2)\n",
    "     #   print(\"Truck feasible\", self.emm, self.emr)\n",
    "     #   print(\"emm\", emm)\n",
    "     #   print(\"emr\", emr)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3991b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Trucks = dict()\n",
    "        self.TrucksWorseAP = set()\n",
    "        self.tcInventory = {} # For a truck the inventory costs\n",
    "        self.tcTransport = {} # For a truck the transportation costs (original + pseudo)\n",
    "        self.info = {\"Obj\": None, \"cT\": 0, \"cI\": 0, \"rt\": None, \"T#\": 0, \"T#O\": 0, \"T#P\": 0}\n",
    "        self.perfectPacking = True\n",
    "    #    self.extraTrucks_Truck = dict()\n",
    "        self.numWeightViolationsAP1 = 0\n",
    "        self.numWeightViolationsAP2 = 0\n",
    "        self.numPseudoTrucksPacking2 = 0\n",
    "        \n",
    "    def print_sol(self):\n",
    "        print(f\"Objective;{self.info['Obj']}\")\n",
    "        print(f\"Transportation cost;{self.info['cT']}\")\n",
    "        print(f\"Inventory cost;{self.info['cI']}\")\n",
    "        print(f\"Runtime;{self.info['rt']}\")\n",
    "\n",
    "    \n",
    "            \n",
    "    def revalue(self, dataT, dataO, usedTime):\n",
    "        self.info['rt'] = usedTime\n",
    "        self.info['Obj'] = 0\n",
    "        self.info['cT'] = 0\n",
    "        self.info['cI'] = 0\n",
    "        self.tcInventory = {}\n",
    "        self.tcTransport = {}\n",
    "        \n",
    "        for tt, Trucks in self.Trucks.items():\n",
    "            self.tcInventory[tt] = 0\n",
    "            self.tcTransport[tt] = 0\n",
    "            \n",
    "            for pos, truck in enumerate(Trucks):\n",
    "                if truck.Stacks:\n",
    "                    if pos == 0:\n",
    "                        self.tcTransport[tt] += dataT.tc[tt]                       \n",
    "                    else:\n",
    "                        self.tcTransport[tt] += dataT.tcPseudo[tt]\n",
    "                        \n",
    "                    for stack in truck.Stacks:\n",
    "                        for item in stack.Items:\n",
    "                            self.tcInventory[tt] += dataO.ic_TruckItem[tt, item.idx]\n",
    "                \n",
    "\n",
    "            self.info['Obj'] += self.tcTransport[tt] + self.tcInventory[tt]\n",
    "            self.info['cT'] += self.tcTransport[tt]\n",
    "            self.info['cI'] += self.tcInventory[tt]\n",
    "            \n",
    "    \n",
    "    def export(self, pathOI, pathOS, pathOT):\n",
    "        pos = pathOI.rfind('/')\n",
    "        # Create folder in path if it does not exist\n",
    "        Path(pathOI[:pos]).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        with open(pathOT, 'w') as fp:\n",
    "            fp.write(\"Id truck;Loaded length;Weight of loaded items;Volume of loaded items;emm;emr\\n\")\n",
    "            \n",
    "            for tt, trucks in self.Trucks.items():\n",
    "                for truck in trucks:\n",
    "                    fp.write(f\"{truck.idx};{int(round(truck.loadedLength,0))};{round(truck.loadedWeight, 3)};{round(truck.loadedVolume, 3)};{round(truck.emm, 3)};{round(truck.emr, 3)}\\n\".replace(\".\", \",\"))\n",
    "\n",
    "        with open(pathOS, 'w') as fp:\n",
    "            fp.write(\"Id truck;Id stack;Stack code;X origin;Y origin;Z origin;X extremity;Y extremity;Z extremity\\n\")\n",
    "\n",
    "            for tt, trucks in self.Trucks.items():\n",
    "                for truck in trucks:\n",
    "                    for stack in truck.Stacks:\n",
    "                        fp.write(f\"{truck.idx};{stack.idx};{stack.code};{int(round(stack.xo, 0))};{int(round(stack.yo, 0))};{int(round(stack.zo, 0))};{int(round(stack.xe, 0))};{int(round(stack.ye, 0))};{int(round(stack.ze, 0))}\\n\".replace(\".\", \",\"))\n",
    "\n",
    "        with open(pathOI, 'w') as fp:\n",
    "            fp.write(\"Item ident;Id truck;Id stack;Item code;X origin;Y origin;Z origin;X extremity;Y extremity;Z extremity\\n\")\n",
    "\n",
    "            for tt, trucks in self.Trucks.items():\n",
    "                for truck in trucks:\n",
    "                    for stack in truck.Stacks:\n",
    "                        for item in stack.Items:\n",
    "                            fp.write(f\"{item.idx};{truck.idx};{stack.idx};{item.code};{int(round(item.xo, 0))};{int(round(item.yo, 0))};{int(round(item.zo, 0))};{int(round(item.xe, 0))};{int(round(item.ye, 0))};{int(round(item.ze, 0))}\\n\".replace(\".\", \",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84e760",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "598c8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_stack(idx, tidx=None):\n",
    "    # The stack code ranges from A to Z, then from AA to AZ, then from BA to BZ etc.\n",
    "    # Items in a Stack are then numbered from bottom to top, e.g. for Stack A: bottom A1 -> A2 -> A3 top.      \n",
    "    func_code = lambda x: chr(ord('@')+x)\n",
    "    if idx <= 26:\n",
    "        return func_code(idx)\n",
    "    else:\n",
    "        first = int(math.floor(idx / 26))\n",
    "        second = idx % 26\n",
    "        if second == 0:\n",
    "            first = int(math.floor((idx-1) / 26))\n",
    "            second = 26\n",
    "        return func_code(first) + func_code(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e986799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_date(arrival_time):\n",
    "    date_time_obj = datetime.strptime(arrival_time, '%Y%m%d%H%M')\n",
    "    return date_time_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcda4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(value):\n",
    "    # Function to format a time in seconds to hh:mm:ss.ms\n",
    "    frac, value = math.modf(value)\n",
    "    value_mf = f\"{frac:.3f}\"\n",
    "    return time.strftime('%H:%M:%S', time.gmtime(value)) + value_mf[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfc525",
   "metadata": {},
   "source": [
    "# Presolve\n",
    "\n",
    "Generate additional information that are useful to reduce the computational time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5672c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "523abe62",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def presolve_one(dataT, dataI, dataP, dataO):\n",
    "# Truck Item Assignment\n",
    "\n",
    "    minTruckWidth = min(dataT.tw.values())###### TODOremoveAPOPT\n",
    "    \n",
    "    # Presolve items, assign \n",
    "    for ii in dataI.I:  \n",
    "        # Fix orientation if one side of item is longer than truck width\n",
    "        if dataI.io[ii] == \"none\":\n",
    "            if dataI.il[ii] > minTruckWidth or dataI.iw[ii] > minTruckWidth:\n",
    "                if dataI.il[ii] > dataI.iw[ii]:\n",
    "                    dataI.io[ii] = \"lengthwise\"\n",
    "                else:\n",
    "                    dataI.io[ii] = \"widthwise\"\n",
    "        \n",
    "        # Create truck/item assignment\n",
    "        for tt in dataT.T:\n",
    "            # 1. If Check: Product Type -> Darf der Truck den Product Typ aufnehmen, Check TR\n",
    "            if dataI.ir[ii] in dataT.TR[tt]:\n",
    "                # 2. If Check: Supplier Code und Supplier Dock -> Fährt der Truck den Startpunkt an?, Check TU, TK\n",
    "                if dataI.iu[ii] in dataT.TU[tt] and dataI.ik[ii] in dataT.TK[tt,dataI.iu[ii]]:\n",
    "                    # 3. If Check: Plant Code und Plant Dock -> Fährt der Truck den Endpunkt an?,Check TP, TG\n",
    "                    if dataI.ip[ii] == dataT.tp[tt] and dataI.ig[ii] in dataT.TG[tt,dataI.ip[ii]]:\n",
    "                        # 4. If Check: Truck muss im Zeitfenster ankommen -> ide, idl, tda\n",
    "                        if dataI.ide[ii] <= dataT.tda[tt] <= dataI.idl[ii]:\n",
    "                            # Ordne Items zu Trucks\n",
    "                            dataO.I_Truck[tt].append(ii)\n",
    "                            dataO.T_Item[ii].append(tt)\n",
    "                            dataO.ic_TruckItem[tt, ii] = dataP.alphaI * dataI.ic[ii] * (dataI.idl[ii].replace(hour=0, minute=0)-dataT.tda[tt].replace(hour=0, minute=0)).days\n",
    "                            \n",
    "                            # Determin 3D volume for item based on max stackability\n",
    "                            if dataI.ism[ii] == 1:\n",
    "                                dataO.ivol3D_TruckItem[tt, ii] = dataI.ivol2D[ii] * (dataT.th[tt] / 1_000)\n",
    "                            else:\n",
    "                                dataO.ivol3D_TruckItem[tt, ii] = dataI.ivol3D[ii]\n",
    "    \n",
    "    for tt1, tt2 in itertools.combinations(dataT.T, 2):\n",
    "        if dataT.TR[tt1] == dataT.TR[tt2]:  # Check product Type identical\n",
    "            if dataT.TU[tt1] == dataT.TU[tt2]:  # Check supplier identical\n",
    "                # Check Supplier/Dock #TODOcodeReduction\n",
    "                docks_same = True\n",
    "                for uu in dataT.TU[tt1]:\n",
    "                    if dataT.TK[tt1, uu] != dataT.TK[tt2, uu]:\n",
    "                        docks_same = False\n",
    "                        break\n",
    "\n",
    "                # Break if not the same\n",
    "                if not docks_same:\n",
    "                    continue\n",
    "    \n",
    "                if dataT.tp[tt1] == dataT.tp[tt2]:  # Check plant identical\n",
    "                    if dataT.TG[tt1, dataT.tp[tt1]] == dataT.TG[tt2, dataT.tp[tt2]]: # Check plant dock identical\n",
    "                        if dataT.tda[tt1] == dataT.tda[tt2]: # Check Arrival time identical   \n",
    "                            dataO.identicalTrucks.append((tt1, tt2))\n",
    "\n",
    "    dataO.identicalTrucks = [sorted(trucks, key=lambda x: dataT.tc[x]) for trucks in dataO.identicalTrucks]\n",
    "\n",
    "    for ii in dataI.I:\n",
    "        dataO.T_Item[ii] = sorted(dataO.T_Item[ii], key=lambda x: dataO.ic_TruckItem[x, ii])\n",
    "        unusedTrucks = []\n",
    "        tcPseudoMin = min([dataT.tcPseudo[tt] for tt in dataO.T_Item[ii]])\n",
    "        for tt in dataO.T_Item[ii]:\n",
    "            if dataO.ic_TruckItem[tt,ii]  >=  tcPseudoMin:\n",
    "                unusedTrucks.append(tt)\n",
    "        unusedTrucks = unusedTrucks[1:] if len(unusedTrucks) == len(dataO.T_Item[ii]) else unusedTrucks\n",
    "        for tt in unusedTrucks:\n",
    "            dataO.I_Truck[tt].remove(ii)\n",
    "            dataO.T_Item[ii].remove(tt) \n",
    "        for tt in dataO.T_Item[ii]:\n",
    "            dataO.numMax_TruckItem[tt,ii] = int(math.floor(tcPseudoMin/dataO.ic_TruckItem[tt,ii])) if dataO.ic_TruckItem[tt,ii] > 0 else dataI.num_Item[ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa0460c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7841be48",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def presolve_two(dataT, dataI, dataP, dataO):\n",
    "    # Building group of items to improve runtime of AP and cut off infeasible solutions\n",
    "    # 1. GI_Truck: Group, whose items have the same stackability code, max stackability , supplier order, supplier dock order, plant dock, height, nested heigt and orientation\n",
    "    # All the following groups are subgroups of GI_Truck\n",
    "    # 2. GIWidthGroup_Truck: Group, whose groupitems cannot be placed beside themself or any other item of the group without violating the truck width. Takes the minimum width of groupitems into consideration. Items must be placed behind each other.\n",
    "    # 3. GIWidthPair_Truck: Group, whose pair of groupitems cannot be placed beside each other without violating the truck width. Takes the minimum width of groupitems into consideration. Items must be placed behind each other (groupitems itself can be placed beside each other!).\n",
    "\n",
    "    # 1. GI_Truck\n",
    "    for ii, T in dataO.T_Item.items():\n",
    "        for tt in T:\n",
    "            newGroup = True\n",
    "            if dataO.GI_Truck[tt]:\n",
    "                for gi in dataO.GI_Truck[tt]:\n",
    "                    if dataI.ist[ii] == dataO.gist_TruckGroupitems[tt, gi] and dataI.ism[ii] == dataO.gism_TruckGroupitems[tt, gi]: #Stackability, Max Stackability\n",
    "                        ###Supplier, Supplier Dock, Plant, Plant Dock\n",
    "                        if dataI.iu[ii] == dataO.gu_TruckGroupitems[tt, gi] and dataI.ik[ii] == dataO.gk_TruckGroupitems[tt, gi] and dataI.ip[ii] == dataO.gp_TruckGroupitems[tt, gi] and dataI.ig[ii] == dataO.gg_TruckGroupitems[tt, gi]:\n",
    "                                \n",
    "                            if dataP.TighterGroups == True:\n",
    "                                if math.floor((dataT.th[tt] - dataI.ihn[ii]) / (dataI.ih[ii] - dataI.ihn[ii])) == math.floor((dataT.th[tt] - dataO.gihn_TruckGroupitems[tt, gi]) / (dataO.gih_TruckGroupitems[tt, gi] - dataO.gihn_TruckGroupitems[tt, gi])) and dataI.io[ii] == dataO.gio_TruckGroupitems[tt, gi]: \n",
    "\n",
    "                                    dataO.I_TruckGroupitems[tt, gi].append(ii)\n",
    "                                    dataO.gi_TruckItem[tt, ii] = gi\n",
    "                                    dataO.numItems_TruckGroupitems[tt, gi] += dataI.num_Item[ii]\n",
    "                                    \n",
    "                                    if dataI.ih[ii] > dataO.gih_TruckGroupitems[tt, gi]:\n",
    "                                        dataO.gih_TruckGroupitems[tt, gi] = dataI.ih[ii]\n",
    "                                    if dataI.ihn[ii] < dataO.gihn_TruckGroupitems[tt, gi]:\n",
    "                                        dataO.gihn_TruckGroupitems[tt, gi] = dataI.ihn[ii]                                     \n",
    "                                    \n",
    "                                    if dataO.gimm_TruckGroupitems[tt, gi] > dataT.tmm[tt, dataI.ir[ii]]:\n",
    "                                        dataO.gimm_TruckGroupitems[tt, gi] = dataT.tmm[tt, dataI.ir[ii]]\n",
    "                                    newGroup = False\n",
    "                                    break\n",
    "    \n",
    "                            else:                              \n",
    "                                if dataI.io[ii] == dataO.gio_TruckGroupitems[tt, gi]: #Orientation\n",
    "                                    dataO.I_TruckGroupitems[tt, gi].append(ii)\n",
    "                                    dataO.gi_TruckItem[tt, ii] = gi\n",
    "                                    dataO.numItems_TruckGroupitems[tt, gi] += dataI.num_Item[ii]\n",
    "\n",
    "                                    if dataI.ih[ii] < dataO.gih_TruckGroupitems[tt, gi]:\n",
    "                                        dataO.gih_TruckGroupitems[tt, gi] = dataI.ih[ii]\n",
    "                                    if dataI.ihn[ii] > dataO.gihn_TruckGroupitems[tt, gi]:\n",
    "                                        dataO.gihn_TruckGroupitems[tt, gi] = dataI.ihn[ii]                                    \n",
    "\n",
    "                                    if dataO.gimm_TruckGroupitems[tt, gi] > dataT.tmm[tt, dataI.ir[ii]]:\n",
    "                                        dataO.gimm_TruckGroupitems[tt, gi] = dataT.tmm[tt, dataI.ir[ii]]\n",
    "                                    newGroup = False\n",
    "                                    break                                \n",
    "                                \n",
    "\n",
    "            if newGroup:\n",
    "                gi = len(dataO.GI_Truck[tt]) + 1\n",
    "                dataO.GI_Truck[tt].append(gi)\n",
    "                dataO.I_TruckGroupitems[tt, gi] = [ii]\n",
    "                dataO.gi_TruckItem[tt, ii] = gi\n",
    "                \n",
    "                dataO.gist_TruckGroupitems[tt, gi] = dataI.ist[ii]\n",
    "                dataO.gism_TruckGroupitems[tt, gi] = dataI.ism[ii]\n",
    "\n",
    "                dataO.gu_TruckGroupitems[tt, gi] = dataI.iu[ii]  # Supplier\n",
    "                dataO.gk_TruckGroupitems[tt, gi] = dataI.ik[ii]  # Supplier dock                  \n",
    "                dataO.gp_TruckGroupitems[tt, gi] = dataI.ip[ii]  # Destination plant\n",
    "                dataO.gg_TruckGroupitems[tt, gi] = dataI.ig[ii] # Destination dock\n",
    "                \n",
    "                dataO.gih_TruckGroupitems[tt, gi] = dataI.ih[ii] \n",
    "                dataO.gihn_TruckGroupitems[tt, gi] = dataI.ihn[ii]\n",
    "                dataO.gio_TruckGroupitems[tt, gi] = dataI.io[ii]\n",
    "                \n",
    "                if dataI.io[ii] == \"none\":\n",
    "                    dataO.giwMin_Truck_Groupitems[tt][gi] = dataO.gilMin_Truck_Groupitems[tt][gi] = min(dataI.il[ii], dataI.iw[ii])\n",
    "                    dataO.giwMax_Truck_Groupitems[tt][gi] = dataO.gilMax_Truck_Groupitems[tt][gi] = max(dataI.il[ii], dataI.iw[ii])\n",
    "                elif dataI.io[ii] == \"widthwise\":\n",
    "                    dataO.giwMin_Truck_Groupitems[tt][gi] = dataO.giwMax_Truck_Groupitems[tt][gi] = dataI.il[ii]\n",
    "                    dataO.gilMin_Truck_Groupitems[tt][gi] = dataO.gilMax_Truck_Groupitems[tt][gi] = dataI.iw[ii]\n",
    "                else:\n",
    "                    dataO.giwMin_Truck_Groupitems[tt][gi] = dataO.giwMax_Truck_Groupitems[tt][gi]  = dataI.iw[ii]\n",
    "                    dataO.gilMin_Truck_Groupitems[tt][gi] = dataO.gilMax_Truck_Groupitems[tt][gi] = dataI.il[ii]                                \n",
    "           \n",
    "                dataO.givol2D_TruckGroupitems[tt, gi] = dataI.ivol2D[ii]\n",
    "                dataO.gimm_TruckGroupitems[tt, gi] = dataT.tmm[tt, dataI.ir[ii]]\n",
    "                dataO.numItems_TruckGroupitems[tt, gi] = dataI.num_Item[ii] \n",
    "                                \n",
    "    # Create subsets                \n",
    "    for tt, I in dataO.I_Truck.items():\n",
    "        if I:\n",
    "            # 2. GIWidthGroup_Truck\n",
    "            WidthMinGroupitems = set(dataO.giwMin_Truck_Groupitems[tt].values())\n",
    "            WidthMinConsidered = set([width for width in WidthMinGroupitems if dataT.tw[tt] / width < 2])\n",
    "            dataO.GIWidthGroup_Truck[tt] = [gi for gi in dataO.GI_Truck[tt] if dataO.giwMin_Truck_Groupitems[tt][gi] in WidthMinConsidered] #Betrifft Itemgruppen, in denen nur ein Stack pro Row stehen kann.\n",
    "                                                                                                                                            #Aufsummierte Länge über alle Itemgruppen in Gruppe muss <= Trucklänge sein\n",
    "\n",
    "            # 3. GIWidthPair_Truck\n",
    "            dataO.GIWidthPair_Truck[tt] = [(gi1, gi2) for gi1, gi2 in itertools.product(dataO.GIWidthGroup_Truck[tt], dataO.GI_Truck[tt])  #Hier vorher itertools.product\n",
    "                                           if gi1 != gi2 and dataO.giwMin_Truck_Groupitems[tt][gi1] + dataO.giwMin_Truck_Groupitems[tt][gi2] > dataT.tw[tt]] #2er Itemgruppen Konstelleationen, die nicht hintereinander stehen können\n",
    "                                                                                                                                                             #Aufsummierte Länge über alle 2er Konstellation in Gruppe muss <= Trucklänge sein\n",
    "\n",
    "            # 4. GIWidthSuperGroup_Truck[tt] Supergroups werden für Längenconstraint erstellt\n",
    "            dataO.GIWidthSuperGroup_Truck[tt] = []\n",
    "            for gi in dataO.GI_Truck[tt]:\n",
    "                if dataO.giwMin_Truck_Groupitems[tt][gi] not in WidthMinConsidered:\n",
    "                    NewSuperGroup = [gi]\n",
    "                    for gi2 in dataO.GI_Truck[tt]:\n",
    "                        if dataO.giwMin_Truck_Groupitems[tt][gi2] in WidthMinConsidered:\n",
    "                            NewSuperGroup.append(gi2)\n",
    "                    dataO.GIWidthSuperGroup_Truck[tt].append(NewSuperGroup)\n",
    "                            \n",
    "                \n",
    "            \n",
    "                \n",
    "            dataO.giMinWidth_Truck[tt] = min(WidthMinGroupitems)\n",
    "\n",
    "            \n",
    "        \n",
    "    # Create parameters for subsets\n",
    "    for tt, I in dataO.I_Truck.items():\n",
    "        if I: \n",
    "            # Determine for each groupitems how many items can be stacked together on the following cases\n",
    "            # Case: 0 max stackability, 1 based on height of items, 2 based on truck density, 3 based on total weight on bottom item        \n",
    "            itemsPerStack = {}\n",
    "            \n",
    "            for gi in dataO.GI_Truck[tt]:\n",
    "                case0 = dataO.gism_TruckGroupitems[tt, gi]\n",
    "                case1 = math.floor((dataT.th[tt] - dataO.gihn_TruckGroupitems[tt, gi]) / (dataO.gih_TruckGroupitems[tt, gi] - dataO.gihn_TruckGroupitems[tt, gi]))\n",
    "                case2 = math.floor(dataT.tem[tt] * dataO.givol2D_TruckGroupitems[tt, gi] / min([dataI.im[iii] for iii in dataO.I_TruckGroupitems[tt, gi]]))\n",
    "                case3 = math.floor(1 + dataO.gimm_TruckGroupitems[tt, gi] / min([dataI.im[iii] for iii in dataO.I_TruckGroupitems[tt, gi]]))\n",
    "                itemsPerStack[gi] = min(case0, case1, case2, case3)\n",
    "\n",
    "                #OPTIMALE PARAMETER: givol2D_TruckGroupitemsNum und gilGroup_TruckGroupitemsNum\n",
    "                for jj in range(dataO.numItems_TruckGroupitems[tt, gi] + 1):\n",
    "                    dataO.givol2D_TruckGroupitemsNum[tt, gi, jj] = math.ceil(jj / itemsPerStack[gi]) * dataO.givol2D_TruckGroupitems[tt, gi]\n",
    "                    \n",
    "                #Einheitlicher: Ein Längenparameter für alle Gruppen: Bestimmt die minimale Länge pro Item pro Stück in Abhängigkeit von ItemsperStack und StackperRow -> Dürfte keine Optimalität abschneiden\n",
    "                # Determine maximum Rows for all possible orientations\n",
    "                if dataO.gio_TruckGroupitems[tt, gi] == \"none\":\n",
    "                    maxRows = np.floor(dataT.tw[tt] / np.array([dataO.giwMin_Truck_Groupitems[tt][gi], dataO.giwMax_Truck_Groupitems[tt][gi]]))\n",
    "                    length = [dataO.gilMax_Truck_Groupitems[tt][gi], dataO.gilMin_Truck_Groupitems[tt][gi]]  \n",
    "                else:             \n",
    "                    maxRows = np.floor(dataT.tw[tt] / np.array([dataO.giwMax_Truck_Groupitems[tt][gi]]))\n",
    "                    length = [dataO.gilMax_Truck_Groupitems[tt][gi]]\n",
    "                # Calculate the minimum length for all numbers of stacks\n",
    "                length_GroupitemsNumstacks = dict()   \n",
    "                for ss in range(math.ceil(dataO.numItems_TruckGroupitems[tt, gi] / itemsPerStack[gi])+1):\n",
    "                    columns = np.ceil(ss / maxRows) \n",
    "                    length_GroupitemsNumstacks[(gi, ss)] = np.min(length * columns)                  \n",
    "                for jj in range(dataO.numItems_TruckGroupitems[tt, gi] + 1):\n",
    "                    dataO.gilGroup_TruckGroupitemsNum[tt, gi, jj] = length_GroupitemsNumstacks[(gi, math.ceil(jj / itemsPerStack[gi]))] \n",
    "                \n",
    "                #HEURISTISCHE PARAMETER: \n",
    "                if dataO.giwMin_Truck_Groupitems[tt][gi] + dataO.giMinWidth_Truck[tt] > dataT.tw[tt]:\n",
    "                    for jj in range(dataO.numItems_TruckGroupitems[tt, gi] + 1):  \n",
    "                        dataO.giVol2DUp_TruckGroupitemsNum[tt, gi, jj] = (math.ceil(jj / itemsPerStack[gi]) * dataT.tw[tt] * dataO.gilMin_Truck_Groupitems[tt][gi]) / 1_000_000     \n",
    "                else:\n",
    "                    for jj in range(dataO.numItems_TruckGroupitems[tt, gi] + 1):  \n",
    "                        dataO.giVol2DUp_TruckGroupitemsNum[tt, gi, jj] = dataO.givol2D_TruckGroupitemsNum[tt, gi, jj]\n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d88f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackBuildingAP(dataT, dataI, dataP, dataO, dataOR):\n",
    "    ###Ziel: Jedes einzelne Item in advance in Stacks zerlegen und später für jeden generierten Stack nur noch eine binäre Variable pro Stack zu haben\n",
    "\n",
    "    for ii in dataI.I:\n",
    "        case0 = dataI.ism[ii]\n",
    "        case1 = math.floor((min([dataT.th[tt] for tt in dataOR.T_Item[ii]]) - dataI.ihn[ii]) / (dataI.ih[ii] - dataI.ihn[ii]))\n",
    "        case2 = math.floor(min([dataT.tem[tt] for tt in dataOR.T_Item[ii]]) * dataI.ivol2D[ii] / dataI.im[ii])\n",
    "        case3 = math.floor(1 + min([dataT.tmm[tt, dataI.ir[ii]] for tt in dataOR.T_Item[ii]]) / dataI.im[ii])\n",
    "        MaxItemsinStack = max(min(case0, case1, case2, case3), 1)\n",
    "        \n",
    "        AmountFullStacks, ItemsRest = divmod(dataI.num_Item[ii], MaxItemsinStack)\n",
    "\n",
    "        NewItems = []\n",
    "\n",
    "        if AmountFullStacks > 0:\n",
    "            NewName = ii + '_a'\n",
    "            dataO.SI.add(NewName)\n",
    "            NewItems.append(NewName)\n",
    "            dataO.Sm[NewName] = dataI.im[ii] * MaxItemsinStack\n",
    "            dataO.ST_Item[NewName] = dataOR.T_Item[ii]\n",
    "            dataO.Svol2D[NewName] = dataI.ivol2D[ii]   #2D Volumen wird in diesem Ansatz nur für die Ermittlung der Stackhöhe benötigt\n",
    "            dataO.num_Stacks[NewName] = AmountFullStacks\n",
    "            \n",
    "            if dataI.io[ii] == \"none\":\n",
    "                dataO.SwMin[NewName] = dataO.SlMin[NewName] = min(dataI.il[ii], dataI.iw[ii])\n",
    "                dataO.SwMax[NewName] = dataO.SlMax[NewName] = max(dataI.il[ii], dataI.iw[ii])\n",
    "            elif dataI.io[ii] == \"widthwise\":\n",
    "                dataO.SwMin[NewName] = dataO.SwMax[NewName] = dataI.il[ii]\n",
    "                dataO.SlMin[NewName] = dataO.SlMax[NewName] = dataI.iw[ii]\n",
    "            else:\n",
    "                dataO.SwMin[NewName] = dataO.SwMax[NewName] = dataI.iw[ii]\n",
    "                dataO.SlMin[NewName] = dataO.SlMax[NewName] = dataI.il[ii]             \n",
    "\n",
    "            for tt in dataOR.T_Item[ii]:\n",
    "                dataO.Sc_TruckItem[tt, NewName] = dataOR.ic_TruckItem[tt, ii] * MaxItemsinStack\n",
    "                dataO.SI_Truck[tt].append(NewName)\n",
    "                \n",
    "            dataO.So[NewName], dataO.Sl[NewName], dataO.Sw[NewName], dataO.Shn[NewName], dataO.Sst[NewName]  = dataI.io[ii], dataI.il[ii], dataI.iw[ii], dataI.ihn[ii], dataI.ist[ii]\n",
    "            dataO.Ssm[NewName] = 1\n",
    "            dataO.Sh[NewName] = MaxItemsinStack * (dataI.ih[ii] - dataI.ihn[ii])\n",
    "            dataO.AmountinStack_SI[NewName] = MaxItemsinStack\n",
    "            \n",
    "            dataO.I_StackingItem[NewName] = dataOR.I_Item[ii]\n",
    "  \n",
    "        if ItemsRest > 0:\n",
    "            NewName = ii + '_b'\n",
    "            dataO.SI.add(NewName)\n",
    "            NewItems.append(NewName)\n",
    "            dataO.Sm[NewName] = dataI.im[ii] \n",
    "            dataO.ST_Item[NewName] = dataOR.T_Item[ii]\n",
    "            dataO.Svol2D[NewName] = dataI.ivol2D[ii]\n",
    "            dataO.num_Stacks[NewName] = ItemsRest\n",
    "            \n",
    "            if dataI.io[ii] == \"none\":\n",
    "                dataO.SwMin[NewName] = dataO.SlMin[NewName] = min(dataI.il[ii], dataI.iw[ii])\n",
    "                dataO.SwMax[NewName] = dataO.SlMax[NewName] = max(dataI.il[ii], dataI.iw[ii])\n",
    "            elif dataI.io[ii] == \"widthwise\":\n",
    "                dataO.SwMin[NewName] = dataO.SwMax[NewName] = dataI.il[ii]\n",
    "                dataO.SlMin[NewName] = dataO.SlMax[NewName] = dataI.iw[ii]\n",
    "            else:\n",
    "                dataO.SwMin[NewName] = dataO.SwMax[NewName] = dataI.iw[ii]\n",
    "                dataO.SlMin[NewName] = dataO.SlMax[NewName] = dataI.il[ii]             \n",
    "\n",
    "            for tt in dataOR.T_Item[ii]:\n",
    "                dataO.Sc_TruckItem[tt, NewName] = dataOR.ic_TruckItem[tt, ii]          \n",
    "                dataO.SI_Truck[tt].append(NewName)\n",
    "            \n",
    "            dataO.So[NewName], dataO.Sl[NewName], dataO.Sw[NewName], dataO.Sh[NewName], dataO.Shn[NewName], dataO.Sst[NewName], dataO.Ssm[NewName] = dataI.io[ii], dataI.il[ii], dataI.iw[ii], dataI.ih[ii], dataI.ihn[ii], dataI.ist[ii], dataI.ism[ii]\n",
    "            dataO.AmountinStack_SI[NewName] = 1\n",
    "            \n",
    "            dataO.I_StackingItem[NewName] = dataOR.I_Item[ii]\n",
    "    \n",
    "        if len(NewItems) > 1:\n",
    "            dataO.SI_SI[NewItems[0]] = NewItems[1]\n",
    "            dataO.SI_SI[NewItems[1]] = NewItems[0]\n",
    "        else:\n",
    "            dataO.SI_SI[NewItems[0]] = NewItems[0]\n",
    "        #Hier werden die neu erstellten Items (NewName) den Gruppen zugeordnet\n",
    "        for NewName in NewItems:\n",
    "            for tt in dataO.ST_Item[NewName]:\n",
    "                newGroup = True\n",
    "                if dataO.SGroup_Truck[tt]:\n",
    "                    for gi in dataO.SGroup_Truck[tt]:\n",
    "                        if dataO.Sst[NewName] == dataO.st_SGroupTruck[tt, gi] and dataO.Ssm[NewName] == dataO.sm_SGroupTruck[tt, gi]: #Stackability, Max Stackability\n",
    "                            ###Supplier , Supplier Dock , Plant, Plant Dock \n",
    "                            if dataI.iu[ii] == dataO.u_SGroupTruck[tt, gi] and dataI.ik[ii] == dataO.k_SGroupTruck[tt, gi] and dataI.ip[ii] == dataO.p_SGroupTruck[tt, gi] and dataI.ig[ii] == dataO.g_SGroupTruck[tt, gi]:\n",
    "                                \n",
    "                                if dataP.TighterGroups == True:\n",
    "                                    \n",
    "                                    if math.floor((dataT.th[tt] - dataO.Shn[NewName]) / (dataO.Sh[NewName] - dataO.Shn[NewName])) == math.floor((dataT.th[tt] - dataO.hn_SGroupTruck[tt, gi]) / (dataO.h_SGroupTruck[tt, gi] - dataO.hn_SGroupTruck[tt, gi])) and dataO.So[NewName] == dataO.o_SGroupTruck[tt, gi]:       #Orientation\n",
    "                                        dataO.Items_SGroupTruck[tt, gi].append(NewName)\n",
    "                                        dataO.SGroup_ItemsTruck[tt, NewName] = gi\n",
    "                                        \n",
    "                                        if dataO.Sh[NewName] > dataO.h_SGroupTruck[tt, gi]:\n",
    "                                            dataO.h_SGroupTruck[tt, gi] = dataO.Sh[NewName]\n",
    "                                        if dataO.Shn[NewName] < dataO.hn_SGroupTruck[tt, gi]:\n",
    "                                            dataO.hn_SGroupTruck[tt, gi] = dataO.Shn[NewName]    \n",
    "                                            \n",
    "                                        if dataO.mm_SGroupTruck[tt, gi] > dataT.tmm[tt, dataI.ir[ii]]:\n",
    "                                            dataO.mm_SGroupTruck[tt, gi] = dataT.tmm[tt, dataI.ir[ii]]\n",
    "                                        newGroup = False\n",
    "                                        break  \n",
    "\n",
    "                                else:\n",
    "                                    if dataO.So[NewName] == dataO.o_SGroupTruck[tt, gi]:       #Orientation\n",
    "                                        dataO.Items_SGroupTruck[tt, gi].append(NewName)\n",
    "                                        dataO.SGroup_ItemsTruck[tt, NewName] = gi\n",
    "                                        \n",
    "                                        if dataO.Sh[NewName] < dataO.h_SGroupTruck[tt, gi]:\n",
    "                                            dataO.h_SGroupTruck[tt, gi] = dataO.Sh[NewName]\n",
    "                                        if dataO.Shn[NewName] > dataO.hn_SGroupTruck[tt, gi]:\n",
    "                                            dataO.hn_SGroupTruck[tt, gi] = dataO.Shn[NewName]    \n",
    "                                            \n",
    "                                        if dataO.mm_SGroupTruck[tt, gi] > dataT.tmm[tt, dataI.ir[ii]]:\n",
    "                                            dataO.mm_SGroupTruck[tt, gi] = dataT.tmm[tt, dataI.ir[ii]]\n",
    "                                        newGroup = False\n",
    "                                        break   \n",
    " \n",
    "                if newGroup:\n",
    "                    gi = len(dataO.SGroup_Truck[tt]) + 1\n",
    "                    dataO.SGroup_Truck[tt].append(gi)\n",
    "                    dataO.Items_SGroupTruck[tt, gi] = [NewName]\n",
    "                    dataO.SGroup_ItemsTruck[tt, NewName] = gi\n",
    "\n",
    "                    dataO.st_SGroupTruck[tt, gi] = dataO.Sst[NewName]\n",
    "                    dataO.sm_SGroupTruck[tt, gi] = dataO.Ssm[NewName]\n",
    "\n",
    "                    dataO.u_SGroupTruck[tt, gi] = dataI.iu[ii]\n",
    "                    dataO.k_SGroupTruck[tt, gi] = dataI.ik[ii]\n",
    "                    dataO.p_SGroupTruck[tt, gi] = dataI.ip[ii]\n",
    "                    dataO.g_SGroupTruck[tt, gi] = dataI.ig[ii]\n",
    "                    \n",
    "                    dataO.h_SGroupTruck[tt, gi] = dataO.Sh[NewName] \n",
    "                    dataO.hn_SGroupTruck[tt, gi] = dataO.Shn[NewName]\n",
    "                    dataO.o_SGroupTruck[tt, gi] = dataO.So[NewName]\n",
    "\n",
    "                    if dataO.So[NewName] == \"none\":\n",
    "                        dataO.Minw_SGroupTruck[tt][gi] = dataO.Minl_SGroupTruck[tt][gi] = min(dataO.Sl[NewName], dataO.Sw[NewName])\n",
    "                        dataO.Maxw_SGroupTruck[tt][gi] = dataO.Maxl_SGroupTruck[tt][gi] = max(dataO.Sl[NewName], dataO.Sw[NewName])\n",
    "                    elif dataO.So[NewName] == \"widthwise\":\n",
    "                        dataO.Minw_SGroupTruck[tt][gi] = dataO.Maxw_SGroupTruck[tt][gi] = dataO.Sl[NewName]\n",
    "                        dataO.Minl_SGroupTruck[tt][gi] = dataO.Maxl_SGroupTruck[tt][gi] = dataO.Sw[NewName]\n",
    "                    else:\n",
    "                        dataO.Minw_SGroupTruck[tt][gi] = dataO.Maxw_SGroupTruck[tt][gi]  = dataO.Sw[NewName]\n",
    "                        dataO.Minl_SGroupTruck[tt][gi] = dataO.Maxl_SGroupTruck[tt][gi] = dataO.Sl[NewName]                                \n",
    "\n",
    "                    dataO.mm_SGroupTruck[tt, gi] = dataT.tmm[tt, dataI.ir[ii]] \n",
    "                    dataO.vol2D_SGroupTruck[tt, gi] = dataI.ivol2D[ii]\n",
    "\n",
    "                    \n",
    "    for tt in dataT.T:\n",
    "        for gi in dataO.SGroup_Truck[tt]:\n",
    "            #Anzahl NewName in Stack bestimmen\n",
    "            case0 = dataO.sm_SGroupTruck[tt, gi]\n",
    "            case1 = math.floor((dataT.th[tt] - dataO.hn_SGroupTruck[tt, gi]) / (dataO.h_SGroupTruck[tt, gi] - dataO.hn_SGroupTruck[tt, gi]))\n",
    "            case2 = math.floor(dataT.tem[tt] * dataO.vol2D_SGroupTruck[tt, gi] / min([dataO.Sm[NewName] for NewName in dataO.Items_SGroupTruck[tt, gi]]))\n",
    "            case3 = math.floor(1 + dataO.mm_SGroupTruck[tt, gi] / min([dataO.Sm[NewName] for NewName in dataO.Items_SGroupTruck[tt, gi]]))\n",
    "            dataO.itemsPerStack_SGroupTruck[tt,gi] = max(1,min(case0, case1, case2, case3))\n",
    "            \n",
    "            #\"Optimale\" Orientierung für Stack bestimmen um Truckweite bestmöglich auszunutzen\n",
    "            \n",
    "            if dataO.o_SGroupTruck[tt, gi] != \"none\":\n",
    "                l_SGroupTruck = dataO.Maxl_SGroupTruck[tt][gi]\n",
    "                w_SGroupTruck = dataO.Maxw_SGroupTruck[tt][gi]\n",
    "                StacksinRow_SGroupTruck= math.floor(dataT.tw[tt]/w_SGroupTruck)\n",
    "            else:\n",
    "                \n",
    "                if math.floor(dataT.tw[tt]/dataO.Maxw_SGroupTruck[tt][gi]) > math.floor(dataT.tw[tt]/dataO.Minw_SGroupTruck[tt][gi]):\n",
    "                    l_SGroupTruck = dataO.Minl_SGroupTruck[tt][gi]\n",
    "                    w_SGroupTruck = dataO.Maxw_SGroupTruck[tt][gi]\n",
    "                    StacksinRow_SGroupTruck = math.floor(dataT.tw[tt]/w_SGroupTruck)\n",
    "                    \n",
    "                elif math.floor(dataT.tw[tt]/dataO.Maxw_SGroupTruck[tt][gi]) < math.floor(dataT.tw[tt]/dataO.Minw_SGroupTruck[tt][gi]):\n",
    "                    l_SGroupTruck = dataO.Maxl_SGroupTruck[tt][gi]\n",
    "                    w_SGroupTruck = dataO.Minw_SGroupTruck[tt][gi]\n",
    "                    StacksinRow_SGroupTruck = math.floor(dataT.tw[tt]/w_SGroupTruck)\n",
    "                \n",
    "                else:\n",
    "                    l_SGroupTruck = dataO.Minl_SGroupTruck[tt][gi]\n",
    "                    w_SGroupTruck = dataO.Maxw_SGroupTruck[tt][gi]\n",
    "                    StacksinRow_SGroupTruck = math.floor(dataT.tw[tt]/w_SGroupTruck)\n",
    "            \n",
    "            \n",
    "                \n",
    "            #Hier überprüfen, ob neue Super Group aufgemacht werden muss oder Stackgruppe zu bestehender Supergroup hinzugefügt werden kann\n",
    "            newSuperGroup = True\n",
    "            if dataO.SuperGroup_Truck[tt]:\n",
    "                for SG in dataO.SuperGroup_Truck[tt]:        \n",
    "                    if l_SGroupTruck >= dataO.l_SuperGroup[tt,SG] * 0.97 and l_SGroupTruck <= dataO.l_SuperGroup[tt,SG] * 1.03 and w_SGroupTruck >= dataO.wStack_SuperGroup[tt,SG] * 0.97 and w_SGroupTruck <= dataO.wStack_SuperGroup[tt,SG] * 1.03 and StacksinRow_SGroupTruck == dataO.StacksinRow_SuperGroup[tt,SG]:\n",
    "                        #HIer wird Stackgruppe zu Supergroup hinzugefügt\n",
    "                        dataO.SGroup_SuperGroupTruck[tt, SG].append(gi)\n",
    "                        dataO.SuperGroup_SGroupTruck[tt, gi] = SG \n",
    "                        \n",
    "                        if l_SGroupTruck > dataO.l_SuperGroup[tt,SG]:\n",
    "                            dataO.l_SuperGroup[tt,SG] = l_SGroupTruck\n",
    "                            \n",
    "                        if w_SGroupTruck > dataO.wStack_SuperGroup[tt,SG]:\n",
    "                            dataO.wStack_SuperGroup[tt,SG] = w_SGroupTruck \n",
    "                            \n",
    "                        newSuperGroup = False\n",
    "                        break\n",
    "\n",
    "            if newSuperGroup:\n",
    "                #Hier muss eine neue SuperGroup eröffnet werden\n",
    "                SG = len(dataO.SuperGroup_Truck[tt]) + 1\n",
    "                dataO.SuperGroup_Truck[tt].append(SG) \n",
    "                \n",
    "                dataO.SGroup_SuperGroupTruck[tt, SG] = [gi]\n",
    "                dataO.SuperGroup_SGroupTruck[tt, gi] = SG  \n",
    "                \n",
    "                dataO.l_SuperGroup[tt,SG] = l_SGroupTruck\n",
    "                dataO.wStack_SuperGroup[tt,SG] = w_SGroupTruck\n",
    "                dataO.StacksinRow_SuperGroup[tt,SG] = StacksinRow_SGroupTruck \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03947792",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "782e2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_Items(dataT, dataI, dataO, dataP, dataIR, dataOR):\n",
    "    print(\"Start Reduction\")\n",
    "    \n",
    "    GroupedItems = set()     \n",
    "    ISorted = sorted(dataI.I, key=lambda x: (dataI.ide[x], dataI.ist[x]))\n",
    "    for pos1, ii1 in enumerate(ISorted):\n",
    "        if ii1 not in GroupedItems:\n",
    "            GroupedItems.add(ii1)\n",
    "            dataIR.I.add(ii1)\n",
    "            \n",
    "            dataOR.I_Item[ii1] = [ii1]\n",
    "            \n",
    "            # Parameter\n",
    "            dataIR.il[ii1] = dataI.il[ii1]  # Length\n",
    "            dataIR.iw[ii1] = dataI.iw[ii1]  # Width\n",
    "            dataIR.ih[ii1] = dataI.ih[ii1]  # Height\n",
    "            dataIR.ihn[ii1] = dataI.ihn[ii1]  # Nested height\n",
    "            dataIR.ist[ii1] = dataI.ist[ii1]  # (is) Stackability code\n",
    "            dataIR.ism[ii1] = dataI.ism[ii1]  # Maximal stackability\n",
    "            dataIR.ir[ii1] = dataI.ir[ii1]  # Product type\n",
    "            dataIR.io[ii1] = dataI.io[ii1]  # Orientation\n",
    "            dataIR.ide[ii1] = dataI.ide[ii1]  # Earliest arrival\n",
    "            dataIR.idl[ii1] = dataI.idl[ii1]  # Latest arrival\n",
    "            dataIR.ip[ii1] = dataI.ip[ii1]  # Destination plant\n",
    "            dataIR.ig[ii1] = dataI.ig[ii1]  # Destination dock\n",
    "            dataIR.iu[ii1] = dataI.iu[ii1]  # Supplier\n",
    "            dataIR.ik[ii1] = dataI.ik[ii1]  # Supplier dock\n",
    "            dataIR.ic[ii1] = dict()  # Inventory cost\n",
    "\n",
    "            dataIR.num_Item[ii1] = dataI.num_Item[ii1]\n",
    "            dataIR.ivol2D[ii1] = dataI.ivol2D[ii1]  # in m²\n",
    "            dataIR.ivol3D[ii1] = dataI.ivol3D[ii1]  # in m³            \n",
    "\n",
    "            for ii2 in ISorted[pos1+1:]:\n",
    "                if ii2 not in GroupedItems:\n",
    "                    if dataI.ide[ii1] != dataI.ide[ii2] or dataI.ist[ii1] != dataI.ist[ii2]:\n",
    "                        break     \n",
    "                    if set(dataO.T_Item[ii1]) == set(dataO.T_Item[ii2]) and dataI.iu[ii1] == dataI.iu[ii2] and dataI.ik[ii1] == dataI.ik[ii2] and dataI.ip[ii1] == dataI.ip[ii2] and dataI.ig[ii1] == dataI.ig[ii2]:\n",
    "                            if dataI.il[ii1] == dataI.il[ii2] and dataI.iw[ii1] == dataI.iw[ii2] and dataI.ih[ii1] == dataI.ih[ii2] and dataI.ihn[ii1] == dataI.ihn[ii2]:\n",
    "                                if dataI.ist[ii1] == dataI.ist[ii2] and dataI.io[ii1] == dataI.io[ii2] and dataI.ism[ii1] == dataI.ism[ii2]:\n",
    "                                    if dataI.ide[ii1] == dataI.ide[ii2] and dataI.idl[ii1] == dataI.idl[ii2]:\n",
    "                                        if dataP.fAPReductionWeight * min(dataI.im[ii1], dataI.im[ii2]) >= max(dataI.im[ii1], dataI.im[ii2]) and dataP.fAPReductionIC * min(dataI.ic[ii1], dataI.ic[ii2]) >= max(dataI.ic[ii1], dataI.ic[ii2]):\n",
    "                                            GroupedItems.add(ii2)\n",
    "                                            dataOR.I_Item[ii1].append(ii2)\n",
    "                                            dataIR.num_Item[ii1] += dataI.num_Item[ii2]\n",
    "                             \n",
    "            dataIR.im[ii1] = max([dataI.im[ii2] for ii2 in dataOR.I_Item[ii1]])  # Weight\n",
    "            dataIR.ic[ii1] = max([dataI.ic[ii2] for ii2 in dataOR.I_Item[ii1]])  # Inventory cost\n",
    "            \n",
    "            \n",
    "            dataOR.T_Item[ii1] = copy.deepcopy(dataO.T_Item[ii1])\n",
    "            for tt in dataO.T_Item[ii1]:\n",
    "                dataOR.ic_TruckItem[tt,ii1] = max([dataO.ic_TruckItem[tt,ii2] for ii2 in dataOR.I_Item[ii1]])\n",
    "                dataOR.I_Truck[tt].append(ii1)\n",
    "                \n",
    "                # Determin 3D volume for item based on max stackability\n",
    "                if dataI.ism[ii1] == 1:\n",
    "                    dataOR.ivol3D_TruckItem[tt, ii1] = dataIR.ivol2D[ii1] * (dataT.th[tt] / 1_000)\n",
    "                else:\n",
    "                    dataOR.ivol3D_TruckItem[tt, ii1] = dataIR.ivol3D[ii1] \n",
    "                    \n",
    "              #  dataOR.numMax_TruckItem[tt,ii1] = sum([dataO.numMax_TruckItem[tt,ii2] for ii2 in dataOR.I_Item[ii1]])\n",
    "\n",
    "    dataOR.identicalTrucks = copy.deepcopy(dataO.identicalTrucks)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for ii in dataIR.I:\n",
    "        dataOR.T_Item[ii] = sorted(dataOR.T_Item[ii], key=lambda x: dataOR.ic_TruckItem[x, ii])\n",
    "        unusedTrucks = []\n",
    "        tcPseudoMin = min([dataT.tcPseudo[tt] for tt in dataOR.T_Item[ii]])\n",
    "        for tt in dataOR.T_Item[ii]:\n",
    "            if dataOR.ic_TruckItem[tt,ii]  >=  tcPseudoMin:\n",
    "                unusedTrucks.append(tt)\n",
    "        unusedTrucks = unusedTrucks[1:] if len(unusedTrucks) == len(dataOR.T_Item[ii]) else unusedTrucks\n",
    "        for tt in unusedTrucks:\n",
    "            dataOR.I_Truck[tt].remove(ii)\n",
    "            dataOR.T_Item[ii].remove(tt) \n",
    "        for tt in dataOR.T_Item[ii]:\n",
    "            dataOR.numMax_TruckItem[tt,ii] = int(math.floor(tcPseudoMin/dataOR.ic_TruckItem[tt,ii])) if dataOR.ic_TruckItem[tt,ii] > 0 else dataIR.num_Item[ii]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd808f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Assignment\n",
    "\n",
    "Assignment problem to define which trucks will be used in what numbers and which items in what numbers will be assigned to what trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508293d0",
   "metadata": {},
   "source": [
    "## Solution objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82c480c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AP0Solution(object):\n",
    "    def __init__(self):\n",
    "        self.tau = dict()\n",
    "        self.theta= dict()\n",
    "        self.iota = dict()\n",
    "        self.gimu = dict()\n",
    "        \n",
    "        \n",
    "        self.ratioUsage_Truck = {}\n",
    "        self.info = {\"APObj\": None, \"APcT\": None, \"APcI\": None, \"APGAP\": None, \"APrt\": None}\n",
    "        \n",
    "    def print_sol(self):\n",
    "        print(f\"Assignment Objective;{self.info['APObj']}\")\n",
    "        print(f\"Assignment transportation cost;{self.info['APcT']}\")\n",
    "        print(f\"Assignment inventory cost;{self.info['APcI']}\")\n",
    "        print(f\"Assignment MIP-GAP (%);{self.info['APGAP']}\")\n",
    "        print(f\"Assignment Runtime;{self.info['APrt']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c60c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AP1Solution(object):\n",
    "    def __init__(self):\n",
    "        self.T = []\n",
    "        self.TRepack = []\n",
    "        self.I_Truck = {}\n",
    "        \n",
    "        self.num_Truck = {}\n",
    "        self.num_Truck_Item = {}\n",
    "        \n",
    "        self.numItemsPerTruck_Truck = {}\n",
    "        self.numItemsPerTruck = {}\n",
    "        \n",
    "        self.weightPerTruck_Truck = {}\n",
    "        \n",
    "        self.tcInventory = {} # For a truck the inventory costs\n",
    "        self.tcTransport = {} # For a truck the transportation costs (original + pseudo)\n",
    "        \n",
    "        self.info = {\"APObj\": None, \"APcT\": None, \"APcI\": None, \"APGAP\": None, \"APrt\": None}\n",
    "        \n",
    "    def print_sol(self):\n",
    "        print(f\"Assignment Objective;{self.info['APObj']}\")\n",
    "        print(f\"Assignment transportation cost;{self.info['APcT']}\")\n",
    "        print(f\"Assignment inventory cost;{self.info['APcI']}\")\n",
    "        print(f\"Assignment MIP-GAP (%);{self.info['APGAP']}\")\n",
    "        print(f\"Assignment Runtime;{self.info['APrt']}\")\n",
    "        \n",
    "    def export_sol(self, path):\n",
    "        pos = path.rfind('/')\n",
    "        # Create folder in path if it does not exist\n",
    "        Path(path[:pos]).mkdir(parents=True, exist_ok=True)\n",
    "        folder = path[:pos]\n",
    "        \n",
    "        with open(folder + \"/AP1.sol\", 'w') as fp:\n",
    "            for tt in self.T:\n",
    "                fp.write(\"---\\n\")   \n",
    "                fp.write(f\"Truck;{tt};{self.num_Truck[tt]}\\n\")\n",
    "                for ii in self.I_Truck[tt]:   \n",
    "                    fp.write(f\"Item;{ii};{self.num_Truck_Item[tt][ii]}\\n\")\n",
    "                    \n",
    "    def load_sol(self, path, dataT, dataI, dataO):\n",
    "        print(path)\n",
    "        pos = path.rfind('/')\n",
    "        # Create folder in path if it does not exist\n",
    "        Path(path[:pos]).mkdir(parents=True, exist_ok=True)\n",
    "        folder = path[:pos]\n",
    "        \n",
    "        with open(folder + \"/AP1.sol\", 'r') as fp:\n",
    "            for line in fp.readlines():\n",
    "                if line.rstrip() == \"---\":\n",
    "                    pass\n",
    "                else:\n",
    "                    vName, idx, value = line.rstrip().split(\";\")\n",
    "                    value = int(value)\n",
    "                    \n",
    "                    if vName == \"Truck\":\n",
    "                        ttIdx = idx\n",
    "                        self.T.append(idx)\n",
    "                        self.num_Truck[idx] = value\n",
    "                        self.I_Truck[ttIdx] = []\n",
    "                        self.num_Truck_Item[ttIdx] = {}\n",
    "                        self.numItemsPerTruck[ttIdx] = 0\n",
    "                    elif vName == \"Item\":\n",
    "                        self.I_Truck[ttIdx].append(idx)\n",
    "                        self.num_Truck_Item[ttIdx][idx] = value\n",
    "                        self.numItemsPerTruck[ttIdx] += value\n",
    "                        \n",
    "        for tt in self.T:\n",
    "            self.numItemsPerTruck_Truck[tt] = sum([self.num_Truck_Item[tt][ii] for ii in self.I_Truck[tt]]) / self.num_Truck[tt]\n",
    "            self.weightPerTruck_Truck[tt] = sum([dataI.im[ii] for ii in self.I_Truck[tt]]) / self.num_Truck[tt]\n",
    "\n",
    "            \n",
    "\n",
    "        self.info['APObj'] = 0\n",
    "        self.info['APcT'] = 0\n",
    "        self.info['APcI'] = 0\n",
    "\n",
    "        for tt in self.T:\n",
    "            self.info['APcT'] += dataT.tc[tt] + dataT.tcPseudo[tt] * (self.num_Truck[tt] - 1)\n",
    "            \n",
    "            for ii, num in self.num_Truck_Item[tt].items():\n",
    "                self.info['APcI'] += dataO.ic_TruckItem[tt, ii] * num\n",
    "                \n",
    "\n",
    "        self.info['APObj'] = self.info['APcT'] + self.info['APcI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f76012",
   "metadata": {},
   "source": [
    "## Time limit soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f896333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softTimeAP1(model, where):\n",
    "    if where == GRB.Callback.MIP:\n",
    "        runtime = model.cbGet(GRB.Callback.RUNTIME)\n",
    "        objbst = model.cbGet(GRB.Callback.MIP_OBJBST)\n",
    "        objbnd = model.cbGet(GRB.Callback.MIP_OBJBND)\n",
    "        gap = abs(objbst - objbnd) / objbst\n",
    "        \n",
    "        # Terminate optimization if MIP-Gap below 0.5% and half time is over\n",
    "        if gap < 0.005 and runtime > model._limit1pct:\n",
    "            model.terminate()   \n",
    "            \n",
    "def softTimeAP0(model, where):\n",
    "    if where == GRB.Callback.MIP:\n",
    "        runtime = model.cbGet(GRB.Callback.RUNTIME)\n",
    "        objbst = model.cbGet(GRB.Callback.MIP_OBJBST)\n",
    "        objbnd = model.cbGet(GRB.Callback.MIP_OBJBND)\n",
    "        gap = abs(objbst - objbnd) / objbst\n",
    "        \n",
    "        # Terminate optimization if MIP-Gap below 1% and half time is over\n",
    "        if gap < 0.01 and runtime > model._limit1pct:\n",
    "            model.terminate()             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1d3c7",
   "metadata": {},
   "source": [
    "## AP0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00ad5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_AP0(dataT, dataO, dataP, limit_Truck, TimeLimit):\n",
    "    \n",
    "    m = Model('Assignment Problem with step function')\n",
    "\n",
    "    # Variables\n",
    "    iota = tupledict()  # Binary if Variable ii is stored in Truck tt\n",
    "    iotaRowsSG = tupledict()  # Rows of SuperGroups in Truck tt\n",
    "    iotaGroupSG = tupledict()  # Group in SuperGroups in Truck tt  \n",
    "    tau = tupledict()  # Indicator if truck tt is used\n",
    "    theta = tupledict()  # Number of pseudo trucks used of truck tt\n",
    "    cT = tupledict()  # Transportation costs for truck tt\n",
    "    cI = tupledict()  # Inventory costs for truck tt\n",
    "\n",
    "    for tt in dataT.T:\n",
    "        tau[tt] = m.addVar(vtype='B', name=f\"tau[{tt}]\")\n",
    "        theta[tt] = m.addVar(vtype='I', name=f\"theta[{tt}]\")\n",
    "        cT[tt] = m.addVar(vtype='C', name=f\"cT[{tt}]\")\n",
    "        cI[tt] = m.addVar(vtype='C', name=f\"cI[{tt}]\")\n",
    "        \n",
    "        #Variablen für Supergroups erstellen\n",
    "        for jj in dataO.SuperGroup_Truck[tt]:\n",
    "            iotaRowsSG[tt, jj] = m.addVar(vtype='I', lb=0)\n",
    "            \n",
    "            for gi in dataO.SGroup_SuperGroupTruck[tt, jj]:\n",
    "                iotaGroupSG[tt, gi] = m.addVar(vtype='I', lb=0)\n",
    "                 \n",
    "    for ii in dataO.SI:\n",
    "        for tt in dataO.ST_Item[ii]:\n",
    "            iota[tt, ii] = m.addVar(vtype='I', lb=0, ub=dataO.num_Stacks[ii])\n",
    "\n",
    "    # Objective\n",
    "    m.setObjective(quicksum(dataT.tc[tt] * tau[tt] for tt in dataT.T)\n",
    "                   + quicksum(dataT.tcPseudo[tt]* theta[tt] for tt in dataT.T)\n",
    "                   + quicksum(dataO.Sc_TruckItem[tt, ii]*iota[tt,ii] for ii in dataO.SI for tt in dataO.ST_Item[ii])\n",
    "                   , GRB.MINIMIZE)\n",
    " \n",
    "    #General constraints\n",
    "    for tt in dataT.T:\n",
    "        # Track costs for a truck\n",
    "        m.addConstr(dataT.tc[tt] * tau[tt] + dataT.tcPseudo[tt] * theta[tt]\n",
    "                    == cT[tt], name=f'TruckCosts[{tt}]')\n",
    "        m.addConstr(quicksum(dataO.Sc_TruckItem[tt,ii] * iota[tt,ii] for ii in dataO.SI_Truck[tt])\n",
    "                    == cI[tt], name=f'InventoryCosts[{tt}]')\n",
    "\n",
    "        # Weight limit for a truck\n",
    "        m.addConstr(quicksum(dataO.Sm[ii] * iota[tt, ii] for ii in dataO.SI_Truck[tt])\n",
    "                    <= limit_Truck[tt] * dataT.tm[tt] * (tau[tt] + theta[tt]))        \n",
    "        \n",
    "        #Anzahl der Rows der Supergroups in Truck bestimmen\n",
    "        for jj in dataO.SuperGroup_Truck[tt]:\n",
    "\n",
    "            for gi in dataO.SGroup_SuperGroupTruck[tt, jj]:\n",
    "                m.addConstr( quicksum(iota[tt, ii] for ii in dataO.Items_SGroupTruck[tt, gi])/ dataO.itemsPerStack_SGroupTruck[tt,gi] <= iotaGroupSG[tt, gi])\n",
    "  \n",
    "            m.addConstr(quicksum(iotaGroupSG[tt, gi] for gi in dataO.SGroup_SuperGroupTruck[tt, jj]) / dataO.StacksinRow_SuperGroup[tt,jj] \n",
    "                        <= iotaRowsSG[tt, jj])\n",
    "        \n",
    "        #Längenconstraints mithilfe der SuperGroups\n",
    "        m.addConstr(quicksum(dataO.l_SuperGroup[tt,jj] * iotaRowsSG[tt, jj] for jj in dataO.SuperGroup_Truck[tt])\n",
    "                    <= dataT.tl[tt] * (tau[tt] + theta[tt]))  \n",
    "        \n",
    "        m.addConstr( 25 * tau[tt] >= theta[tt])\n",
    "        \n",
    "      \n",
    "    for ii in dataO.SI:\n",
    "        # All items must be assigned to a truck\n",
    "        m.addConstr(quicksum(iota[tt, ii] for tt in dataO.ST_Item[ii])\n",
    "                    == dataO.num_Stacks[ii])\n",
    "\n",
    "\n",
    "    # Symmetrie breaking for trucks, both truck are similar and the cheaper truck is used first\n",
    "    for tt1, tt2 in dataO.identicalTrucks:\n",
    "        m.addConstr(tau[tt2]\n",
    "                    <= tau[tt1], name=f\"Truck_symmetry[{tt1},{tt2}]\")\n",
    "                \n",
    "    # Start optimization\n",
    " #   m.setParam('OutputFlag', 0)\n",
    "    m.setParam('MIPFocus', 1)\n",
    "    m.setParam('Timelimit', TimeLimit)\n",
    "    m.setParam('Threads', 8)\n",
    "    m.setParam('MIPGAP' , 0.005)   \n",
    "    \n",
    "    m._limit1pct = TimeLimit*0.25\n",
    "    m.optimize(softTimeAP0)       \n",
    "    \n",
    "    if m.status == 3:\n",
    "        m.computeIIS()\n",
    "        m.write(\"model.ilp\")\n",
    "        exit(\"FAIL\")   \n",
    "    \n",
    "        \n",
    "    \n",
    "    print(f\"Objective AP1: {round(m.ObjVal, 2)}, MIP-Gap: {round(m.MIPGap * 100, 2)}%\")\n",
    "                \n",
    "    print(f\"AP0 requires {int(sum([var.X for var in tau.values()]))} trucks and {int(sum([var.X for var in theta.values()]))} pseudo trucks.\") \n",
    "    \n",
    "\n",
    "    \n",
    "    # Safe Solution\n",
    "    for ii in dataO.SI:\n",
    "        for tt in dataO.ST_Item[ii]:\n",
    "            dataO.APStackSolution_Truck_Item[tt,ii] = int(round(iota[tt, ii].X, 0))\n",
    "            \n",
    "            \n",
    "            dataO.FixPseudosTest[tt] = int(round(theta[tt].X, 0))\n",
    "            \n",
    "            if int(round(tau[tt].X, 0)) > 0:\n",
    "                dataO.FixTruckTest.add(tt)\n",
    "\n",
    "                        \n",
    "            \n",
    "    # Parse solution\n",
    "    assignment0 = AP0Solution()\n",
    "\n",
    "    for tt in dataT.T:\n",
    "        \n",
    "        assignment0.tau[tt] = round(tau[tt].X)\n",
    "        assignment0.theta[tt] = round(theta[tt].X)\n",
    "\n",
    "        \n",
    "    assignment0.info[\"APObj\"] = round(m.ObjVal, 2)\n",
    "    assignment0.info[\"APcT\"] = round(sum([cT[tt].X for tt in dataT.T]), 2)\n",
    "    assignment0.info[\"APcI\"] = round(sum([cI[tt].X for tt in dataT.T]), 2)\n",
    "    assignment0.info[\"APGAP\"] = round(m.MIPGap * 100, 2)\n",
    "    assignment0.info[\"APrt\"] = round(m.Runtime, 2)\n",
    "    \n",
    "    return assignment0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea01094",
   "metadata": {},
   "source": [
    "## AP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9a5cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_AP1(dataT, dataI, dataO, dataOR, dataP, num_Item, limitTime, assignment0, fixed=False):\n",
    "    # Use step function and partial variable fixation to improve first assignment solution\n",
    "    timeAP1 = time.perf_counter()\n",
    "    fixedConstrs = []\n",
    "    \n",
    "    m = Model('Assignment Problem with step function')\n",
    "\n",
    "    # Variables\n",
    "    iota = tupledict()  # Number of item ii assigned to truck tt\n",
    "    ginu = tupledict()  # group of items active\n",
    "    tau = tupledict()  # Indicator if truck tt is used\n",
    "    theta = tupledict()  # Number of pseudo trucks used of truck tt\n",
    "    cT = tupledict()  # Transportation costs for truck tt\n",
    "    cI = tupledict()  # Inventory costs for truck tt\n",
    "\n",
    "    for tt in dataT.T:\n",
    "        tau[tt] = m.addVar(vtype='B', name=f\"tau[{tt}]\")\n",
    "        theta[tt] = m.addVar(vtype='I', name=f\"theta[{tt}]\")\n",
    "        cT[tt] = m.addVar(vtype='C', name=f\"cT[{tt}]\")\n",
    "        cI[tt] = m.addVar(vtype='C', name=f\"cI[{tt}]\")\n",
    "\n",
    "        for ii in dataO.I_Truck[tt]:\n",
    "            iota[tt, ii] = m.addVar(vtype='I',ub=num_Item[ii], name=f\"iota[{tt},{ii}]\")\n",
    "  \n",
    "        for gi in dataO.GI_Truck[tt]:\n",
    "            for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1):\n",
    "                ginu[tt, gi, jj] = m.addVar(vtype='B', name=f\"ginu[{tt},{gi},{jj}]\") \n",
    "    \n",
    "    # Objective\n",
    "    m.setObjective(quicksum(dataT.tc[tt] * tau[tt] for tt in dataT.T)\n",
    "                   + quicksum(dataT.tcPseudo[tt]* theta[tt] for tt in dataT.T)\n",
    "                   + quicksum(dataO.ic_TruckItem[tt, ii]*iota[tt,ii] for tt in dataT.T for ii in dataO.I_Truck[tt])\n",
    "                   , GRB.MINIMIZE)\n",
    "    \n",
    "    #General constraints\n",
    "    for tt in dataT.T:\n",
    "        # Track costs for a truck\n",
    "        m.addConstr(dataT.tc[tt] * tau[tt] + dataT.tcPseudo[tt] * theta[tt]\n",
    "                    == cT[tt], name=f'TruckCosts[{tt}]')\n",
    "        m.addConstr(quicksum(dataO.ic_TruckItem[tt,ii] * iota[tt,ii] for ii in dataO.I_Truck[tt])\n",
    "                    == cI[tt], name=f'InventoryCosts[{tt}]')\n",
    "        \n",
    "        # 3d volume and weight limit for a truck\n",
    "        m.addConstr(quicksum(dataO.ivol3D_TruckItem[tt, ii] * iota[tt, ii] for ii in dataO.I_Truck[tt])\n",
    "                    <= dataO.limit_Truck[tt] * (dataT.tvol3D[tt] * (tau[tt] + theta[tt])), name=f\"Truck_vol3D[{tt}]\")\n",
    "        m.addConstr(quicksum(dataI.im[ii] * iota[tt, ii] for ii in dataO.I_Truck[tt])\n",
    "                    <= dataO.limit_Truck[tt] * (dataT.tm[tt] * (tau[tt] + theta[tt])), name=f\"Truck_weight[{tt}]\")\n",
    "        \n",
    "        m.addConstr( 1000 * tau[tt] >= theta[tt])\n",
    "        \n",
    "\n",
    "    for ii in dataI.I:\n",
    "        # All items must be assigned to a truck\n",
    "        m.addConstr(quicksum(iota[tt, ii] for tt in dataO.T_Item[ii])\n",
    "                    == num_Item[ii], name=f'Item_loaded[{ii}]')\n",
    "\n",
    "\n",
    "    # Symmetrie breaking for trucks, both truck are similar and the cheaper truck is used first\n",
    "    for tt1, tt2 in dataO.identicalTrucks:\n",
    "        m.addConstr(tau[tt2]\n",
    "                    <= tau[tt1], name=f\"Truck_symmetry[{tt1},{tt2}]\")\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Ginu mit iota verknüpfen\n",
    "    for tt in dataT.T:\n",
    "        for gi in dataO.GI_Truck[tt]:\n",
    "            m.addConstr(quicksum(ginu[tt, gi, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                        == 1, name=f\"GroupItemActive[{tt},{gi}]\")\n",
    "            m.addConstr(quicksum(iota[tt, ii] for ii in dataO.I_TruckGroupitems[tt, gi])\n",
    "                        == quicksum(jj * ginu[tt, gi, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1)), name=f\"GroupItemNumber[{tt},{gi}]\")\n",
    "            \n",
    "\n",
    "    for tt, II in dataO.I_Truck.items():\n",
    "        if II:        \n",
    "            #2D Volumen Constraint\n",
    "            m.addConstr(quicksum(dataO.givol2D_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for gi in dataO.GI_Truck[tt] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                        <= dataO.limit_Truck[tt] * dataT.tvol2D[tt] * (tau[tt] + theta[tt]), name=f\"Truck_vol2D[{tt}]\")            \n",
    "            \n",
    "            #2D Volumen UP Constraint -> Redundant mit oberere Constraint\n",
    "            m.addConstr(quicksum(dataO.giVol2DUp_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for gi in dataO.GI_Truck[tt] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                        <= dataO.limit_Truck[tt] * dataT.tvol2D[tt] * (tau[tt] + theta[tt]), name=f\"Truck_vol2DUP[{tt}]\")            \n",
    "            \n",
    "            #Einfache Längenrestriktion pro Itemgruppe\n",
    "            for gi in dataO.GI_Truck[tt]:\n",
    "                m.addConstr(quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                            <= dataT.tl[tt] * (tau[tt] + theta[tt]), name=f\"GILength_Truck[{tt}, {gi}]\")              \n",
    "            \n",
    "            #Einfache Längenrestriktion über alle Itemgruppen die nicht hintereinander gestellt werden können\n",
    "            m.addConstr(quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for gi in dataO.GIWidthGroup_Truck[tt] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                        <= dataT.tl[tt] * (tau[tt] + theta[tt]), name=f\"GIMultiGroupsLength_Truck[{tt}]\")             \n",
    "            \n",
    "            #Komplexere Längenrestriktion für Itempaare die nicht hintereinander gepackt werden dürfen\n",
    "            for gi1, gi2 in dataO.GIWidthPair_Truck[tt]:\n",
    "                m.addConstr(quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi1, jj] * ginu[tt, gi1, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi1]+1))\n",
    "                            + quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi2, jj] * ginu[tt, gi2, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi2]+1))\n",
    "                            <= dataT.tl[tt] * (tau[tt] + theta[tt]), name=f\"GIWidthPair_Truck[{tt},{gi1},{gi2}]\")\n",
    "                \n",
    "            #Supergroup Längenconstraints\n",
    "            for supergroups in dataO.GIWidthSuperGroup_Truck[tt]:\n",
    "                m.addConstr(quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for gi in supergroups for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                            <= dataT.tl[tt] * (tau[tt] + theta[tt]), name=f\"Supergroup[{tt}, {supergroups}]\")\n",
    "            \n",
    "\n",
    "    ###Hier wird AP0 Lösung fixiert\n",
    "    for iiR in dataO.SI:\n",
    "        for tt in dataO.ST_Item[iiR]:            \n",
    "            if dataO.APStackSolution_Truck_Item[tt,iiR] > 0:\n",
    "                if iiR == dataO.SI_SI[iiR]:\n",
    "                    fixedConstrs.append(m.addConstr(quicksum(iota[tt, ii] for ii in dataO.I_StackingItem[iiR]) >= dataO.AmountinStack_SI[iiR] * dataO.APStackSolution_Truck_Item[tt,iiR], name=f\"fixSolIota[{tt},{iiR}]\"))\n",
    "                else:\n",
    "                    fixedConstrs.append(m.addConstr(quicksum(iota[tt, ii] for ii in dataO.I_StackingItem[iiR]) >= dataO.AmountinStack_SI[iiR] * dataO.APStackSolution_Truck_Item[tt,iiR] + dataO.AmountinStack_SI[dataO.SI_SI[iiR]] * dataO.APStackSolution_Truck_Item[tt,dataO.SI_SI[iiR]], name=f\"fixSolIota[{tt},{iiR}]\"))\n",
    "                    \n",
    "            else:\n",
    "                if dataO.APStackSolution_Truck_Item[tt,dataO.SI_SI[iiR]] == 0:\n",
    "                    fixedConstrs.append(m.addConstr(quicksum(iota[tt, ii] for ii in dataO.I_StackingItem[iiR]) == 0, name=f\"fixSolIota[{tt},{iiR}]\"))\n",
    "                    \n",
    "   # for tt in assignment0.tau:\n",
    "   #     fixedConstrs.append(m.addConstr(tau[tt] == assignment0.tau[tt], name=f\"fixTruck[{tt}]\"))\n",
    "   #     fixedConstrs.append(m.addConstr(theta[tt] == assignment0.theta[tt], name=f\"fixPseudo[{tt}]\"))\n",
    "    \n",
    "\n",
    "    # Start optimization\n",
    "    if not fixed:\n",
    "        m.setParam('Timelimit', limitTime)\n",
    "  #  m.setParam('OutputFlag', 0)\n",
    "    m.setParam('Threads', 8)\n",
    "    m.setParam('MIPGAP' , 0.0000000000000001)\n",
    "    m.optimize()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if m.status == 3:\n",
    "        m.computeIIS()\n",
    "        m.write(\"model.ilp\")\n",
    "        exit(\"FAIL\")   \n",
    "    \n",
    "    if (time.perf_counter() - timeAP1) / limitTime <= 0.9:\n",
    "        print(\"#\"*100)\n",
    "        print(\"Hier wird die fixierte Version nochmal relaxiert um bessere Lösungen zu erhalten\")\n",
    "\n",
    "        \n",
    "        for constr in fixedConstrs:\n",
    "            m.remove(constr)\n",
    "        m.setParam('Timelimit', limitTime - (time.perf_counter() - timeAP1))\n",
    "        m.setParam('MIPFocus', 1)\n",
    "        m.setParam('MIPGAP' , 0.0000000000000001)\n",
    "        m._limit1pct = limitTime/4\n",
    "        m.optimize(softTimeAP1)\n",
    "        \n",
    "    \n",
    "    print(f\"Objective AP1: {round(m.ObjVal, 2)}, MIP-Gap: {round(m.MIPGap * 100, 2)}%\")\n",
    "\n",
    "    \n",
    "    # Parse solution\n",
    "    assignment1 = AP1Solution()\n",
    "\n",
    " #   Anzahl_Pseudo_Trucks_Genutzt = 0\n",
    "    for tt, var in tau.items():       \n",
    "        if var.X > 0.5:\n",
    "            assignment1.T.append(tt)\n",
    "            assignment1.num_Truck[tt] = 1 + int(round(theta[tt].X, 0))\n",
    "            assignment1.I_Truck[tt] = []\n",
    "            assignment1.num_Truck_Item[tt] = {}\n",
    "            assignment1.numItemsPerTruck_Truck[tt] = 0\n",
    "            assignment1.numItemsPerTruck[tt] = 0\n",
    "            assignment1.weightPerTruck_Truck[tt] = 0\n",
    "            \n",
    "            for ii in dataO.I_Truck[tt]:\n",
    "                if iota[tt, ii].X > 0.5:\n",
    "                    \n",
    "                    assignment1.I_Truck[tt].append(ii)\n",
    "                    assignment1.num_Truck_Item[tt][ii] = int(round(iota[tt, ii].X, 0))\n",
    "                    assignment1.numItemsPerTruck_Truck[tt] += assignment1.num_Truck_Item[tt][ii]\n",
    "                    assignment1.numItemsPerTruck[tt] += assignment1.num_Truck_Item[tt][ii]\n",
    "                    assignment1.weightPerTruck_Truck[tt] += dataI.im[ii] * assignment1.num_Truck_Item[tt][ii]\n",
    "\n",
    "            \n",
    "            assignment1.numItemsPerTruck_Truck[tt] /= assignment1.num_Truck[tt]\n",
    "            assignment1.weightPerTruck_Truck[tt] /= assignment1.num_Truck[tt]\n",
    "    \n",
    "    assignment1.T.sort()\n",
    "    for tt in assignment1.T:\n",
    "        assignment1.I_Truck[tt].sort()\n",
    "\n",
    "    for tt in assignment1.T:\n",
    "        assignment1.tcTransport[tt] = cT[tt].X\n",
    "        assignment1.tcInventory[tt] = cI[tt].X\n",
    "         \n",
    "    assignment1.info[\"APObj\"] = round(m.ObjVal, 2)\n",
    "    assignment1.info[\"APcT\"] = round(sum([cT[tt].X for tt in dataT.T]), 2)\n",
    "    assignment1.info[\"APcI\"] = round(sum([cI[tt].X for tt in dataT.T]), 2)\n",
    "    assignment1.info[\"APGAP\"] = round(m.MIPGap * 100, 2)\n",
    "    assignment1.info[\"APrt\"] = m.Runtime\n",
    "    \n",
    "    print(f\"AP1 requires {sum(assignment1.num_Truck.values())} trucks to transport {sum(dataI.num_Item.values())} items. {int(sum([var.X for var in tau.values()]))} trucks and {int(sum([var.X for var in theta.values()]))} pseudo trucks.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "   # for tt in dataT.T:\n",
    "   #     if tau[tt].X > 0.5:\n",
    "   #         print()\n",
    "   #         print(tt, round(theta[tt].X))\n",
    "    \n",
    "    \n",
    "    return assignment1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0898bc94",
   "metadata": {},
   "source": [
    "##  APLNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f52f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softAPLNS(model, where):\n",
    "    if where == GRB.Callback.MIPSOL:\n",
    "        model._solFound = True\n",
    "\n",
    "    if where == GRB.Callback.MIP:\n",
    "        runtime = model.cbGet(GRB.Callback.RUNTIME)\n",
    "\n",
    "        if model._limitTimeNotReached:\n",
    "            model._solFoundTime = time.perf_counter()\n",
    "\n",
    "        if model._solFound and runtime > model._limitTime:\n",
    "            model._limitTimeNotReached = False\n",
    "            \n",
    "        if time.perf_counter() > model._solFoundTime + 5:\n",
    "            model.terminate()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0fd4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_APLNS(dataT, dataI, dataO, dataP, sol, T, TTrouble, I, num_Item, limitTime):\n",
    "    \n",
    "    # Use step function and partial variable fixation to improve first assignment solution\n",
    "  #  print(\"#\"*1000)\n",
    "  #  print(f\"APLNS mit Zeitlimit {limitTime}\")\n",
    "  #  print(\"TTrouble: \" , TTrouble)\n",
    "    # Determine LNS trucks\n",
    "    TFree = []\n",
    "    TFull = []\n",
    "    \n",
    "    # Trucks that required more trucks than AP assigned\n",
    "    #TWithExtra = [tt for tt in sol.Trucks if sol.extraTrucks_Truck[tt]]\n",
    "    ### Here decide which trucks should be open, i.e. where later we do not fix the transported items\n",
    "    TLNS = set(TTrouble)\n",
    "    \n",
    "    num_Truck_Item = {tt: {ii: 0 for ii in dataO.I_Truck[tt]} for tt in TLNS}\n",
    "    if dataP.ReductionInfeasibleTrucks == True:\n",
    "        for tt in TLNS:\n",
    "            Loaded2D = 0\n",
    "            Loaded3D = 0\n",
    "            LoadedM = 0        \n",
    "            for truck in sol.Trucks[tt]:            \n",
    "                for stack in truck.Stacks:\n",
    "                    Loaded2D += (stack.xe - stack.xo) * (stack.ye - stack.yo) / 1_000_000\n",
    "                    Loaded3D += (stack.xe - stack.xo) * (stack.ye - stack.yo) * stack.ze / 1_000_000_000\n",
    "\n",
    "                    for item in stack.Items:\n",
    "                        LoadedM += dataI.im[item.idx]\n",
    "                        num_Truck_Item[tt][item.idx] += 1\n",
    "                  \n",
    "                \n",
    "            Loaded2D = 0\n",
    "            Loaded2DUp = 0\n",
    "            for gi in dataO.GI_Truck[tt]:\n",
    "                AmountofGroup = 0\n",
    "                for ii in dataO.I_TruckGroupitems[tt, gi]:\n",
    "                    AmountofGroup += num_Truck_Item[tt][ii]\n",
    "                Loaded2D += dataO.givol2D_TruckGroupitemsNum[tt, gi, AmountofGroup]\n",
    "                Loaded2DUp += dataO.giVol2DUp_TruckGroupitemsNum[tt, gi, AmountofGroup]\n",
    "\n",
    "           # print(\"First tt: \" , tt, len(sol.Trucks[tt]))\n",
    "            Loaded2D = Loaded2D / (dataT.tvol2D[tt] * (len(sol.Trucks[tt]) - 1))   #Die ANzahl der Trucks im Nenner muss noch mit 1 subtrahiert werden, da wir schon ein Truck hinzugefügt haben, und ansonsten durch einen Truck zu viel teilen\n",
    "            Loaded3D = Loaded3D / (dataT.tvol3D[tt] * (len(sol.Trucks[tt]) - 1))   #Es kann niemals durch 0 geteilt werden, da wir nur die Trucks mit einem extra Truck betrachten\n",
    "            Loaded2DUp = Loaded2DUp / (dataT.tvol2D[tt] * (len(sol.Trucks[tt]) - 1))\n",
    "            LoadedM = LoadedM / (dataT.tm[tt] * (len(sol.Trucks[tt]) - 1)) \n",
    "            OldLimits = max(Loaded2D, Loaded3D, LoadedM, Loaded2DUp)\n",
    "            dataO.limit_Truck[tt] = min(OldLimits, dataO.limit_Truck[tt], dataP.fAPLNSTrucklimits)\n",
    "            \n",
    "    \n",
    "    for tt in TLNS:\n",
    "        dataO.limit_Truck[tt] -= dataP.fLNSReduction\n",
    "        \n",
    "    # Determine assignment from solution, presolve offsets for AP2 truck limit\n",
    "    IInSolTruck = {tt: set() for tt in T}\n",
    "    num_Truck = {tt: 0 for tt in T}\n",
    "    num_Truck_Item = {tt: {ii: 0 for ii in dataO.I_Truck[tt]} for tt in T}\n",
    "    \n",
    "    dataO.tOffset2D = {tt: 0 for tt in dataT.T}\n",
    "    dataO.tOffset2DUp = {tt: 0 for tt in dataT.T}\n",
    "    dataO.tOffset3D = {tt: 0 for tt in dataT.T}\n",
    "    dataO.tOffsetM = {tt: 0 for tt in dataT.T}\n",
    "    \n",
    "    # Track the number of items within truck as well as the used 2D-, 2DUp- and 3D-volume as well as the used weight \n",
    "    for tt in sol.Trucks:\n",
    "        if tt not in TLNS:\n",
    "            num_Truck[tt] = len(sol.Trucks[tt])\n",
    "            for truck in sol.Trucks[tt]:            \n",
    "                numItems_Groupitems = defaultdict(int)\n",
    "\n",
    "                for stack in truck.Stacks:\n",
    "                    dataO.tOffset2D[tt] += (stack.xe - stack.xo) * (stack.ye - stack.yo) / 1_000_000\n",
    "                    dataO.tOffset3D[tt] += (stack.xe - stack.xo) * (stack.ye - stack.yo) * stack.ze / 1_000_000_000\n",
    "                    \n",
    "                    for item in stack.Items:\n",
    "                        dataO.tOffsetM[tt] += dataI.im[item.idx]\n",
    "                        num_Truck_Item[tt][item.idx] += 1\n",
    "\n",
    "            \n",
    "            TwoDVol = 0\n",
    "            TwoDVolUp = 0\n",
    "            for gi in dataO.GI_Truck[tt]:\n",
    "                AmountofGroup = 0\n",
    "                for ii in dataO.I_TruckGroupitems[tt, gi]:\n",
    "                    AmountofGroup += num_Truck_Item[tt][ii]\n",
    "                TwoDVol += dataO.givol2D_TruckGroupitemsNum[tt, gi, AmountofGroup]\n",
    "                TwoDVolUp += dataO.giVol2DUp_TruckGroupitemsNum[tt, gi, AmountofGroup]\n",
    "            dataO.tOffset2D[tt] = TwoDVol\n",
    "            dataO.tOffset2DUp[tt] = TwoDVolUp\n",
    "\n",
    "            \n",
    "            # Set offset in relation to available truck volume and weight, i.e get the factor of usage\n",
    "            dataO.tOffset2D[tt] = dataO.tOffset2D[tt] / (dataT.tvol2D[tt] * len(sol.Trucks[tt]))\n",
    "            dataO.tOffset2DUp[tt] = dataO.tOffset2DUp[tt] / (dataT.tvol2D[tt] * len(sol.Trucks[tt]))\n",
    "            dataO.tOffset3D[tt] = dataO.tOffset3D[tt] / (dataT.tvol3D[tt] * len(sol.Trucks[tt]))\n",
    "            dataO.tOffsetM[tt] = dataO.tOffsetM[tt] / (dataT.tm[tt] * len(sol.Trucks[tt]))\n",
    "            \n",
    "\n",
    "\n",
    "            ###Masse würde ich hier auslasssen, da eher das Volumen Probleme bereitet\n",
    "            if max(dataO.tOffset2D[tt], dataO.tOffset2DUp[tt], dataO.tOffset3D[tt]) > dataP.fTFullthreshold:\n",
    "                TFull.append(tt)\n",
    "            else:\n",
    "                TFree.append(tt)\n",
    "                \n",
    "        \n",
    "    \n",
    "    ####Das hatten wir glaube ich noch vergessen zu füllen\n",
    "    for tt in sol.Trucks:\n",
    "        if tt in TLNS:\n",
    "            for truck in sol.Trucks[tt]:   \n",
    "                for stack in truck.Stacks:\n",
    "                    for item in stack.Items:\n",
    "                        num_Truck_Item[tt][item.idx] += 1           \n",
    "            \n",
    "    m = Model('Assignment Problem with step function')\n",
    "\n",
    "    # Variables\n",
    "    iota = tupledict()  # Number of item ii assigned to truck tt\n",
    "    ginu = tupledict()  # group of items active\n",
    "    tau = tupledict()  # Indicator if truck tt is used\n",
    "    theta = tupledict()  # Number of pseudo trucks used of truck tt\n",
    "    cT = tupledict()  # Transportation costs for truck tt\n",
    "    cI = tupledict()  # Inventory costs for truck tt\n",
    "    upsilon = m.addVars(TFull, vtype='B', name=f\"upsilon\")  # Indicator if further trucks are required in APLNS\n",
    "\n",
    "    for tt in T:\n",
    "        tau[tt] = m.addVar(vtype='B', name=f\"tau[{tt}]\")\n",
    "        theta[tt] = m.addVar(vtype='I', name=f\"theta[{tt}]\")\n",
    "        cT[tt] = m.addVar(vtype='C', name=f\"cT[{tt}]\")\n",
    "        cI[tt] = m.addVar(vtype='C', name=f\"cI[{tt}]\")\n",
    "\n",
    "        for ii in dataO.I_Truck[tt]:\n",
    "            iota[tt, ii] = m.addVar(vtype='I',ub=num_Item[ii], name=f\"iota[{tt},{ii}]\")\n",
    "  \n",
    "        for gi in dataO.GI_Truck[tt]:\n",
    "            for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1):\n",
    "                ginu[tt, gi, jj] = m.addVar(vtype='B', name=f\"ginu[{tt},{gi},{jj}]\") \n",
    "    \n",
    "    # Objective\n",
    "    m.setObjective(quicksum(dataT.tc[tt] * tau[tt] for tt in T)\n",
    "                   + quicksum(dataT.tcPseudo[tt]* theta[tt] for tt in T)\n",
    "                   + quicksum(dataO.ic_TruckItem[tt, ii]*iota[tt,ii] for tt in T for ii in dataO.I_Truck[tt])\n",
    "                   , GRB.MINIMIZE)\n",
    "    \n",
    "    #General constraints\n",
    "    for tt in T:\n",
    "        # Track costs for a truck\n",
    "        m.addConstr(dataT.tc[tt] * tau[tt] + dataT.tcPseudo[tt] * theta[tt]\n",
    "                    == cT[tt], name=f'TruckCosts[{tt}]')\n",
    "        m.addConstr(quicksum(dataO.ic_TruckItem[tt,ii] * iota[tt,ii] for ii in dataO.I_Truck[tt])\n",
    "                    == cI[tt], name=f'InventoryCosts[{tt}]')\n",
    "        \n",
    "        # 3d volume and weight limit for a truck\n",
    "        m.addConstr(quicksum(dataO.ivol3D_TruckItem[tt, ii] * iota[tt, ii] for ii in dataO.I_Truck[tt])\n",
    "                    <= dataO.limit_Truck[tt] * (dataT.tvol3D[tt] * (tau[tt] + theta[tt])), name=f\"Truck_vol3D[{tt}]\")\n",
    "                    #\n",
    "        m.addConstr(quicksum(dataI.im[ii] * iota[tt, ii] for ii in dataO.I_Truck[tt])\n",
    "                    <= dataO.limit_Truck[tt] * (dataT.tm[tt] * (tau[tt] + theta[tt])), name=f\"Truck_weight[{tt}]\")\n",
    "\n",
    "        \n",
    "        m.addConstr(100 * tau[tt] >= theta[tt])\n",
    "        \n",
    "        m.addConstr(tau[tt] <= quicksum(iota[tt, ii] for tt in dataO.T_Item[ii]))\n",
    "        \n",
    "\n",
    "    for ii in I:\n",
    "        # All items must be assigned to a truck\n",
    "        m.addConstr(quicksum(iota[tt, ii] for tt in dataO.T_Item[ii])\n",
    "                    == num_Item[ii], name=f'Item_loaded[{ii}]')\n",
    "\n",
    "\n",
    "    # Symmetrie breaking for trucks, both truck are similar and the cheaper truck is used first\n",
    "    for tt1, tt2 in dataO.identicalTrucks:\n",
    "        m.addConstr(tau[tt2]\n",
    "                    <= tau[tt1], name=f\"Truck_symmetry[{tt1},{tt2}]\")\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Ginu mit iota verknüpfen\n",
    "    for tt in T:\n",
    "        for gi in dataO.GI_Truck[tt]:\n",
    "            m.addConstr(quicksum(ginu[tt, gi, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                        == 1, name=f\"GroupItemActive[{tt},{gi}]\")\n",
    "            m.addConstr(quicksum(iota[tt, ii] for ii in dataO.I_TruckGroupitems[tt, gi])\n",
    "                        == quicksum(jj * ginu[tt, gi, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1)), name=f\"GroupItemNumber[{tt},{gi}]\")\n",
    "            \n",
    "\n",
    "    for tt, II in dataO.I_Truck.items():\n",
    "        if II:\n",
    "                      \n",
    "            \n",
    "            #2D Volumen Constraint\n",
    "            m.addConstr(quicksum(dataO.givol2D_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for gi in dataO.GI_Truck[tt] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                        <= dataO.limit_Truck[tt] * dataT.tvol2D[tt] * (tau[tt] + theta[tt]), name=f\"Truck_vol2D[{tt}]\")            \n",
    "            \n",
    "            \n",
    "            #Nehme ich hier raus, weil sonst Probleme mit den Offsets entstehen könnten\n",
    "            #2D Volumen UP Constraint -> Redundant mit oberere Constraint\n",
    "            m.addConstr(quicksum(dataO.giVol2DUp_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for gi in dataO.GI_Truck[tt] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                        <= dataO.limit_Truck[tt] * dataT.tvol2D[tt] * (tau[tt] + theta[tt]), name=f\"Truck_vol2DUP[{tt}]\")            \n",
    "            \n",
    "            #Einfache Längenrestriktion pro Itemgruppe\n",
    "            for gi in dataO.GI_Truck[tt]:\n",
    "                m.addConstr(quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                            <= dataT.tl[tt] * (tau[tt] + theta[tt]), name=f\"GILength_Truck[{tt}, {gi}]\")              \n",
    "            \n",
    "            #Einfache Längenrestriktion über alle Itemgruppen die nicht hintereinander gestellt werden können\n",
    "            m.addConstr(quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for gi in dataO.GIWidthGroup_Truck[tt] for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                        <= dataT.tl[tt] * (tau[tt] + theta[tt]), name=f\"GIMultiGroupsLength_Truck[{tt}]\")             \n",
    "            \n",
    "            #Komplexere Längenrestriktion für Itempaare die nicht hintereinander gepackt werden dürfen\n",
    "            for gi1, gi2 in dataO.GIWidthPair_Truck[tt]:\n",
    "                m.addConstr(quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi1, jj] * ginu[tt, gi1, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi1]+1))\n",
    "                            + quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi2, jj] * ginu[tt, gi2, jj] for jj in range(dataO.numItems_TruckGroupitems[tt, gi2]+1))\n",
    "                            <= dataT.tl[tt] * (tau[tt] + theta[tt]), name=f\"GIWidthPair_Truck[{tt},{gi1},{gi2}]\")\n",
    "                \n",
    "            #Supergroup Längenconstraints\n",
    "            for supergroups in dataO.GIWidthSuperGroup_Truck[tt]:\n",
    "                m.addConstr(quicksum(dataO.gilGroup_TruckGroupitemsNum[tt, gi, jj] * ginu[tt, gi, jj] for gi in supergroups for jj in range(dataO.numItems_TruckGroupitems[tt, gi]+1))\n",
    "                            <= dataT.tl[tt] * (tau[tt] + theta[tt]), name=f\"Supergroup[{tt}, {supergroups}]\")\n",
    "\n",
    "                \n",
    "    if sum([len(sol.Trucks[tt]) for tt in sol.Trucks]) > 100:\n",
    "        # Fix solution from packing\n",
    "        for tt in T:\n",
    "            if tt not in TLNS:\n",
    "                for ii, num in num_Truck_Item[tt].items():\n",
    "                    m.addConstr(iota[tt, ii]\n",
    "                                >= num, name=f\"fixItem[{tt},{ii}]\")\n",
    "  #  else:\n",
    "  #      print(\"Kein Item wird im APLNS fixiert\")\n",
    "\n",
    "        \n",
    "\n",
    "    # Start optimization\n",
    "  #  m.setParam('OutputFlag', 0)\n",
    "    m.setParam('Threads', 8)\n",
    "    m._limitTime = limitTime\n",
    "    m._solFound = False\n",
    "    m._limitTimeNotReached = True\n",
    "    m._solFoundTime = time.perf_counter() + dataP.tROADEF\n",
    "    m.optimize(softAPLNS)\n",
    "    \n",
    "    \n",
    "    if m.status == 3:\n",
    "        m.computeIIS()\n",
    "        m.write(\"model.ilp\")\n",
    "        exit(\"FAIL\")\n",
    "\n",
    "    assignmentLNS = AP1Solution()\n",
    "\n",
    "            \n",
    "    for tt in T:\n",
    "        assignmentLNS.numItemsPerTruck[tt] = 0\n",
    "        \n",
    "        # Check if trucks need to be repacked\n",
    "        # Could/should the number of items not be lower for these trucks so we have to actual check if the exact same items ar in or not.\n",
    "        repackTruck = False\n",
    "\n",
    "        # Check if items number that are packed this time match items numbers of previous solution\n",
    "        for ii in dataO.I_Truck[tt]:\n",
    "            if iota[tt, ii].X != num_Truck_Item[tt][ii]:\n",
    "                repackTruck = True\n",
    "                break\n",
    "\n",
    "        if repackTruck and tau[tt].X > 0.5:\n",
    "            assignmentLNS.TRepack.append(tt)\n",
    "                \n",
    "        assignmentLNS.num_Truck[tt] = int(round(tau[tt].X, 0)) + int(round(theta[tt].X, 0))\n",
    "        assignmentLNS.I_Truck[tt] = []\n",
    "        assignmentLNS.num_Truck_Item[tt] = {}\n",
    "\n",
    "        for ii in dataO.I_Truck[tt]:\n",
    "            if iota[tt, ii].X > 0.5:\n",
    "                assignmentLNS.I_Truck[tt].append(ii)\n",
    "                assignmentLNS.num_Truck_Item[tt][ii] = int(round(iota[tt, ii].X, 0))\n",
    "                assignmentLNS.numItemsPerTruck[tt] += assignmentLNS.num_Truck_Item[tt][ii]\n",
    "        \n",
    "        #Hier Truck aus Lösung löschen, falls Truck nach APLNS nicht mehr genutzt wird\n",
    "        if tau[tt].X < 0.5 and tt in sol.Trucks:\n",
    "            del sol.Trucks[tt]\n",
    "                \n",
    "            \n",
    "\n",
    "    for tt in assignmentLNS.TRepack:\n",
    "        assignmentLNS.tcTransport[tt] = cT[tt].X\n",
    "        assignmentLNS.tcInventory[tt] = cI[tt].X\n",
    "         \n",
    "    assignmentLNS.info[\"APObj\"] = round(m.ObjVal, 2)\n",
    "    assignmentLNS.info[\"APcT\"] = round(sum([cT[tt].X for tt in dataT.T]), 2)\n",
    "    assignmentLNS.info[\"APcI\"] = round(sum([cI[tt].X for tt in dataT.T]), 2)\n",
    "    assignmentLNS.info[\"APGAP\"] = round(m.MIPGap * 100, 2)\n",
    "    assignmentLNS.info[\"APrt\"] = m.Runtime\n",
    "\n",
    "    print(f\"APLNS requires {sum([assignmentLNS.num_Truck[tt] for tt in assignmentLNS.TRepack])} trucks to repack. With transportation costs {sum([dataT.tc[tt] * tau[tt].X for tt in T]) + sum([dataT.tcPseudo[tt] * theta[tt].X for tt in T])} and inventory costs {sum([dataO.ic_TruckItem[tt, ii]*iota[tt,ii].X for tt in T for ii in dataO.I_Truck[tt]])}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    return assignmentLNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095d801",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d03028e",
   "metadata": {},
   "source": [
    "## Solution object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daf6a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPSolution(object):\n",
    "    def __init__(self):\n",
    "        self.S = []\n",
    "        self.I_Stack = defaultdict(list)  # Key stack -> list of items, ordered from bottom to top\n",
    "        \n",
    "        self.sl = {}\n",
    "        self.sw = {}\n",
    "        self.sh = {}\n",
    "        self.svol2D = {}\n",
    "        self.svol3D = {}\n",
    "        self.sm = {}\n",
    "        self.so = {}\n",
    "        self.su = {}\n",
    "        self.sk = {}\n",
    "        self.sg = {}\n",
    "        self.sMulti = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2c486",
   "metadata": {},
   "source": [
    "## Heuristic SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "293231d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_SP(dataT, dataI, IHeuristic, num_Item, tt, I_StackableCode, S_StackableCode, StackableCode_Item):\n",
    "    \n",
    "    numStrategies = 3\n",
    "    Items_Stack = {}\n",
    "    num_StackItem = {}\n",
    "    \n",
    "    for pos in range(numStrategies):  # Range specifies different sorting options\n",
    "        if pos == 0:\n",
    "            Items = sorted(IHeuristic, key=lambda x: dataI.ism[x])\n",
    "        elif pos == 1:\n",
    "            Items = sorted(IHeuristic, key=lambda x: (dataI.ism[x], dataI.ih[x] - dataI.ihn[x]))\n",
    "        elif pos == 2:   \n",
    "            Items = sorted(IHeuristic, key=lambda x: (dataI.ism[x], dataI.ih[x] - dataI.ihn[x], dataI.im[x]))\n",
    "\n",
    "\n",
    "        # Solution\n",
    "        Items_Stack[pos] = {ss: [] for sc in I_StackableCode for ss in S_StackableCode[sc]}  # Key stack, value list of items,,order of list represents stacking, i.e. first item bottom item\n",
    "        num_StackItem[pos] = defaultdict(int)\n",
    "\n",
    "        # Helpers\n",
    "        minAddedHeight = min([dataI.ih[ii] - dataI.ihn[ii] for ii in IHeuristic])\n",
    "        minAddedWeight = min([dataI.im[ii] for ii in IHeuristic])\n",
    "        open_Stack = {ss: True for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        numItems_Stack = {ss: 0 for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        height_Stack = {ss: 0 for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        weight_Stack = {ss: 0 for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        plantDock_Stack = {ss: None for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        numPacked_Item = {ii: 0 for ii in Items}\n",
    "        orientations_Stack = {ss: set() for sc in I_StackableCode for ss in S_StackableCode[sc]} \n",
    "\n",
    "        while Items:\n",
    "            ii = Items.pop()\n",
    "            for ss in S_StackableCode[StackableCode_Item[ii]]:\n",
    "                if open_Stack[ss]:\n",
    "                    for jj in range(num_Item[ii] - numPacked_Item[ii]):\n",
    "                        # Check plant dock\n",
    "                        if numItems_Stack[ss] == 0 or dataI.ig[ii] == plantDock_Stack[ss]:\n",
    "                            # Check height\n",
    "                            if height_Stack[ss] + (dataI.ih[ii] - dataI.ihn[ii]) <= dataT.th[tt]:\n",
    "                                # Check truck density\n",
    "                                if (weight_Stack[ss] + dataI.im[ii]) / dataI.ivol2D[ii] <= dataT.tem[tt]:\n",
    "                                    # CHeck orientation:\n",
    "                                    if (len(orientations_Stack[ss]) > 0 and (dataI.io[ii] in orientations_Stack[ss] or dataI.io[ii] == \"none\")) or len(orientations_Stack[ss]) == 0:\n",
    "                                        # Check weight on bottom item\n",
    "                                        if dataI.ism[ii] > numItems_Stack[ss]:\n",
    "                                            if numItems_Stack[ss] == 0 or weight_Stack[ss] + dataI.im[ii] - dataI.im[Items_Stack[pos][ss][0]] <= dataT.tmm[tt, dataI.ir[Items_Stack[pos][ss][0]]]:\n",
    "                                                if jj == 0:\n",
    "                                                    Items_Stack[pos][ss].append(ii)\n",
    "\n",
    "                                                if numItems_Stack[ss] == 0:\n",
    "                                                    height_Stack[ss] += dataI.ih[ii]\n",
    "                                                    plantDock_Stack[ss] = dataI.ig[ii]\n",
    "                                                else:\n",
    "                                                    height_Stack[ss] += dataI.ih[ii] - dataI.ihn[ii]\n",
    "\n",
    "                                                numItems_Stack[ss] += 1\n",
    "                                                num_StackItem[pos][ss, ii] += 1\n",
    "                                                numPacked_Item[ii] += 1\n",
    "                                                weight_Stack[ss] += dataI.im[ii]\n",
    "                                                orientations_Stack[ss].add(dataI.io[ii])\n",
    "\n",
    "                                              #  if dataI.ism[Items_Stack[pos][ss][0]] == numItems_Stack[ss] \\\n",
    "                                                if not all([dataI.ism[iii] > numItems_Stack[ss] for iii in Items_Stack[pos][ss]]) \\\n",
    "                                                or height_Stack[ss] + minAddedHeight > dataT.th[tt] \\\n",
    "                                                or (weight_Stack[ss] + minAddedWeight) / dataI.ivol2D[ii] > dataT.tem[tt] \\\n",
    "                                                or weight_Stack[ss] + minAddedWeight - dataI.im[Items_Stack[pos][ss][0]] > dataT.tmm[tt, dataI.ir[Items_Stack[pos][ss][0]]]:\n",
    "                                                    open_Stack[ss] = False\n",
    "                                                    break\n",
    "\n",
    "                                            \n",
    "    numStacks = [sum([1 for _, I in Items_Stack[pos].items() if I]) for pos in range(numStrategies)]\n",
    "    minStack = np.argmin(numStacks)\n",
    "\n",
    "    return Items_Stack[minStack], num_StackItem[minStack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e928fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_SP2(dataT, dataI, IHeuristic, tt, I_StackableCode, S_StackableCode, StackableCode_Item):\n",
    "    \n",
    "    \n",
    "    \n",
    "    numStrategies = 3\n",
    "    Items_Stack = {}\n",
    "    num_StackItem = {}\n",
    "\n",
    "    for pos in range(numStrategies):  # Range specifies different sorting options\n",
    "        if pos == 0:\n",
    "            Items = sorted(IHeuristic, key=lambda x: dataI.ism[x])\n",
    "        elif pos == 1:\n",
    "            Items = sorted(IHeuristic, key=lambda x: (dataI.ism[x], dataI.ih[x] - dataI.ihn[x]))\n",
    "        elif pos == 2:   \n",
    "            Items = sorted(IHeuristic, key=lambda x: (dataI.ism[x], dataI.ih[x] - dataI.ihn[x], dataI.im[x]))\n",
    "\n",
    "\n",
    "        # Solution\n",
    "        Items_Stack[pos] = {ss: [] for sc in I_StackableCode for ss in S_StackableCode[sc]}  # Key stack, value list of items,,order of list represents stacking, i.e. first item bottom item\n",
    "        num_StackItem[pos] = defaultdict(int)\n",
    "\n",
    "        # Helpers\n",
    "        minAddedHeight = min([dataI.ih[ii] - dataI.ihn[ii] for ii in IHeuristic])\n",
    "        minAddedWeight = min([dataI.im[ii] for ii in IHeuristic])\n",
    "        open_Stack = {ss: True for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        numItems_Stack = {ss: 0 for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        height_Stack = {ss: 0 for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        weight_Stack = {ss: 0 for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        plantDock_Stack = {ss: None for sc in I_StackableCode for ss in S_StackableCode[sc]}\n",
    "        numPacked_Item = {ii: 0 for ii in Items}\n",
    "\n",
    "        while Items:\n",
    "            ii = Items.pop()\n",
    "            for ss in S_StackableCode[StackableCode_Item[ii]]:\n",
    "                if open_Stack[ss]:\n",
    "                    # Check plant dock\n",
    "                    if numItems_Stack[ss] == 0 or dataI.ig[ii] == plantDock_Stack[ss]:\n",
    "                        # Check height\n",
    "                        if height_Stack[ss] + (dataI.ih[ii] - dataI.ihn[ii]) <= dataT.th[tt]:\n",
    "                            # Check truck density\n",
    "                            if (weight_Stack[ss] + dataI.im[ii]) / dataI.ivol2D[ii] <= dataT.tem[tt]:\n",
    "                                # Check weight on bottom item\n",
    "                                if numItems_Stack[ss] == 0 or weight_Stack[ss] + dataI.im[ii] - dataI.im[Items_Stack[pos][ss][0]] <= dataT.tmm[tt, dataI.ir[Items_Stack[pos][ss][0]]]:\n",
    "                                    Items_Stack[pos][ss].append(ii)\n",
    "                                    \n",
    "                                    if numItems_Stack[ss] == 0:\n",
    "                                        height_Stack[ss] += dataI.ih[ii]\n",
    "                                        plantDock_Stack[ss] = dataI.ig[ii]\n",
    "                                    else:\n",
    "                                        height_Stack[ss] += dataI.ih[ii] - dataI.ihn[ii]\n",
    "\n",
    "                                    numItems_Stack[ss] += 1\n",
    "                                    num_StackItem[pos][ss, ii] += 1\n",
    "                                    weight_Stack[ss] += dataI.im[ii]\n",
    "\n",
    "                                    if dataI.ism[Items_Stack[pos][ss][0]] == numItems_Stack[ss] \\\n",
    "                                    or height_Stack[ss] + minAddedHeight > dataT.th[tt] \\\n",
    "                                    or (weight_Stack[ss] + minAddedWeight) / dataI.ivol2D[ii] > dataT.tem[tt] \\\n",
    "                                    or weight_Stack[ss] + minAddedWeight - dataI.im[Items_Stack[pos][ss][0]] > dataT.tmm[tt, dataI.ir[Items_Stack[pos][ss][0]]]:\n",
    "                                        open_Stack[ss] = False\n",
    "                                    \n",
    "                                    break\n",
    "\n",
    "    numStacks = [sum([1 for _, I in Items_Stack[pos].items() if I]) for pos in range(numStrategies)]\n",
    "    minStack = np.argmin(numStacks)\n",
    "    return Items_Stack[minStack], num_StackItem[minStack]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f3a45e",
   "metadata": {},
   "source": [
    "## Model SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a5f51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeStop(model, where):\n",
    "    if where == GRB.Callback.MIP:\n",
    "        runtime = model.cbGet(GRB.Callback.RUNTIME)\n",
    "        count = model.cbGet(GRB.Callback.MIP_SOLCNT)\n",
    "\n",
    "        if count > 0 and runtime > model._timeLimit:\n",
    "            model.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46d7aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_SP(dataT, dataI, stacking, tt, num_Item, timeLimit):\n",
    "    \n",
    "    startTime = time.perf_counter()\n",
    "    \n",
    "  #  print(\"tt = \" , tt)\n",
    "  #  print(\"num_Item = \" , num_Item)\n",
    "  #  print(\"timeLimit = \" , timeLimit)\n",
    "    \n",
    "    \n",
    "    # Stackable code (sc) is defined by stackability code, supplier and supplier loading dock\n",
    "    # Additional Sets \n",
    "    Items = sorted(num_Item)\n",
    "    IHeuristic = []\n",
    "    S = []  # Set of possible stacks needed for remaining items\n",
    "    S_StackableCode = {}  # Set of stacks covering sc \n",
    "    S_Stackability = defaultdict(list)  # Set of stacks covering stackability code\n",
    "    S_SupplierDock = defaultdict(list)  # Set of stacks covering supplier and supllier dock\n",
    "    I_StackableCode = {}  # Set of items grouped by sc\n",
    "    StackableCode_Item = {}  # Sc of item\n",
    "    I_StackableCodePlantDock = {}  # Set of items grouped by sc and plant dock\n",
    "    G_StackableCode = {}  # Set of plant docks covered by sc\n",
    "    IIncompatible_StackableCode = {}  # Set of item pairs that cannot be paired together grouped by sc \n",
    "    \n",
    "    # Additional paramters\n",
    "    scem = {}  # Max density of a stack belonging to stackable code\n",
    "    scsm = {}  # Max stackability of all items bekĺonging to stackable code\n",
    "    sc = {}  # Max nested height of all items bekĺonging to stackable code\n",
    "    bottom_ItemItem = {}  # 1, iff item 1 will be placed below item 2 (items have different plant dock) key: item pair\n",
    "    \n",
    "    # Find items that cannot be stacked and group remaining items by their sc\n",
    "    for ii in Items:\n",
    "        if dataI.ism[ii] == 1:\n",
    "            for jj in range(1, num_Item[ii] + 1):\n",
    "                ss = len(stacking.S)\n",
    "                stacking.S.append(ss)\n",
    "                stacking.I_Stack[ss] = [ii]\n",
    "                stacking.sl[ss] = dataI.il[ii]\n",
    "                stacking.sw[ss] = dataI.iw[ii]\n",
    "                stacking.sh[ss] = dataI.ih[ii]\n",
    "                stacking.svol2D[ss] = dataI.ivol2D[ii]\n",
    "                stacking.svol3D[ss] = dataI.ivol3DO[ii]\n",
    "                stacking.sm[ss] = dataI.im[ii]\n",
    "                stacking.su[ss] = dataI.iu[ii]\n",
    "                stacking.sk[ss] = dataI.ik[ii]\n",
    "                stacking.sg[ss] = [dataI.ig[ii]]\n",
    "                stacking.sMulti[ss] = 0 \n",
    "                stacking.so[ss] = dataI.io[ii]\n",
    "        else:\n",
    "            sc = (dataI.ist[ii], dataI.iu[ii], dataI.ik[ii])\n",
    "            StackableCode_Item[ii] = sc\n",
    "            IHeuristic.append(ii)\n",
    "            \n",
    "            if sc in I_StackableCode:\n",
    "                I_StackableCode[sc].append(ii) #TODOcheck defaultdict\n",
    "            else:\n",
    "                I_StackableCode[sc] = [ii]\n",
    "                \n",
    "    # Presolve\n",
    "    for sc, I in I_StackableCode.items():\n",
    "        scem[sc] = dataT.tem[tt] * dataI.ivol2D[I[0]]\n",
    "        scsm[sc] = max([dataI.ism[ii] for ii in I])\n",
    "        stackability, uu, kk = sc  # stackability code, supplier, supplier dock\n",
    "        \n",
    "        numRequiredStacks = 0\n",
    "        for ii in I:\n",
    "                case1 = math.ceil(num_Item[ii] / math.floor(dataT.th[tt] / dataI.ih[ii]))  # Number of required stacks based on item height (ignore nested heigt)\n",
    "                case2 = math.ceil(num_Item[ii] / math.floor(1 + dataT.tmm[tt, dataI.ir[ii]] / dataI.im[ii]))  # Number of required stacks based on weight on bottom item\n",
    "                case3 = math.ceil(num_Item[ii] / math.floor(scem[sc] / dataI.im[ii]))  # Number of required stacks based on weight on trailer\n",
    "                case4 = math.ceil(num_Item[ii] / dataI.ism[ii])  # Number of required stacks based on max stackability\n",
    "                numRequiredStacks += max(case1, case2, case3, case4)\n",
    "        numRequiredStacks = math.ceil(numRequiredStacks * 1.1)  # Add a buffer of 10%\n",
    "\n",
    "        # Create new stacks and add stacks to necessarry dictionarys\n",
    "        S_required = list(range(len(S), len(S) + numRequiredStacks))\n",
    "        \n",
    "        S_StackableCode[sc] = S_required\n",
    "        S.extend(list(S_required))\n",
    "        S_Stackability[stackability].extend(list(S_required))\n",
    "        S_SupplierDock[uu, kk].extend(list(S_required)) #TODOcheck required?\n",
    "\n",
    "        G_StackableCode[sc] = list(set([dataI.ig[ii] for ii in I]))\n",
    "        I_StackableCodePlantDock.update({(sc, gg): [ii for ii in I if dataI.ig[ii] == gg] for gg in G_StackableCode[sc]})\n",
    "        IIncompatible_StackableCode[sc] = set()\n",
    "                 \n",
    "        # Find relations between two items\n",
    "        if len(I) > 1:\n",
    "            # Find item pairs that cannot be stacked\n",
    "            for ii1, ii2 in itertools.combinations(I, 2):\n",
    "                # Different orientation\n",
    "                if dataI.io[ii1] != dataI.io[ii2] and dataI.io[ii1] != \"none\" and dataI.io[ii2] != \"none\":\n",
    "                    IIncompatible_StackableCode[sc].add((ii1, ii2))\n",
    "                # Check if multi stacks are allowed (== 1)\n",
    "                if dataT.tf[tt] == 1:\n",
    "                    # Ban combination if difference in dock order greater 1\n",
    "                    if abs(dataT.tge[tt, dataI.ip[ii1], dataI.ig[ii1]] - dataT.tge[tt, dataI.ip[ii2], dataI.ig[ii2]]) > 1:\n",
    "                        IIncompatible_StackableCode[sc].add((ii1, ii2))\n",
    "                else:\n",
    "                    # Ban combination if different docks\n",
    "                    if dataI.ig[ii1] != dataI.ig[ii2]:\n",
    "                        IIncompatible_StackableCode[sc].add((ii1, ii2))\n",
    "            # Check for item pairs if first item can be placed at bottom\n",
    "            for ii1, ii2 in itertools.permutations(I, 2):\n",
    "                if dataI.ig[ii1] != dataI.ig[ii2]:\n",
    "                    if dataT.tge[tt, dataT.tp[tt], dataI.ig[ii1]] <= dataT.tge[tt, dataT.tp[tt], dataI.ig[ii2]]:\n",
    "                        bottom_ItemItem[ii1, ii2] = 1\n",
    "                    else:\n",
    "                        bottom_ItemItem[ii1, ii2] = 0    \n",
    "    \n",
    "    for sc in IIncompatible_StackableCode:\n",
    "        IIncompatible_StackableCode[sc] = sorted(IIncompatible_StackableCode[sc])             \n",
    "    \n",
    "    m = Model('Stacking Problem')\n",
    "\n",
    "    # Variables\n",
    "    iota = tupledict()  # Number of item in stack, key: (s, i)\n",
    "    ikappa = tupledict()  # Item in Stack, key: (s, i)\n",
    "    ilambda = tupledict()  # Item at bottom in stack, key: (s, i)\n",
    "\n",
    "    sigma = tupledict()  # Stack used, key: s\n",
    "    pi = tupledict()  # Plant dock in stack, key: (s, g)\n",
    "    phi = tupledict()  # Items in stack go to two different plant docks, key: s\n",
    "\n",
    "    \n",
    "    for sc, I in I_StackableCode.items():\n",
    "        for ss in S_StackableCode[sc]:\n",
    "            for ii in I:\n",
    "                iota[ss, ii] = m.addVar(vtype='I', ub=num_Item[ii], name=f\"iota[{ss},{ii}]\")\n",
    "                ikappa[ss, ii] = m.addVar(vtype='B', name=f\"ikappa[{ss},{ii}]\")\n",
    "                ilambda[ss, ii] = m.addVar(vtype='B', name=f\"ilambda[{ss},{ii}]\")\n",
    "\n",
    "            sigma[ss] = m.addVar(vtype='B', name=f\"sigma[{ss}]\")\n",
    "            phi[ss] = m.addVar(vtype='B', name=f\"phi[{ss}]\")\n",
    "\n",
    "            for gg in G_StackableCode[sc]:\n",
    "                pi[ss, gg] = m.addVar(vtype='B', name=f\"pi[{ss},{gg}]\")\n",
    "\n",
    "                \n",
    "    if IHeuristic:        \n",
    "        # Objective: Minimize number of used stacks\n",
    "        m.setObjective(sigma.sum(), GRB.MINIMIZE)\n",
    "\n",
    "        # Constraints\n",
    "        for sc, I in I_StackableCode.items():\n",
    "            for ss in S_StackableCode[sc]:\n",
    "                # Constraints S1: Items to check already have the same stackability code, supplier and supplier dock\n",
    "\n",
    "                # Constraints S2/S3/S4: Forbid items with different dock order or distance between dock order greater 1 or different orientation in the same stack\n",
    "                for ii1, ii2 in IIncompatible_StackableCode[sc]:\n",
    "                    m.addConstr(ikappa[ss, ii1] + ikappa[ss, ii2]\n",
    "                                <= 1, name=f\"IIncompatible(S2/S3/S4)[{ss},{ii1},{ii2}]\")\n",
    "\n",
    "                # Constraints S3: For consecutive part see S2\n",
    "                # Max two different dock orders in Stack\n",
    "                m.addConstr(phi[ss]\n",
    "                            <= sigma[ss], name=f\"MultiStackOnlyIfStack(S3)[{ss},{ii}]\")\n",
    "\n",
    "                for gg in G_StackableCode[sc]:\n",
    "                    m.addConstr(pi[ss, gg]\n",
    "                                <= sigma[ss], name=f\"DockInStackOnlyIfStack(S3)[{ss},{ii}]\")\n",
    "                    m.addConstr(pi[ss, gg]\n",
    "                                <= quicksum(ikappa[ss, ii] for ii in I_StackableCodePlantDock[sc, gg]), name=f\"DockInStackOnlyIfItem(S3)[{ss},{ii}]\")\n",
    "\n",
    "                for ii in I:\n",
    "                    m.addConstr(ikappa[ss, ii]\n",
    "                                <= pi[ss, dataI.ig[ii]], name=f\"ItemInStackOnlyIfDock(S3)[{ss},{ii}]\")\n",
    "\n",
    "                if dataT.tf[tt] == 1:\n",
    "                    m.addConstr(sigma[ss] + phi[ss]\n",
    "                                == pi.sum(ss, '*'), name=f\"MultiStackOn(S3){ss}]\")\n",
    "                    m.addConstr(phi[ss]\n",
    "                                    == 0, name=f\"MultiStackOff(S3){ss}]\")                    \n",
    "                else:\n",
    "                    m.addConstr(pi.sum(ss, '*')\n",
    "                                == sigma[ss], name=f\"OneDockinStackIfStack(S3)[{ss}]\")\n",
    "                    m.addConstr(phi[ss]\n",
    "                                    == 0, name=f\"MultiStackOff(S3){ss}]\")\n",
    "\n",
    "        # Constraints S4: See S2\n",
    "\n",
    "        for sc, I in I_StackableCode.items():\n",
    "            for ss in S_StackableCode[sc]:\n",
    "                # Constraints S5: Weight on bottom item\n",
    "                m.addConstr(quicksum(ilambda[ss, ii] for ii in I)\n",
    "                            == sigma[ss], name=f\"ExactlyOneBottom(S5)[{ss}]\")\n",
    "                for ii1 in I:\n",
    "                    m.addConstr(ilambda[ss, ii1]\n",
    "                                <= ikappa[ss, ii1], name=f\"OnlyBottomIfInStack(S5)[{ss},{ii1}]\")\n",
    "                    m.addConstr(quicksum(dataI.im[ii2] * iota[ss, ii2] for ii2 in I) - dataI.im[ii1] * ilambda[ss, ii1]\n",
    "                                <= dataT.tmm[tt, dataI.ir[ii1]] * ilambda[ss, ii1] + scem[sc] * (1 - ilambda[ss, ii1]), name=f\"MaxBottomWeight(S5)[{ss},{ii1}]\")\n",
    "\n",
    "                # Constraints S6: Check for each item in stack if max stackability not violated\n",
    "                for ii1 in I:\n",
    "                    m.addConstr(quicksum(iota[ss, ii2] for ii2 in I)\n",
    "                                <= dataI.ism[ii1] * ikappa[ss, ii1] + scsm[sc] * (1 - ikappa[ss, ii1]), name=f\"MaxStackability(S6)[{ss},{ii1}]\")\n",
    "\n",
    "                # Constraints S7\n",
    "                m.addConstr(quicksum(dataI.im[ii] * iota[ss, ii] for ii in I)\n",
    "                            <= scem[sc], name=f\"StackDensity(S7)[{ss}]\")\n",
    "\n",
    "        # Additional constraints\n",
    "        for sc, I in I_StackableCode.items():\n",
    "            for ss in S_StackableCode[sc]:\n",
    "                # Stack height\n",
    "                m.addConstr(quicksum((dataI.ih[ii] - dataI.ihn[ii]) * iota[ss, ii] +  dataI.ihn[ii] * ilambda[ss, ii] for ii in I)\n",
    "                            <= dataT.th[tt] * sigma[ss], name=f\"StackHeight[{ss}]\")\n",
    "\n",
    "                for ii in I:\n",
    "                    # Max number of item in stack based on stackability of item\n",
    "                    m.addConstr(iota[ss, ii]\n",
    "                                <= dataI.ism[ii] * ikappa[ss, ii], name=f\"MaxStackabilityItem1[{ss}]\")\n",
    "                    m.addConstr(ikappa[ss, ii]\n",
    "                                <= iota[ss, ii], name=f\"MaxStackabilityItem2[{ss}]\")\n",
    "\n",
    "                # Bottom relation between two items\n",
    "                for ii1, ii2 in itertools.permutations(I, 2):\n",
    "                    if dataI.ig[ii1] != dataI.ig[ii2]:\n",
    "                        m.addConstr(ilambda[ss, ii1]\n",
    "                                    <= bottom_ItemItem[ii1, ii2] + 2 - ikappa[ss, ii1] - ikappa[ss, ii2])\n",
    "                        m.addConstr(ilambda[ss, ii2]\n",
    "                                    <= bottom_ItemItem[ii2, ii1] + 2 - ikappa[ss, ii1] - ikappa[ss, ii2])\n",
    "\n",
    "            # Symmetry breaking stacks\n",
    "            for ss1, ss2 in itertools.combinations(S_StackableCode[sc], 2):\n",
    "                m.addConstr(sigma[ss2]\n",
    "                            <= sigma[ss1], name=f'SymmetryBreakingStacks[{ss1},{ss2}]')\n",
    "\n",
    "            # All items must be assigned to a stack\n",
    "            for ii in I:\n",
    "                m.addConstr(iota.sum('*', ii)\n",
    "                            == num_Item[ii], name=f\"AllItemsInStack[{ii}]\")\n",
    "\n",
    "        # Cases that cut off optimal solution                        \n",
    "        # Each stackability code can only have one multi stack\n",
    "        for stackability, S in S_Stackability.items():\n",
    "            m.addConstr(quicksum(phi[ss] for ss in S) <= 1 , name=f\"NumStacksDifferentDocks[stackability]\")  \n",
    "\n",
    "        Items_Stack, num_StackItem = heuristic_SP(dataT, dataI, IHeuristic, num_Item, tt, I_StackableCode, S_StackableCode, StackableCode_Item)\n",
    "        \n",
    "        \n",
    "        \n",
    "        fixedConstrs = []\n",
    "        for ss, I in Items_Stack.items():\n",
    "            if I:\n",
    "                fixedConstrs.append(m.addConstr(sigma[ss] == 1))\n",
    "                fixedConstrs.append(m.addConstr(ilambda[ss, I[0]] == 1))\n",
    "\n",
    "                for ii in I:\n",
    "                    fixedConstrs.append(m.addConstr(ikappa[ss, ii] == 1))\n",
    "                    fixedConstrs.append(m.addConstr(iota[ss, ii] == num_StackItem[ss, ii]))\n",
    "\n",
    "        # Start optimization                             \n",
    "        m.setParam('OutputFlag', 0)\n",
    "        m.setParam('Threads', 8)\n",
    "        m.optimize()\n",
    "        \n",
    "        if (time.perf_counter() - startTime) < timeLimit:\n",
    "            \n",
    "            for constr in fixedConstrs:\n",
    "                m.remove(constr)\n",
    "\n",
    "            m._timeLimit = timeLimit - (time.perf_counter() - startTime)\n",
    "            m.optimize(timeStop)\n",
    "\n",
    "        if m.status == 3:\n",
    "            m.computeIIS()\n",
    "            m.write(\"model.ilp\")\n",
    "            exit(\"FAIL\")  \n",
    "            \n",
    "        for sc, I in I_StackableCode.items():\n",
    "            for ssIdx in S_StackableCode[sc]:\n",
    "                if sigma[ssIdx].X > 0.5:\n",
    "                    ss = len(stacking.S)\n",
    "                    stacking.S.append(ss)\n",
    "                    stacking.I_Stack[ss] = []\n",
    "\n",
    "                    bottomItem = None\n",
    "\n",
    "                    for ii in I:\n",
    "                        if ilambda[ssIdx, ii].X > 0.5:\n",
    "                            bottomItem = ii\n",
    "\n",
    "                        if iota[ssIdx, ii].X > 0.5:\n",
    "                            for jj in range(1, 1 + int(round(iota[ssIdx, ii].X, 0))):\n",
    "                                stacking.I_Stack[ss].append(ii)\n",
    "\n",
    "                    stacking.I_Stack[ss].sort(key=lambda x: dataT.tge[tt, dataT.tp[tt], dataI.ig[ii]])\n",
    "\n",
    "                    if bottomItem != stacking.I_Stack[ss][0]:                 \n",
    "                        posB = stacking.I_Stack[ss].index(bottomItem)\n",
    "                        stacking.I_Stack[ss][0], stacking.I_Stack[ss][posB] = stacking.I_Stack[ss][posB], stacking.I_Stack[ss][0]\n",
    "\n",
    "                    stacking.sl[ss] = dataI.il[bottomItem]\n",
    "                    stacking.sw[ss] = dataI.iw[bottomItem]\n",
    "                    stacking.sh[ss] = int(round(sum([dataI.ih[ii] for ii in stacking.I_Stack[ss]]) - sum([dataI.ihn[ii] for ii in stacking.I_Stack[ss]][1:]), 0))\n",
    "                    stacking.svol2D[ss] = dataI.ivol2D[bottomItem]\n",
    "                    stacking.svol3D[ss] = round(stacking.svol2D[ss] * (stacking.sh[ss] / 1_000), 3)\n",
    "                    stacking.sm[ss] = sum([dataI.im[ii] for ii in stacking.I_Stack[ss]])\n",
    "                    stacking.su[ss] = dataI.iu[bottomItem]\n",
    "                    stacking.sk[ss] = dataI.ik[bottomItem]\n",
    "                    stacking.sg[ss] = sorted(set([dataI.ig[ii] for ii in stacking.I_Stack[ss]]), key=lambda x: dataT.tge[tt, dataT.tp[tt], x])\n",
    "                    stacking.sMulti[ss] = 0 if len(stacking.sg[ss]) == 1 else 1 \n",
    "\n",
    "                    allOrientations = set([dataI.io[ii] for ii in stacking.I_Stack[ss]])\n",
    "                    if \"lengthwise\" in allOrientations:\n",
    "                        stacking.so[ss] = \"lengthwise\"\n",
    "                    elif \"widthwise\" in allOrientations:\n",
    "                        stacking.so[ss] = \"widthwise\"\n",
    "                    else:\n",
    "                        stacking.so[ss] = \"none\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc56fa4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Packing Heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54484215",
   "metadata": {},
   "source": [
    "## Heuristic Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "962b263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion Objective -> Sorgt dafür, dass Stacks zu Anfang eher in die Weite sortiert werden. \n",
    "def GreedyObjWidth(LengthStack, coord, TruckLength):\n",
    "   # GreedyObjWidth(LengthStack, WidthStack, coord, TruckWidth):\n",
    "    if LengthStack + coord[0] == TruckLength: #Avoid Division by zero\n",
    "        Obj = 1 / (TruckLength - (LengthStack + coord[0] - 1))\n",
    "    else:\n",
    "        Obj = 1/ (TruckLength - (LengthStack + coord[0]))\n",
    "    return Obj\n",
    "\n",
    "#Funktion Objective -> Sorgt dafür, dass Stacks schnell in die Länge gestapelt werden und Items auch eher auf die hintere als auf die vordere Achse gelegt werden\n",
    "def GreedyObjLength(LengthStack, coord, TruckLength):\n",
    "    Obj = TruckLength - (LengthStack + coord[0])\n",
    "    return Obj\n",
    "\n",
    "def LowerLeftCorner(coord):\n",
    "    return (coord[0] + coord[1])\n",
    "\n",
    "def MinLength(coord):\n",
    "    return coord[0] + coord[1]/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d4c6a",
   "metadata": {},
   "source": [
    "## Heuristic Weight Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b909a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightConstr3D(dataT, dataI, tt, LocalSolutionCoord_Item):\n",
    "    \n",
    "    UOrdered = sorted(dataT.TU[tt], key=lambda x: dataT.te[tt, x])\n",
    "    I_Supplier = {uu: [] for uu in  UOrdered}\n",
    "\n",
    "    for ii in LocalSolutionCoord_Item.keys():\n",
    "        #Achtung ii ist ein Tuple aus dem wirklichen Item Namen String UND einem Integer, welcher für die exakte Identifikation des Item steht (wegen numItem)\n",
    "        I_Supplier[dataI.iu[ii[0]]].append(ii)\n",
    "    tm = {uuu: max(1e-5, sum([dataI.im[ii[0]] for uu in UOrdered[:pos+1] for ii in I_Supplier[uu]])) for pos, uuu in enumerate(UOrdered)}\n",
    "\n",
    "    eje = dict()\n",
    "    ejr = dict()\n",
    "    emh = dict()\n",
    "    emr = dict()\n",
    "    emm = dict()\n",
    "    \n",
    "    for uu in UOrdered:\n",
    "        eje[uu] = 0\n",
    "        ejr[uu] = 0\n",
    "        emh[uu] = 0\n",
    "        emr[uu] = 0\n",
    "        emm[uu] = 0   \n",
    "          \n",
    "    #Startpunkt und x Länge jedes Items berechnen\n",
    "    XCoorW_I = dict()    \n",
    "    for ii,info in LocalSolutionCoord_Item.items():\n",
    "        if info[0] == 0:\n",
    "            ItemLength = dataI.il[ii[0]]\n",
    "        else:\n",
    "            ItemLength = dataI.iw[ii[0]]  \n",
    "        XCoorW_I[ii] = (info[1] + ItemLength/2) * dataI.im[ii[0]]    \n",
    "\n",
    "    for pos, uuu in enumerate(UOrdered):\n",
    "        eje[uuu] = sum([XCoorW_I[ii] for uu in UOrdered[:pos+1] for ii in I_Supplier[uu]])/ tm[uuu]\n",
    "        ejr[uuu] = dataT.ejeh[tt] + dataT.ejhr[tt] - eje[uuu]\n",
    "        emh[uuu] = (tm[uuu] * ejr[uuu] + dataT.em[tt] * dataT.ejcr[tt]) / dataT.ejhr[tt]\n",
    "        emr[uuu] = tm[uuu] + dataT.em[tt] - emh[uuu]\n",
    "        emm[uuu] = (dataT.cm[tt] * dataT.cjfc[tt] + emh[uuu] * dataT.cjfh[tt]) / dataT.cjfm[tt]       \n",
    "\n",
    "    feas = True\n",
    "    for uu in UOrdered:      \n",
    "        if emm[uu] > dataT.emmm[tt] or emr[uu] > dataT.emmr[tt]:\n",
    "            feas = False\n",
    "    \n",
    "    return feas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ef68581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightConstrWeightBalance(dataT, tt, stacking, LocalSolutionCoord_Stack, Volumenausnutzung, RemStacks):\n",
    "    \n",
    "    #Startpunkt und x Länge jedes Stacks berechnen\n",
    "    XCoorW_S = dict()\n",
    "    MaxXCoord_S = dict()\n",
    "    for ss,info in LocalSolutionCoord_Stack.items():\n",
    "        if info[0] == 0:\n",
    "            StackLength = stacking.sl[ss]\n",
    "        else:\n",
    "            StackLength = stacking.sw[ss]  \n",
    "        MaxXCoord_S[ss] = info[1] + StackLength\n",
    "        XCoorW_S[ss] = (info[1] + StackLength/2) * stacking.sm[ss]    \n",
    "    \n",
    "    UOrdered = sorted(dataT.TU[tt], key=lambda x: dataT.te[tt, x])\n",
    "    S_Supplier = {uu: [] for uu in  UOrdered}\n",
    "    \n",
    "    RemainingTruckWeight = dataT.tm[tt]\n",
    "    \n",
    "    for ss in LocalSolutionCoord_Stack.keys():\n",
    "        RemainingTruckWeight -= stacking.sm[ss]\n",
    "        S_Supplier[stacking.su[ss]].append(ss) \n",
    "        \n",
    "    tm = {uuu: min(dataT.tm[tt], max(1e-5, sum([stacking.sm[ss] for uu in UOrdered[:pos+1] for ss in S_Supplier[uu]]))) for pos, uuu in enumerate(UOrdered)}     \n",
    "    \n",
    "    #Für jeden Stop wird nun ein Dummy Stack erstellt, bei dem wir annehmen, dass die Weite des Trucks entsprechend der Volumenausnutzung ausgenutzt wird, um eine realistische Verteilung innerhalb des Trucks zu approximieren\n",
    "    #Pro Supplier einen neuen PseudoStack\n",
    "    Pseudos_S_Supplier = {uu: [] for uu in  UOrdered}\n",
    "    for ss in RemStacks:\n",
    "        Pseudos_S_Supplier[stacking.su[ss]].append(ss)\n",
    "        \n",
    "    StartPosition = max(MaxXCoord_S.values())\n",
    "    PseudoStackNbr = max(max(list(LocalSolutionCoord_Stack.keys())), max(RemStacks+[0])) + 1_000_001\n",
    "    for supplier, stackgroups in Pseudos_S_Supplier.items():\n",
    "        Two2DVolRem = sum([stacking.sl[ss]*stacking.sw[ss] for ss in stackgroups])\n",
    "        NewLenght = Two2DVolRem / (dataT.tw[tt]*Volumenausnutzung)\n",
    "        NewLenght = NewLenght if dataT.tl[tt] - (StartPosition + NewLenght) > 0 else dataT.tl[tt] - StartPosition\n",
    "        XCoorW_S[PseudoStackNbr] = (StartPosition + NewLenght/2) * min(RemainingTruckWeight, sum([stacking.sm[ss] for ss in stackgroups]))\n",
    "        S_Supplier[supplier].append(PseudoStackNbr)\n",
    "        PseudoStackNbr += 1\n",
    "        StartPosition += NewLenght\n",
    "\n",
    "    #Hier noch die Masse aufaddieren der noch nicht gepackten Items\n",
    "    for supplier, stackgroups in Pseudos_S_Supplier.items():\n",
    "        for ss in stackgroups:\n",
    "            tm[supplier] += stacking.sm[ss]\n",
    "            tm[supplier] = min(dataT.tm[tt], tm[supplier])\n",
    "            \n",
    "    eje = dict()\n",
    "    ejr = dict()\n",
    "    emh = dict()\n",
    "    emr = dict()\n",
    "    emm = dict()\n",
    "    \n",
    "    for uu in UOrdered:\n",
    "        eje[uu] = 0\n",
    "        ejr[uu] = 0\n",
    "        emh[uu] = 0\n",
    "        emr[uu] = 0\n",
    "        emm[uu] = 0     \n",
    "        \n",
    "    for pos, uuu in enumerate(UOrdered):\n",
    "        eje[uuu] = sum([XCoorW_S[ss] for uu in UOrdered[:pos+1] for ss in S_Supplier[uu]])/ tm[uuu]\n",
    "        ejr[uuu] = dataT.ejeh[tt] + dataT.ejhr[tt] - eje[uuu]\n",
    "        emh[uuu] = (tm[uuu] * ejr[uuu] + dataT.em[tt] * dataT.ejcr[tt]) / dataT.ejhr[tt]\n",
    "        emr[uuu] = tm[uuu] + dataT.em[tt] - emh[uuu]\n",
    "        emm[uuu] = (dataT.cm[tt] * dataT.cjfc[tt] + emh[uuu] * dataT.cjfh[tt]) / dataT.cjfm[tt]       \n",
    "\n",
    "    feas = True\n",
    "    for uu in UOrdered:\n",
    "        if emm[uu] > dataT.emmm[tt] or emr[uu] > dataT.emmr[tt]:\n",
    "            feas = False\n",
    "\n",
    "    return feas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ed0708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion um Gewicht zu überprüfen\n",
    "def WeightConstr(dataT, tt, stacking, LocalSolutionCoord_Stack):\n",
    "    UOrdered = sorted(dataT.TU[tt], key=lambda x: dataT.te[tt, x])\n",
    "    S_Supplier = {uu: [] for uu in  UOrdered}\n",
    "    for ss in LocalSolutionCoord_Stack.keys():\n",
    "        S_Supplier[stacking.su[ss]].append(ss) \n",
    "    tm = {uuu: max(1e-5, sum([stacking.sm[ss] for uu in UOrdered[:pos+1] for ss in S_Supplier[uu]])) for pos, uuu in enumerate(UOrdered)}    \n",
    "\n",
    "    eje = dict()\n",
    "    ejr = dict()\n",
    "    emh = dict()\n",
    "    emr = dict()\n",
    "    emm = dict()\n",
    "    \n",
    "    for uu in UOrdered:\n",
    "        eje[uu] = 0\n",
    "        ejr[uu] = 0\n",
    "        emh[uu] = 0\n",
    "        emr[uu] = 0\n",
    "        emm[uu] = 0     \n",
    "        \n",
    "    #Startpunkt und x Länge jedes Stacks berechnen\n",
    "    XCoorW_S = dict()\n",
    "    for ss,info in LocalSolutionCoord_Stack.items():\n",
    "        if info[0] == 0:\n",
    "            StackLength = stacking.sl[ss]\n",
    "        else:\n",
    "            StackLength = stacking.sw[ss]  \n",
    "        XCoorW_S[ss] = (info[1] + StackLength/2) * stacking.sm[ss]\n",
    "\n",
    "    for pos, uuu in enumerate(UOrdered):\n",
    "        eje[uuu] = sum([XCoorW_S[ss] for uu in UOrdered[:pos+1] for ss in S_Supplier[uu]])/ tm[uuu]\n",
    "        ejr[uuu] = dataT.ejeh[tt] + dataT.ejhr[tt] - eje[uuu]\n",
    "        emh[uuu] = (tm[uuu] * ejr[uuu] + dataT.em[tt] * dataT.ejcr[tt]) / dataT.ejhr[tt]\n",
    "        emr[uuu] = tm[uuu] + dataT.em[tt] - emh[uuu]\n",
    "        emm[uuu] = (dataT.cm[tt] * dataT.cjfc[tt] + emh[uuu] * dataT.cjfh[tt]) / dataT.cjfm[tt]       \n",
    "\n",
    "    feas = True\n",
    "    for uu in UOrdered:      \n",
    "        if emm[uu] > dataT.emmm[tt] or emr[uu] > dataT.emmr[tt]:\n",
    "            feas = False\n",
    "    \n",
    "    return feas  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e7daf",
   "metadata": {},
   "source": [
    "## Heuristic ES Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19b24a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion Empty Spaces updaten\n",
    "def UpdateESMoreComplex3D(ES_Set, InsertStackhere, dataI, ii, MinDim):\n",
    "    #Wir löschen keine ES (nur wenn minimale Dimension verletzt ist) um den Support Fall weiterhin abzudecken\n",
    "\n",
    "    \n",
    "    if InsertStackhere[0] == 0: #Erte Orientierung für Stack wurde gewählt\n",
    "        Length = dataI.il[ii]\n",
    "        Width = dataI.iw[ii]\n",
    "    else:\n",
    "        Length = dataI.iw[ii]\n",
    "        Width = dataI.il[ii] \n",
    "    \n",
    "    NewStackCoords = tuple((ES_Set[InsertStackhere[1]][0],ES_Set[InsertStackhere[1]][1], ES_Set[InsertStackhere[1]][0] + Length, ES_Set[InsertStackhere[1]][1] + Width))\n",
    "    \n",
    "    \n",
    "    New_Es = []\n",
    "    DeleteKeys = []\n",
    "    for es,coords in ES_Set.items():\n",
    "        if NewStackCoords[0] >= coords[2] or NewStackCoords[2] <= coords[0] or NewStackCoords[1] >= coords[3] or NewStackCoords[3] <= coords[1]:\n",
    "            #Hier gibt es keine Überschneidung\n",
    "            pass\n",
    "        else:\n",
    "            DeleteKeys.append(es)\n",
    "            x1 = coords[0]\n",
    "            y1 = coords[1]\n",
    "            x2 = coords[2]\n",
    "            y2 = coords[3]\n",
    "            x3 = NewStackCoords[0]\n",
    "            y3 = NewStackCoords[1]\n",
    "            x4 = NewStackCoords[2]\n",
    "            y4 = NewStackCoords[3]\n",
    "            \n",
    "            NewEs1 = tuple((x1, y1, x3, y2))\n",
    "            NewEs2 = tuple((x4, y1, x2, y2))\n",
    "            NewEs3 = tuple((x1, y1, x2, y3))\n",
    "            NewEs4 = tuple((x1, y4, x2, y2))\n",
    "          #  NewEs5 = tuple((x1, y1, x2, y2))\n",
    "            \n",
    "            if NewEs1[2] - NewEs1[0] <= MinDim or NewEs1[3] - NewEs1[1] <= MinDim:\n",
    "                ####Dieses ES nicht erstellen\n",
    "                pass\n",
    "            else:\n",
    "                New_Es.append(NewEs1)\n",
    "                \n",
    "            if NewEs2[2] - NewEs2[0] <= MinDim or NewEs2[3] - NewEs2[1] <= MinDim:\n",
    "                ####Dieses ES nicht erstellen\n",
    "                pass\n",
    "            else: \n",
    "                New_Es.append(NewEs2)                \n",
    "                \n",
    "            if NewEs3[2] - NewEs3[0] <= MinDim or NewEs3[3] - NewEs3[1] <= MinDim:\n",
    "                ####Dieses ES nicht erstellen\n",
    "                pass\n",
    "            else:\n",
    "                New_Es.append(NewEs3) \n",
    "        \n",
    "            if NewEs4[2] - NewEs4[0] <= MinDim or NewEs4[3] - NewEs4[1] <= MinDim:\n",
    "                ####Dieses ES nicht erstellen\n",
    "                pass\n",
    "            else:\n",
    "                New_Es.append(NewEs4) \n",
    "        \n",
    "    for keys in DeleteKeys:\n",
    "        del ES_Set[keys] \n",
    "\n",
    "    \n",
    "    if list(ES_Set.keys()):\n",
    "        MaxKey = max(list(ES_Set.keys()))\n",
    "    else:\n",
    "        MaxKey = -1\n",
    "    \n",
    "    for es in New_Es:\n",
    "        MaxKey += 1\n",
    "        ES_Set[MaxKey] = es\n",
    "    \n",
    "    \n",
    "    \n",
    "    DeleteKeys = []    \n",
    "    Keys_List = list(ES_Set.keys())\n",
    "    for pos,es in enumerate(Keys_List):\n",
    "        if es not in DeleteKeys:\n",
    "            for es2 in Keys_List[pos+1:]:\n",
    "                if es2 not in DeleteKeys:\n",
    "                    if ES_Set[es] == ES_Set[es2]:\n",
    "                        DeleteKeys.append(es2)\n",
    "    for keys in DeleteKeys:\n",
    "        del ES_Set[keys]    \n",
    "    \n",
    "    \n",
    "    return ES_Set            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf36f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion Empty Spaces updaten\n",
    "def UpdateES(ES_Set, InsertStackhere, stacking, ss, NextItemSameGroup, MinDim, LocalSolutionCoord_Stack):\n",
    "    #ES wird hier sehr greedy erstellt: Wir erstellen immer nur 2 neue ES aus einem ES welche sich nicht überlappen. Maßgeblich sind hier die X und Y Koordinaten. Manchmal entsteht nur 1 ES wenn Grenzen perfekt geschlossen werden\n",
    "    \n",
    "    #Genutztes ES löschen\n",
    "    coord = ES_Set[InsertStackhere[1]]\n",
    "    del ES_Set[InsertStackhere[1]]\n",
    "    \n",
    "    #Nach ES suchen, die gelöscht werden können.\n",
    "    #Manchmal existieren kleine ES die erst später gelöscht werden können, weil erst später alle Stacks anderweitig eingelagert wurden\n",
    "    #Ist schon ein wenig Kostenintensiv jedes mal über alle ES drüber zu iterieren, generell existieren häufig aber nicht mehr als 5 ES. Dafür sparen wir uns in anderen\n",
    "    #Schritten Iterationen falls wir ein ES finden, welches gelöscht werden kann\n",
    "    #Außerdem ist es sinnvoll, weil wir unten wenn wir ES suchen die nicht supporten werden können nur ES betrachten von denen links kein anderes ES exitiert.\n",
    "    #Wenn jedoch ganz links ein ES existiert das nicht mehr genutzt werden kann verbaut uns dies eventuell andere ES\n",
    "    DeleteKeys = []\n",
    "    for espos, coordinfo in ES_Set.items():\n",
    "        if coordinfo[2] - coordinfo[0] < MinDim or coordinfo[3] - coordinfo[1] < MinDim:\n",
    "            DeleteKeys.append(espos)\n",
    "    for keys in DeleteKeys:\n",
    "        del ES_Set[keys]\n",
    "    \n",
    "    if ES_Set:\n",
    "        MaxESSet = max([es for es in ES_Set.keys()])\n",
    "        es1 = MaxESSet + 1\n",
    "        es2 = MaxESSet + 2       \n",
    "    else:\n",
    "        es1 = 0\n",
    "        es2 = 1\n",
    "\n",
    "    #Zwei neue ES erstellen\n",
    "    if InsertStackhere[0] == 0: #Erte Orientierung für Stack wurde gewählt\n",
    "        Length = stacking.sl[ss]\n",
    "        Width = stacking.sw[ss]\n",
    "    else:\n",
    "        Length = stacking.sw[ss]\n",
    "        Width = stacking.sl[ss]    \n",
    "    \n",
    "    coord1 = tuple((coord[0], coord[1]+Width, coord[0]+Length, coord[3]))\n",
    "    coord2 = tuple((Length+coord[0], coord[1], coord[2], coord[3]))\n",
    "    \n",
    "    #Überprüfen ob wirklich zwei neue ES entstehen oder schon gelöscht werden dürfen\n",
    "    Coord1Created = False\n",
    "    if coord1[2]-coord1[0] >= MinDim and coord1[3]-coord1[1] >= MinDim:\n",
    "        ES_Set[es1] = coord1 \n",
    "        Coord1Created = True\n",
    "\n",
    "    if coord2[2]-coord2[0] >= MinDim and coord2[3]-coord2[1] >= MinDim: \n",
    "        ES_Set[es2] = coord2\n",
    "    else: ####Dieses ES eventuell erweitern mit nächstgelegendem ES\n",
    "        ESUpdate = False\n",
    "        for espos, coordinfo in ES_Set.items():\n",
    "            if coord2[1] == coordinfo[1] and coord2[2] == coordinfo[0] and coord2[3] == coordinfo[3] and NextItemSameGroup == True:\n",
    "                ES_Set[espos] = tuple((coord2[0], coordinfo[1], coordinfo[2], coordinfo[3]))\n",
    "                ESUpdate = True\n",
    "                break \n",
    "        if ESUpdate == False:\n",
    "            #Hier geht es darum ein ES zu finden, das keine Chance mehr hat genutzt zu werden da IMMER der Support fehlen würde.\n",
    "            #Dies kann passieren, wenn ein ES gelöscht wurde in dem kein Stack gelagert werden könnte da das ES zu klein wäre.\n",
    "            #In diesem Fall kann vlt ein anderes ES nach links verschoben werden.\n",
    "            #Dieses ES suchen wir nun:\n",
    "            if coord2[2] - coord2[0] > 0:\n",
    "                for espos, coordinfo in ES_Set.items():\n",
    "                    if coord2[1] <= coordinfo[1] and coord2[2] == coordinfo[0] and coord2[3] >= coordinfo[1]:\n",
    "                        ES_Set[espos] = tuple((coord2[0], coordinfo[1], coordinfo[2], coordinfo[3]))\n",
    "                        ESUpdate = True\n",
    "                        break  \n",
    "                        \n",
    "    #Aber erst nachdem die neuen Sets erstellt wurden\n",
    "    #Hier noch überprüfen, ob ES eventuell nach links verschoben werden kann um den Support den ES zukünftig zu gewährleisten.\n",
    "    #NUR wenn links von dem ES kein anderes ES mehr existiert\n",
    "    #Gehe so weit nach links bis erster bereits eingelagerter Stack gefunden wurde, dessen rechte Kante den Ursprung des ES berühren würde, wenn das ES entsprechend nach links verschoben werden würde\n",
    "    #Mach dies nur für das neue ES das über dem neuen Stack erstellt wurde (coord1), da das neue ES (coord2) neben bem neuen Stack immer supportet wird\n",
    "    ESUpdate = True\n",
    "    if Coord1Created == True and coord1[0] > 0:\n",
    "        for espos, coordinfo in ES_Set.items():\n",
    "            if es1 != espos:\n",
    "                #Könnten sich in der Weite überschneiden\n",
    "                if coord1[1] < coordinfo[3] and coord1[3] > coordinfo[1]:\n",
    "                    #Überprüfen, wenn dem so ist, ob coordinfo links davon liegt?\n",
    "                    if coordinfo[2] < coord1[0] or coordinfo[0] < coord1[0]:\n",
    "                        ESUpdate = False\n",
    "                        break\n",
    "        if ESUpdate == True:\n",
    "            MaxNewBeginning = -100\n",
    "            #ES so weit nach links erweitern, bis es an Kante des ersten Stacks stößt\n",
    "            for ss2, info in LocalSolutionCoord_Stack.items():\n",
    "                if info[0] == 0:\n",
    "                    StackLength = stacking.sl[ss2]\n",
    "                    StackWidth = stacking.sw[ss2]\n",
    "                else:\n",
    "                    StackLength = stacking.sw[ss2]\n",
    "                    StackWidth = stacking.sl[ss2]\n",
    "                #Nur Stacks beachten, die vollsätndig links von dem ES liegen\n",
    "                if info[1] + StackLength <= coord1[0]:\n",
    "                    if info[2] <= coord1[3] and info[2] + StackWidth >= coord1[1]:\n",
    "                        if info[1] + StackLength > MaxNewBeginning:\n",
    "                            MaxNewBeginning = info[1] + StackLength\n",
    "            if MaxNewBeginning > 0:\n",
    "                ES_Set[es1] = tuple((MaxNewBeginning, coord1[1], coord1[2], coord1[3])) \n",
    "\n",
    "    return ES_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4076b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion Empty Spaces updaten\n",
    "def UpdateESMoreComplex(ES_Set, InsertStackhere, stacking, ss, MinDim):\n",
    "    #Wir löschen keine ES (nur wenn minimale Dimension verletzt ist) um den Support Fall weiterhin abzudecken\n",
    "\n",
    "    \n",
    "    if InsertStackhere[0] == 0: #Erte Orientierung für Stack wurde gewählt\n",
    "        Length = stacking.sl[ss]\n",
    "        Width = stacking.sw[ss]\n",
    "    else:\n",
    "        Length = stacking.sw[ss]\n",
    "        Width = stacking.sl[ss] \n",
    "    \n",
    "    NewStackCoords = tuple((ES_Set[InsertStackhere[1]][0],ES_Set[InsertStackhere[1]][1], ES_Set[InsertStackhere[1]][0] + Length, ES_Set[InsertStackhere[1]][1] + Width))\n",
    "    \n",
    "    \n",
    "    New_Es = []\n",
    "    DeleteKeys = []\n",
    "    for es,coords in ES_Set.items():\n",
    "        if NewStackCoords[0] >= coords[2] or NewStackCoords[2] <= coords[0] or NewStackCoords[1] >= coords[3] or NewStackCoords[3] <= coords[1]:\n",
    "            #Hier gibt es keine Überschneidung\n",
    "            pass\n",
    "        else:\n",
    "            DeleteKeys.append(es)\n",
    "            x1 = coords[0]\n",
    "            y1 = coords[1]\n",
    "            x2 = coords[2]\n",
    "            y2 = coords[3]\n",
    "            x3 = NewStackCoords[0]\n",
    "            y3 = NewStackCoords[1]\n",
    "            x4 = NewStackCoords[2]\n",
    "            y4 = NewStackCoords[3]\n",
    "            \n",
    "            NewEs1 = tuple((x1, y1, x3, y2))\n",
    "            NewEs2 = tuple((x4, y1, x2, y2))\n",
    "            NewEs3 = tuple((x1, y1, x2, y3))\n",
    "            NewEs4 = tuple((x1, y4, x2, y2))\n",
    "            \n",
    "            if NewEs1[2] - NewEs1[0] <= MinDim or NewEs1[3] - NewEs1[1] <= MinDim:\n",
    "                ####Dieses ES nicht erstellen\n",
    "                pass\n",
    "            else:\n",
    "                New_Es.append(NewEs1)\n",
    "                \n",
    "            if NewEs2[2] - NewEs2[0] <= MinDim or NewEs2[3] - NewEs2[1] <= MinDim:\n",
    "                ####Dieses ES nicht erstellen\n",
    "                pass\n",
    "            else: \n",
    "                New_Es.append(NewEs2)                \n",
    "                \n",
    "            if NewEs3[2] - NewEs3[0] <= MinDim or NewEs3[3] - NewEs3[1] <= MinDim:\n",
    "                ####Dieses ES nicht erstellen\n",
    "                pass\n",
    "            else:\n",
    "                New_Es.append(NewEs3) \n",
    "        \n",
    "            if NewEs4[2] - NewEs4[0] <= MinDim or NewEs4[3] - NewEs4[1] <= MinDim:\n",
    "                ####Dieses ES nicht erstellen\n",
    "                pass\n",
    "            else:\n",
    "                New_Es.append(NewEs4) \n",
    "\n",
    "        \n",
    "    for keys in DeleteKeys:\n",
    "        del ES_Set[keys] \n",
    "\n",
    "    \n",
    "    if list(ES_Set.keys()):\n",
    "        MaxKey = max(list(ES_Set.keys()))\n",
    "    else:\n",
    "        MaxKey = -1\n",
    "    \n",
    "    for es in New_Es:\n",
    "        MaxKey += 1\n",
    "        ES_Set[MaxKey] = es\n",
    "    \n",
    "    \n",
    "    \n",
    "    DeleteKeys = []    \n",
    "    Keys_List = list(ES_Set.keys())\n",
    "    for pos,es in enumerate(Keys_List):\n",
    "        if es not in DeleteKeys:\n",
    "            for es2 in Keys_List[pos+1:]:\n",
    "                if es2 not in DeleteKeys:\n",
    "                    if ES_Set[es] == ES_Set[es2]:\n",
    "                        DeleteKeys.append(es2)\n",
    "    for keys in DeleteKeys:\n",
    "        del ES_Set[keys]    \n",
    "    \n",
    "    \n",
    "    return ES_Set            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178c70a",
   "metadata": {},
   "source": [
    "## 3D Heursitics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01ccc781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_3DPPH(dataT, dataI, dataP, tt, ttIdx, num_Item):\n",
    "    \n",
    "    #Heuristik Jakob\n",
    "    Vol3DMustPacked = 0\n",
    "    UsedTruckWeight = 0\n",
    "    for ii, num in num_Item.items():\n",
    "        Vol3DMustPacked += (dataI.il[ii]*dataI.iw[ii] * dataI.ih[ii]) * num\n",
    "        UsedTruckWeight += dataI.im[ii] * num\n",
    "    UsedTruckWeight /= dataT.tm[tt]\n",
    "    \n",
    "    SortingOrderStacks = ['MinmassMaxvol', 'MaxvolMinmass', 'MinmassMinvol', 'MinvolMinmass']\n",
    "    ObjectiveFunctionsES = ['ObjLowerLeftCorner','ObjWidth', 'ObjLength', 'ObjMinLength']\n",
    "    MaxStackinglist = [5,4,3,2,1] #Minimum muss immer 1 sein -> bei 1 wären wir schon im 2D Fall\n",
    "    \n",
    "    MinMaxLenght = dataT.tl[tt]\n",
    "    BestInitialValue = 0\n",
    "    BestInitialSolution = dict()\n",
    "    OptimalSolutionFoundbyHeuristic = False\n",
    "    for orderstacksheuristic in SortingOrderStacks:\n",
    "        for objectiveheuristic in ObjectiveFunctionsES:\n",
    "            for MaxStacking in MaxStackinglist:\n",
    "                SolutionCoord_Item, MaxLenght = Heuristic3DPacking(dataT, dataI, tt, num_Item, orderstacksheuristic, objectiveheuristic, MaxStacking)\n",
    "                if sum([dataI.il[ii[0]]*dataI.iw[ii[0]] * dataI.ih[ii[0]] for ii in SolutionCoord_Item.keys()]) >= BestInitialValue:\n",
    "                    ###Hier noch einen Tie Breaker -> Packplan wird bevorzugt, der kompakter ist\n",
    "                    if sum([dataI.il[ii[0]]*dataI.iw[ii[0]] * dataI.ih[ii[0]] for ii in SolutionCoord_Item.keys()]) == BestInitialValue:\n",
    "                        if MaxLenght < MinMaxLenght:\n",
    "                            MinMaxLenght = MaxLenght\n",
    "                            BestInitialSolution = copy.deepcopy(SolutionCoord_Item)\n",
    "                        else:\n",
    "                            pass    \n",
    "                    else:\n",
    "                        BestInitialValue = sum([dataI.il[ii[0]]*dataI.iw[ii[0]] * dataI.ih[ii[0]] for ii in SolutionCoord_Item.keys()])\n",
    "                        BestInitialSolution = copy.deepcopy(SolutionCoord_Item)\n",
    "                        MinMaxLenght = MaxLenght\n",
    "                if BestInitialValue == Vol3DMustPacked:\n",
    "                    OptimalSolutionFoundbyHeuristic = True\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "            if OptimalSolutionFoundbyHeuristic:\n",
    "                break\n",
    "        if OptimalSolutionFoundbyHeuristic:\n",
    "            break          \n",
    "\n",
    "    omega = dict()     \n",
    "    xx = dict()\n",
    "    yy = dict()\n",
    "    bb = dict()\n",
    "    \n",
    "    for ii,info in BestInitialSolution.items():\n",
    "        ii1 = ii[0]\n",
    "        jj1 = ii[1]\n",
    "        if info[0] == 0:\n",
    "            omega[ii1,jj1, 0] = 1\n",
    "            omega[ii1,jj1, 1] = 0\n",
    "        else:\n",
    "            omega[ii1,jj1, 1] = 1\n",
    "            omega[ii1,jj1, 0] = 0\n",
    "        xx[ii1,jj1] = info[1]\n",
    "        yy[ii1,jj1] = info[2]   \n",
    "        if info[3] == 0:\n",
    "            bb[ii1,jj1] = 1\n",
    "        else:\n",
    "            bb[ii1,jj1] = 0\n",
    "    #Heuristik Jakob   \n",
    "\n",
    "    \n",
    "    # Track all items that are not packed into the truck\n",
    "    numNotPacked_Item = defaultdict(int)\n",
    "    IPacked = []\n",
    "    for ii in num_Item:\n",
    "        for jj in range(num_Item[ii]):\n",
    "            if (ii, jj) not in BestInitialSolution:\n",
    "                numNotPacked_Item[ii] += 1\n",
    "            else:\n",
    "                IPacked.append((ii, jj))\n",
    "    \n",
    "    \n",
    "    # Create truck\n",
    "    truck = Truck(ttIdx, tt)\n",
    "    \n",
    "    # Create stacks\n",
    "    BI = [(ii, jj) for ii, jj in IPacked if bb[ii, jj] == 1]  # List of bottom items\n",
    "    BIOrdered = sorted(BI, key=lambda x: (xx[x], yy[x]))\n",
    "\n",
    "    \n",
    "    for pos, (ii1, jj1) in enumerate(BIOrdered):\n",
    "        stack = Stack()\n",
    "        truck.Stacks.append(stack)\n",
    "        \n",
    "        stack.xo = int(round(xx[ii1, jj1], 0))\n",
    "        stack.yo = int(round(yy[ii1, jj1], 0))\n",
    "        stack.zo = 0\n",
    "        stack.xe = int(round(xx[ii1, jj1] + dataI.il[ii1] * omega[ii1, jj1, 0] + dataI.iw[ii1] * omega[ii1, jj1, 1], 0))\n",
    "        stack.ye = int(round(yy[ii1, jj1] + dataI.iw[ii1] * omega[ii1, jj1, 0] + dataI.il[ii1] * omega[ii1, jj1, 1], 0))\n",
    "        stack.ze = None\n",
    "        \n",
    "    \n",
    "        IStack = [(ii1, jj1)]\n",
    "        IOnTop = []\n",
    "        for ii2, jj2 in IPacked:\n",
    "            if ii1 != ii2 or jj1 != jj2:\n",
    "                if xx[ii1, jj1] == xx[ii2, jj2] and yy[ii1, jj1] == yy[ii2, jj2]:\n",
    "                    IOnTop.append((ii2, jj2))\n",
    "        \n",
    "        # Sort items by their plant dock order and add to stack\n",
    "        IOnTop.sort(key=lambda x: dataT.tge[tt, dataT.tp[tt], dataI.ig[x[0]]])\n",
    "        IStack.extend(IOnTop)\n",
    "\n",
    "        stack.idx = f\"{truck.idx}_{pos+1}\"\n",
    "        stack.code = code_stack(pos+1, tidx=truck.idx)\n",
    "\n",
    "        # Create items\n",
    "        height = 0\n",
    "        for pos, (ii, jj) in enumerate(IStack):\n",
    "            item = Item()            \n",
    "            item.idx = ii\n",
    "            item.code = stack.code + str(pos+1)                    \n",
    "            item.xo = stack.xo\n",
    "            item.xe = stack.xe\n",
    "            item.yo = stack.yo\n",
    "            item.ye = stack.ye   \n",
    "            item.zo = height\n",
    "            if pos > 0:\n",
    "                height += dataI.ih[ii] - dataI.ihn[ii]\n",
    "            else:\n",
    "                height += dataI.ih[ii]\n",
    "            item.ze = height\n",
    "\n",
    "            stack.Items.append(item)            \n",
    "                \n",
    "        stack.ze = height\n",
    "\n",
    "        \n",
    "\n",
    "    truck.check_weight(dataT, dataI)\n",
    "        \n",
    "    return truck, numNotPacked_Item    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfa25760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heuristic3DPacking(dataT, dataI, tt, num_Item, sortorder, objfunction, MaxStacking):\n",
    "    ####Erstmal das 2D Volumen überprüfen\n",
    "    Volumenausnutzung = 0\n",
    "    for ii, num in num_Item.items():\n",
    "        Volumenausnutzung += (dataI.il[ii]*dataI.iw[ii]) * num\n",
    "    Volumenausnutzung /= (dataT.tl[tt]*dataT.tw[tt])\n",
    "    \n",
    "    MagicBorder = (Volumenausnutzung + 0.05) * dataT.tw[tt]\n",
    "    LocalSolutionCoord_Item = dict() #Value: Orientierung von Stack, x Koordinate, y Koordinate, Position in Stack (0,1,2,3,... -> 0: First/Bottom Item, 1: Second Item, ....)\n",
    " \n",
    "    OrderTuple_Item = dict()\n",
    "    UnloadingOrderTuple_Item = dict() #Achtung, muss parallel in weiteres Dictionary laufen lasse, wenn ich Items nach mehr Kriterien als der (Un)loading Order sortieren möchte für die Greedy Heuristik (Gewicht, Volumen, etc)\n",
    "    for ii, num in num_Item.items():\n",
    "        \n",
    "        UnloadingOrderTuple_Item[ii] = tuple((dataT.te[tt, dataI.iu[ii]], dataT.tke[tt, dataI.iu[ii], dataI.ik[ii]], dataT.tge[tt, dataT.tp[tt], dataI.ig[ii]]))\n",
    "        if sortorder == 'MinmassMaxvol':\n",
    "            OrderTuple_Item[ii] = tuple((dataT.te[tt, dataI.iu[ii]], dataT.tke[tt, dataI.iu[ii], dataI.ik[ii]], dataT.tge[tt, dataT.tp[tt], dataI.ig[ii]], dataI.im[ii], 1/(dataI.il[ii]*dataI.iw[ii])))\n",
    "        if sortorder == 'MaxvolMinmass': \n",
    "            OrderTuple_Item[ii] = tuple((dataT.te[tt, dataI.iu[ii]], dataT.tke[tt, dataI.iu[ii], dataI.ik[ii]], dataT.tge[tt, dataT.tp[tt], dataI.ig[ii]], 1/(dataI.il[ii]*dataI.iw[ii]), dataI.im[ii]))\n",
    "        if sortorder == 'MinmassMinvol':\n",
    "            OrderTuple_Item[ii] = tuple((dataT.te[tt, dataI.iu[ii]], dataT.tke[tt, dataI.iu[ii], dataI.ik[ii]], dataT.tge[tt, dataT.tp[tt], dataI.ig[ii]], dataI.im[ii], (dataI.il[ii]*dataI.iw[ii])))\n",
    "        if sortorder == 'MinvolMinmass': \n",
    "            OrderTuple_Item[ii] = tuple((dataT.te[tt, dataI.iu[ii]], dataT.tke[tt, dataI.iu[ii], dataI.ik[ii]], dataT.tge[tt, dataT.tp[tt], dataI.ig[ii]], (dataI.il[ii]*dataI.iw[ii]), dataI.im[ii]))    \n",
    "      \n",
    "    OrderGroup_Item = dict()\n",
    "    OrderedItems = sorted(OrderTuple_Item, key=lambda x: OrderTuple_Item[x])    \n",
    "    Group = 0\n",
    "    for pos,ii in enumerate(OrderedItems):\n",
    "        if pos == 0:\n",
    "            OrderGroup_Item[ii] = Group\n",
    "        else:\n",
    "            if UnloadingOrderTuple_Item[ii] != UnloadingOrderTuple_Item[OrderedItems[pos-1]]:\n",
    "                Group += 1\n",
    "                OrderGroup_Item[ii] = Group\n",
    "            else:\n",
    "                OrderGroup_Item[ii] = Group\n",
    "         \n",
    "    #Create Empty Set = Truck Dimensions -> Key: Sets, Value: tuple mit 4 Einträgen (x,y, X,Y) Koordinate des Sets\n",
    "    ES_Set = dict()\n",
    "    ES_Set[0] = tuple((0,0, dataT.tl[tt], dataT.tw[tt]))\n",
    "\n",
    "    RemTruckWeight = dataT.tm[tt]\n",
    "    MaxLenght = 0 ####We use MaxLenght as a Tie Breaker\n",
    "    #So lange bis jedes Item einmal betrachtet wurde\n",
    "    ItemCount = -1\n",
    "    for pos1,ii in enumerate(OrderedItems):\n",
    "        for jj in range(num_Item[ii]):\n",
    "            \n",
    "            if RemTruckWeight >= dataI.im[ii]:\n",
    "                #Multi Drop noch berücksichtigen\n",
    "                if LocalSolutionCoord_Item and OrderGroup_Item[ii] > 0:\n",
    "                    MaxXPreviousGroups = max([LocalSolutionCoord_Item[iii][1] for iii in LocalSolutionCoord_Item.keys() if OrderGroup_Item[iii[0]] < OrderGroup_Item[ii]])\n",
    "                else:\n",
    "                    MaxXPreviousGroups = 0   \n",
    "                BestValue = float('inf')\n",
    "                InsertStackhere = tuple(()) #Tuple hat die Informationen Orientierung, ESKey\n",
    "                #Für jede mögliche Orientierung des Items\n",
    "                if dataI.io[ii] == 'none':\n",
    "                    Orientations = [0,1]\n",
    "                    #Orientierungen Greedy Einschränken, z.B. für Pakete mit Maßen 1600,1200\n",
    "                    Ratios = []\n",
    "                    Ratios.append((math.floor(dataT.tw[tt] / dataI.iw[ii]) * dataI.iw[ii]) / dataT.tw[tt])\n",
    "                    Ratios.append((math.floor(dataT.tw[tt] / dataI.il[ii]) * dataI.il[ii]) / dataT.tw[tt])\n",
    "                    if max(Ratios) > 0.95:\n",
    "                        if Ratios[0] == Ratios[1]:\n",
    "                            if dataI.iw[ii] > dataI.il[ii]:\n",
    "                                Orientations = [0]\n",
    "                            else:\n",
    "                                Orientations = [1]\n",
    "                        else:\n",
    "                            if dataI.il[ii] == dataI.iw[ii]:\n",
    "                                Orientations = [0]\n",
    "                            else:\n",
    "                                Orientations = [Ratios.index(max(Ratios))]\n",
    "                elif dataI.io[ii] == 'lengthwise':\n",
    "                    Orientations = [0]\n",
    "                else:\n",
    "                    Orientations = [1] \n",
    "\n",
    "                ###Jedes andere Item überprüfen, ob Item oben drauf gelagert werden kann\n",
    "                ###MaxStacking ist Parameter von außen\n",
    "                feasweight = False\n",
    "                #Wenn maxStackability <= 1 brauchen wir nicht weiter zu suchen\n",
    "                if dataI.ism[ii] > 1:\n",
    "                    PossibleItemsStacking = []\n",
    "                    for ii2, info in LocalSolutionCoord_Item.items():\n",
    "                        if dataI.ism[ii2[0]] > 1:\n",
    "                            if dataI.ist[ii] == dataI.ist[ii2[0]] and dataI.ism[ii] == dataI.ism[ii2[0]]: #Stackability, Max Stackability\n",
    "                                ###Supplier Order, Supplier Dock Order, Plant Dock Order\n",
    "                                if dataI.iu[ii] == dataI.iu[ii2[0]] and dataI.ik[ii] == dataI.ik[ii2[0]] and dataI.ig[ii] == dataI.ig[ii2[0]] and dataT.te[tt, dataI.iu[ii]] == dataT.te[tt, dataI.iu[ii2[0]]] and dataT.tke[tt, dataI.iu[ii], dataI.ik[ii]] == dataT.tke[tt, dataI.iu[ii2[0]], dataI.ik[ii2[0]]] and dataT.tge[tt, dataT.tp[tt], dataI.ig[ii]] == dataT.tge[tt, dataT.tp[tt], dataI.ig[ii2[0]]]:\n",
    "                                    if dataI.ih[ii] == dataI.ih[ii2[0]] and dataI.ihn[ii] == dataI.ihn[ii2[0]] and dataI.io[ii] == dataI.io[ii2[0]]: #Height, Nested Height, Orientation\n",
    "                                        #Diese Items können gestacked werden\n",
    "                                        PossibleItemsStacking.append(ii2)\n",
    "                    #Überprüfen ob neues Item mit allen Items auf dieser Position gestackt werden können\n",
    "                    for ii2 in PossibleItemsStacking:\n",
    "                        SamePosition = [ii3 for ii3 in LocalSolutionCoord_Item.keys() if ii3 in PossibleItemsStacking and LocalSolutionCoord_Item[ii3][:3] == LocalSolutionCoord_Item[ii2][:3]] #Nur die ersten drei Positionen, da dir 4. Position die Reihenfolge in dem Stack angibt\n",
    "                        #Zunächst überprüfen, ob selbstgewählte Stack Höhe eingehalten wird\n",
    "                        if len(SamePosition) + 1 <= MaxStacking:\n",
    "                            #Max Stackability überprüfen\n",
    "                            if len(SamePosition) + 1 <= dataI.ism[ii]:\n",
    "                                #Bottom Item bestimmen\n",
    "                                BottomItem = [ii3 for ii3 in SamePosition if LocalSolutionCoord_Item[ii3][3] == 0]\n",
    "                                BottomItem = BottomItem[0]\n",
    "                                #Check weight on bottom item\n",
    "                                if sum([dataI.im[ii3[0]] for ii3 in SamePosition if ii3 != BottomItem]) + dataI.im[ii] <= dataT.tmm[tt, dataI.ir[BottomItem[0]]]:\n",
    "                                    #Check Truck height\n",
    "                                    if dataI.ih[BottomItem[0]] + (dataI.ih[ii] - dataI.ihn[ii]) + sum([(dataI.ih[ii3[0]] - dataI.ihn[ii3[0]]) for ii3 in SamePosition if ii3 != BottomItem]) <= dataT.th[tt]:\n",
    "                                        #Truck density\n",
    "                                        if sum([(dataI.im[ii3[0]] / ((dataI.il[ii3[0]] * dataI.iw[ii3[0]]) / 1_000_000)) for ii3 in SamePosition]) + (dataI.im[ii] / ((dataI.il[ii] * dataI.iw[ii]) / 1_000_000)) <= dataT.tem[tt]:\n",
    "                                            #Weight Constraint muss auch beachtet werden\n",
    "                                            NextStackPos = max([LocalSolutionCoord_Item[ii3][3] for ii3 in SamePosition]) + 1\n",
    "                                            LocalSolutionCoord_Item[ii,jj] = tuple((LocalSolutionCoord_Item[BottomItem][0], LocalSolutionCoord_Item[BottomItem][1], LocalSolutionCoord_Item[BottomItem][2], NextStackPos))\n",
    "                                            feasweight = WeightConstr3D(dataT, dataI, tt, LocalSolutionCoord_Item)\n",
    "                                            if feasweight:\n",
    "                                                RemTruckWeight -= dataI.im[ii]\n",
    "                                                break\n",
    "                                            else:\n",
    "                                                del LocalSolutionCoord_Item[ii,jj]  \n",
    "\n",
    "                if feasweight == False:\n",
    "                    for oo in Orientations:\n",
    "                        #Jedes Set überprüfen in welches der Stack einsortiert werden soll\n",
    "                        for es, coord in ES_Set.items():\n",
    "                            if oo == 0:\n",
    "                                LengthItem = dataI.il[ii]\n",
    "                                WidthItem = dataI.iw[ii]\n",
    "                            else:\n",
    "                                LengthItem = dataI.iw[ii]\n",
    "                                WidthItem = dataI.il[ii] \n",
    "                            #ES nur betrachten, wenn Stack überhaupt hineinpassen könnte        \n",
    "                            if LengthItem <= coord[2]-coord[0] and WidthItem <= coord[3]-coord[1]:\n",
    "                                #Hier überprüfen ob Origin des ES von einem anderen Paket supportet wird\n",
    "                                Sup = False\n",
    "                                if coord[0] == 0:\n",
    "                                    Sup = True\n",
    "                                else:\n",
    "                                    for ii2, info in LocalSolutionCoord_Item.items():\n",
    "                                        if info[0] == 0:\n",
    "                                            ItemLength = dataI.il[ii2[0]]\n",
    "                                            ItemWidth = dataI.iw[ii2[0]]\n",
    "                                        else:\n",
    "                                            ItemLength = dataI.iw[ii2[0]]\n",
    "                                            ItemWidth = dataI.il[ii2[0]]\n",
    "                                        #Support ist gewährleistet wenn x Koordinaten übereinstimmen -> Ist zwingend\n",
    "                                        if info[1] + ItemLength == coord[0]:\n",
    "                                            ###Untere Kante des Pakets muss kleiner gleich Urpsung des ES sein + die Weite des Stacks UND Obere Kante des Pakets muss größer gleich Ursprung des ES sein\n",
    "                                            if info[2] <= coord[1] + WidthItem and info[2] + ItemWidth >= coord[1]:\n",
    "                                                Sup = True\n",
    "                                                break        \n",
    "\n",
    "                                if Sup == True and MaxXPreviousGroups <= coord[0]:\n",
    "                                    ####Hier die imaginäre Grenze einügen. Vlt hilft das etwas? -> Soll dazu dienen, die Pakete bei niedriger 2D Volumenauslastung mehr in der Länge zu verteilen um Gewichtsconstraint besser zu approximieren\n",
    "                                    if ES_Set[es][1] <= MagicBorder:\n",
    "                                        ####Hier noch überprüfen, ob Item in dieser Orientierung die Gewichtsbedingung für alle Supplier verletzen würde\n",
    "                                        LocalSolutionCoord_Item[ii,jj] = tuple((oo, ES_Set[es][0], ES_Set[es][1], 0)) #Value: Orientierung von Item, x Koordinate, y Koordinate\n",
    "                                        feas = WeightConstr3D(dataT, dataI, tt, LocalSolutionCoord_Item)\n",
    "                                        del LocalSolutionCoord_Item[ii,jj]\n",
    "                                        if feas:\n",
    "                                            if objfunction == 'ObjWidth':\n",
    "                                               # Value = GreedyObjWidth(LengthStack, WidthStack, coord, dataT.tw[tt])\n",
    "                                                Value = GreedyObjWidth(LengthItem, coord, dataT.tl[tt])\n",
    "                                            if objfunction == 'ObjLength':\n",
    "                                                Value = GreedyObjLength(LengthItem, coord, dataT.tl[tt]) \n",
    "                                            if objfunction == 'ObjLowerLeftCorner':\n",
    "                                                Value = LowerLeftCorner(coord)  \n",
    "                                            if objfunction == \"ObjMinLength\":\n",
    "                                                Value = MinLength(coord)\n",
    "                                            if Value < BestValue:\n",
    "                                                BestValue = Value\n",
    "                                                InsertStackhere = tuple((oo,es))   \n",
    "\n",
    "                    if InsertStackhere:\n",
    "                        RemTruckWeight -= dataI.im[ii]\n",
    "                        ###Wenn Item in neues ES Set gepackt wird, steht es immer auf dem Boden\n",
    "                        LocalSolutionCoord_Item[ii,jj] = tuple((InsertStackhere[0], ES_Set[InsertStackhere[1]][0], ES_Set[InsertStackhere[1]][1], 0)) #Value: Orientierung von Stack, x Koordinate, y Koordinate, Position in Stack (0,1,2,3,... -> 0: First/Bottom Item, 1: Second Item, ....)\n",
    "                        if ES_Set[InsertStackhere[1]][0] + LengthItem > MaxLenght:\n",
    "                            MaxLenght = ES_Set[InsertStackhere[1]][0] + LengthItem\n",
    "                        #ES updaten\n",
    "                        NextItemSameGroup = True #Ist wichtig, da wir kein ES zusammenfassen wollen, wenn das nächste Item aus einer anderen Gruppe wäre, in diesem Fall könnten wir sonst die ES einschränken die die multi drop Bedingung erfüllen.\n",
    "                        if pos1 == len(OrderedItems)-1:\n",
    "                            pass\n",
    "                        else:\n",
    "                            if OrderGroup_Item[ii] != OrderGroup_Item[OrderedItems[pos1+1]]:\n",
    "                                NextItemSameGroup = False\n",
    "\n",
    "                        if pos1 == len(OrderedItems)-1:\n",
    "                            MinDim = min(min([dataI.il[iii2] for iii2 in OrderedItems[pos1:]]), min([dataI.iw[iii2] for iii2 in OrderedItems[pos1:]]))\n",
    "                        else:\n",
    "                            MinDim = min(min([dataI.il[iii2] for iii2 in OrderedItems[pos1+1:]]), min([dataI.iw[iii2] for iii2 in OrderedItems[pos1+1:]]))\n",
    "                        ES_Set = UpdateESMoreComplex3D(ES_Set, InsertStackhere, dataI, ii, MinDim)\n",
    "\n",
    "    return LocalSolutionCoord_Item, MaxLenght              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d4f16",
   "metadata": {},
   "source": [
    "## 2D Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6888389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_2DPPH(dataT, dataI, dataP, tt, ttIdx, stacking, Vol2DMustPacked=1):\n",
    "    S = stacking.S    \n",
    "    #Heuristik Jakob\n",
    "    #Vol2DMustPacked = sum([stacking.sl[ss] * stacking.sw[ss] for ss in stacking.S])\n",
    "\n",
    "   # print(\"Heuristic Factor: \" , Vol2DMustPacked)\n",
    "   # print(\"dataP.tSimplePacking: \" , dataP.tSimplePacking)\n",
    "    startHeuristic = time.perf_counter()\n",
    "    SortingOrderStacks = ['MinmassMaxvol', 'MaxvolMinmass', 'MinmassMinvol', 'MinvolMinmass', 'MinvolMaxmass', 'MaxmassMinvol', 'MaxvolMaxmass', 'MaxmassMaxvol']\n",
    "    ObjectiveFunctionsES = ['ObjLowerLeftCorner','ObjWidth', 'ObjLength', 'ObjMinLength']\n",
    "    WeightBalance = ['False','True']\n",
    "    SkipPacks = [0,1,2,3]\n",
    "    ContainerSplit = ['False', 'True']\n",
    "    FixOrientations = ['False', 'True']\n",
    "    BlockBuilding = ['False', 'True']\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    SortingOrderStacks = ['MinmassMaxvol', 'MaxvolMinmass']\n",
    "    ObjectiveFunctionsES = ['ObjLowerLeftCorner']\n",
    "    WeightBalance = ['True']\n",
    "    SkipPacks = [0]\n",
    "    ContainerSplit = ['False']\n",
    "    FixOrientations = ['False']\n",
    "    BlockBuilding = ['False']  \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    MinMaxLenght = dataT.tl[tt]\n",
    "    BestInitialValue = 0\n",
    "    BestInitialSolution = dict()\n",
    "    OptimalSolutionFoundbyHeuristic = False\n",
    "    TimeLimitReached = False\n",
    "    \n",
    "    for SkipPack in SkipPacks:\n",
    "        for blck in BlockBuilding:\n",
    "            for orderstacksheuristic in SortingOrderStacks:\n",
    "                for objectiveheuristic in ObjectiveFunctionsES:\n",
    "                    for wbal in WeightBalance:\n",
    "                        for split in ContainerSplit:\n",
    "                            for fixor in FixOrientations:\n",
    "                                if time.perf_counter() - startHeuristic > dataP.tSimplePacking:\n",
    "                                    TimeLimitReached = True\n",
    "                                  #  print(\"Heuristic Time Limit reached\")\n",
    "                                    break\n",
    "                                SolutionCoord_Stack, MaxLenght = Greedy_Heuristic(dataT, tt, stacking, orderstacksheuristic, objectiveheuristic, wbal, SkipPack, split, fixor, blck)\n",
    "                                feas = WeightConstr(dataT, tt, stacking, SolutionCoord_Stack)\n",
    "                                if not feas:\n",
    "                                    SolutionCoord_Stack = dict()\n",
    "                                if sum([stacking.svol2D[ss] for ss in SolutionCoord_Stack.keys()]) >= BestInitialValue:\n",
    "                                    ###Hier noch einen Tie Breaker -> Packplan wird bevorzugt, der kompakter ist\n",
    "                                    if sum([stacking.svol2D[ss] for ss in SolutionCoord_Stack.keys()]) == BestInitialValue:\n",
    "                                        if MaxLenght < MinMaxLenght:\n",
    "                                            MinMaxLenght = MaxLenght\n",
    "                                            BestInitialSolution = copy.deepcopy(SolutionCoord_Stack)\n",
    "                                        else:\n",
    "                                            pass    \n",
    "                                    else:\n",
    "                                        BestInitialValue = sum([stacking.svol2D[ss] for ss in SolutionCoord_Stack.keys()])\n",
    "                                        BestInitialSolution = copy.deepcopy(SolutionCoord_Stack)\n",
    "                                        MinMaxLenght = MaxLenght\n",
    "                                if BestInitialValue >= Vol2DMustPacked * dataT.tvol2D[tt]:\n",
    "                                  #  print(\"Optimal Solution Found by Heuristic\")\n",
    "                                    OptimalSolutionFoundbyHeuristic = True\n",
    "                                    break\n",
    "                                else:\n",
    "                                    #print(\"Optimal Solution not found by Heuristic\")\n",
    "                                    pass\n",
    "                            if OptimalSolutionFoundbyHeuristic or TimeLimitReached:\n",
    "                                break\n",
    "                        if OptimalSolutionFoundbyHeuristic or TimeLimitReached:\n",
    "                            break \n",
    "                    if OptimalSolutionFoundbyHeuristic or TimeLimitReached:\n",
    "                        break        \n",
    "                if OptimalSolutionFoundbyHeuristic or TimeLimitReached:\n",
    "                    break   \n",
    "            if OptimalSolutionFoundbyHeuristic or TimeLimitReached:\n",
    "                break  \n",
    "        if OptimalSolutionFoundbyHeuristic or TimeLimitReached:\n",
    "            break  \n",
    "            \n",
    "    #Heuristik Jakob        \n",
    "\n",
    "    # Create truck\n",
    "    truck = Truck(ttIdx, tt)\n",
    "    \n",
    "    # Create stacks\n",
    "    SOrdered = sorted(BestInitialSolution.keys(), key=lambda x: (BestInitialSolution[x][1], BestInitialSolution[x][2]))\n",
    "    for pos, ss in enumerate(SOrdered):\n",
    "        stack = Stack()\n",
    "        truck.Stacks.append(stack)\n",
    "\n",
    "        stack.idx = f\"{truck.idx}_{pos+1}\"\n",
    "        stack.oidx = ss\n",
    "        stack.code = code_stack(pos+1, tidx=truck.idx)\n",
    "        stack.xo = int(round(BestInitialSolution[ss][1], 0))\n",
    "        stack.yo = int(round(BestInitialSolution[ss][2], 0))\n",
    "        stack.zo = 0\n",
    "        stack.xe = int(round(BestInitialSolution[ss][1] + (stacking.sl[ss] if BestInitialSolution[ss][0] == 0 else stacking.sw[ss]), 0))\n",
    "        stack.ye = int(round(BestInitialSolution[ss][2] + (stacking.sw[ss] if BestInitialSolution[ss][0] == 0 else stacking.sl[ss]), 0))\n",
    "        stack.ze = stacking.sh[ss]\n",
    "\n",
    "        # Assign items to stack\n",
    "        height = 0\n",
    "        for pos, ii in enumerate(stacking.I_Stack[stack.oidx]):\n",
    "            item = Item()\n",
    "            item.idx = ii\n",
    "            item.code = stack.code + str(pos+1)                    \n",
    "            item.xo = stack.xo\n",
    "            item.xe = stack.xe\n",
    "            item.yo = stack.yo\n",
    "            item.ye = stack.ye   \n",
    "            item.zo = height\n",
    "            if pos > 0:\n",
    "                height += dataI.ih[ii] - dataI.ihn[ii]\n",
    "            else:\n",
    "                height += dataI.ih[ii]\n",
    "            item.ze = height\n",
    "\n",
    "            stack.Items.append(item)\n",
    "\n",
    "    \n",
    "    # Determine items not used\n",
    "    numNotPacked_Item = defaultdict(int)\n",
    "        \n",
    "    for ss in stacking.S:\n",
    "        if ss not in BestInitialSolution.keys():\n",
    "            for ii in stacking.I_Stack[ss]:\n",
    "                numNotPacked_Item[ii] += 1\n",
    "                \n",
    "    truck.check_weight(dataT, dataI)\n",
    "    \n",
    "    return truck, numNotPacked_Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b768c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Greedy_Heuristic(dataT, tt, stacking, sortorder, objfunction, wbal, SkipPack, split, fixor, blck): #Kein Empty Set überlappt sich mit anderem empty Set -> Sehr Greedy Heuristik, da immer nur ein Empty Set geupdatet werden muss wenn Stack eingefügt wird\n",
    "\n",
    "    Volumenausnutzung = min(1, sum([(stacking.sl[ss]*stacking.sw[ss]) for ss in stacking.S]) / (dataT.tl[tt]*dataT.tw[tt]))\n",
    "    MagicBorder = (min(1, Volumenausnutzung + 0.05)) * dataT.tw[tt]\n",
    " #   print(\"2D Volumen das in Greedy Heuristik gepackt werden muss: \" , Volumenausnutzung)\n",
    "    LocalSolutionCoord_Stack = dict()\n",
    "    \n",
    "    OrderTuple_Stack = dict()\n",
    "    UnloadingOrderTuple_Stack = dict() #Achtung, muss parallel in weiteres Dictionary laufen lasse, wenn ich Items nach mehr Kriterien als der (Un)loading Order sortieren möchte für die Greedy Heuristik (Gewicht, Volumen, etc)\n",
    "    for ss in stacking.S:\n",
    "        UnloadingOrderTuple_Stack[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss]))\n",
    "        if sortorder == 'MinmassMaxvol':\n",
    "            OrderTuple_Stack[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss], stacking.sm[ss], 1/(stacking.sl[ss]*stacking.sw[ss])))\n",
    "        if sortorder == 'MaxvolMinmass': \n",
    "            OrderTuple_Stack[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss], 1/(stacking.sl[ss]*stacking.sw[ss]), stacking.sm[ss]))\n",
    "        if sortorder == 'MinmassMinvol':\n",
    "            OrderTuple_Stack[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss], stacking.sm[ss], (stacking.sl[ss]*stacking.sw[ss])))\n",
    "        if sortorder == 'MinvolMinmass': \n",
    "            OrderTuple_Stack[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss], (stacking.sl[ss]*stacking.sw[ss]), stacking.sm[ss]))\n",
    "        if sortorder == 'MinvolMaxmass': \n",
    "            OrderTuple_Stack[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss], (stacking.sl[ss]*stacking.sw[ss]), 1/stacking.sm[ss]))\n",
    "        if sortorder == 'MaxmassMinvol': \n",
    "            OrderTuple_Stack[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss], 1/stacking.sm[ss], (stacking.sl[ss]*stacking.sw[ss])))\n",
    "        if sortorder == 'MaxvolMaxmass': \n",
    "            OrderTuple_Stack[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss], 1/(stacking.sl[ss]*stacking.sw[ss]), 1/stacking.sm[ss]))\n",
    "        if sortorder == 'MaxmassMaxvol': \n",
    "            OrderTuple_Stack[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss], 1/stacking.sm[ss], 1/(stacking.sl[ss]*stacking.sw[ss])))\n",
    "\n",
    "    OrderGroup_Stack = dict()\n",
    "    OrderedStacks = sorted(OrderTuple_Stack, key=lambda x: OrderTuple_Stack[x])\n",
    "\n",
    "    Group = 0\n",
    "    for pos,ii in enumerate(OrderedStacks):\n",
    "        if pos == 0:\n",
    "            OrderGroup_Stack[ii] = Group\n",
    "        else:\n",
    "            if UnloadingOrderTuple_Stack[ii] != UnloadingOrderTuple_Stack[OrderedStacks[pos-1]]:\n",
    "                Group += 1\n",
    "                OrderGroup_Stack[ii] = Group\n",
    "            else:\n",
    "                OrderGroup_Stack[ii] = Group\n",
    "       \n",
    "    #Create Empty Set = Truck Dimensions -> Key: Sets, Value: tuple mit 4 Einträgen (x,y,X,Y) Koordinate des Sets\n",
    "\n",
    "    RemTruckWeight = dataT.tm[tt]   \n",
    "    \n",
    "    ES_Set = dict()\n",
    "    if split == \"True\":\n",
    "        FirstStack = OrderedStacks[0]\n",
    "        if stacking.so[FirstStack] == 'none':\n",
    "            MaxWidthStack = max(stacking.sl[FirstStack], stacking.sw[FirstStack])\n",
    "            MinWidthStack = min(stacking.sl[FirstStack], stacking.sw[FirstStack])\n",
    "        elif stacking.so[FirstStack] == 'lengthwise':\n",
    "            MaxWidthStack = stacking.sw[FirstStack]\n",
    "            MinWidthStack = MaxWidthStack\n",
    "        else:\n",
    "            MaxWidthStack = stacking.sl[FirstStack]\n",
    "            MinWidthStack= MaxWidthStack\n",
    "        ContainerSplit = min(dataT.tw[tt]/2, MaxWidthStack)\n",
    "        if MinWidthStack > ContainerSplit:\n",
    "            ContainerSplit = MinWidthStack \n",
    "        ES_Set[0] = tuple((0,0,dataT.tl[tt], ContainerSplit))\n",
    "        ES_Set[1] = tuple((0,ContainerSplit,dataT.tl[tt], dataT.tw[tt]))\n",
    "    else:\n",
    "        ES_Set[0] = tuple((0,0,dataT.tl[tt], dataT.tw[tt]))\n",
    "        \n",
    "        #Nur durchführen, wenn es keinen Container Split gibt\n",
    "        #NUr wenn maximal 4 Stacks existieren\n",
    "        if blck == 'True' and len(OrderedStacks) > 4:\n",
    "            First4Stacks = OrderedStacks[:4]\n",
    "            FirstStack = OrderedStacks[0]\n",
    "            if stacking.sl[FirstStack] > stacking.sw[FirstStack] and all(stacking.sl[ele] == stacking.sl[FirstStack] for ele in First4Stacks) and all(stacking.sw[ele] == stacking.sw[FirstStack] for ele in First4Stacks)and all(OrderGroup_Stack[ele] == OrderGroup_Stack[FirstStack] for ele in First4Stacks) and all(stacking.so[ele] == stacking.so[FirstStack] for ele in First4Stacks) and all(stacking.so[ele] == 'none' for ele in First4Stacks):\n",
    "\n",
    "                if stacking.sl[FirstStack] * 2 > dataT.tw[tt] and stacking.sl[FirstStack] + stacking.sw[FirstStack] <= dataT.tw[tt]:\n",
    "                    if stacking.sl[ss] > stacking.sw[ss]:\n",
    "                        FirstChosenOrientation = 0\n",
    "                        SecondChosenOrientation = 1\n",
    "                    else:\n",
    "                        FirstChosenOrientation = 1\n",
    "                        SecondChosenOrientation = 0\n",
    "                    #Nur ein ES erstellen um nicht mit multi drop in Schwierigkeiten zu kommen\n",
    "                    ES_Set[0] = tuple((stacking.sl[FirstStack] + stacking.sw[FirstStack], 0, dataT.tl[tt], dataT.tw[tt]))\n",
    "                    LocalSolutionCoord_Stack[OrderedStacks[0]] = tuple((FirstChosenOrientation, 0, 0)) #Value: Orientierung von Stack, x Koordinate, y Koordinate\n",
    "                    LocalSolutionCoord_Stack[OrderedStacks[1]] = tuple((SecondChosenOrientation, 0, stacking.sw[FirstStack])) #Value: Orientierung von Stack, x Koordinate, y Koordinate\n",
    "                    LocalSolutionCoord_Stack[OrderedStacks[2]] = tuple((SecondChosenOrientation, stacking.sl[FirstStack], 0)) #Value: Orientierung von Stack, x Koordinate, y Koordinate\n",
    "                    LocalSolutionCoord_Stack[OrderedStacks[3]] = tuple((FirstChosenOrientation, stacking.sw[FirstStack], stacking.sl[FirstStack])) #Value: Orientierung von Stack, x Koordinate, y Koordinate\n",
    "\n",
    "                    RemTruckWeight -= stacking.sm[OrderedStacks[0]]\n",
    "                    RemTruckWeight -= stacking.sm[OrderedStacks[1]]\n",
    "                    RemTruckWeight -= stacking.sm[OrderedStacks[2]]\n",
    "                    RemTruckWeight -= stacking.sm[OrderedStacks[3]]\n",
    "                    \n",
    "                    OrderedStacks = OrderedStacks[len(First4Stacks):]\n",
    "                    #Verbleibende Stacks nochmal nach Größe ordnen\n",
    "                    #Große Stacks, bis auf das schon eingelagerte Quadrat sollen nun als nächstes eingelagert werden\n",
    "                    OrderTuple_Stack2 = dict()\n",
    "                    for ss in OrderedStacks:\n",
    "                        OrderTuple_Stack2[ss] = tuple((dataT.te[tt, stacking.su[ss]], dataT.tke[tt, stacking.su[ss], stacking.sk[ss]], dataT.tge[tt, dataT.tp[tt], stacking.sg[ss][0]], stacking.sMulti[ss], 1/(stacking.sl[ss]*stacking.sw[ss]), stacking.sm[ss]))\n",
    "                    OrderedStacks = sorted(OrderTuple_Stack2, key=lambda x: OrderTuple_Stack2[x])  \n",
    "                else:\n",
    "                    return dict(), dataT.tl[tt]\n",
    "            else:\n",
    "                return dict(), dataT.tl[tt]\n",
    "                           \n",
    "\n",
    "    \n",
    "    MaxLenght = 0 ####We use MaxLenght as a Tie Breaker\n",
    "    #So lange bis jeder Stack einmal betrachtet wurde\n",
    "    for pos1, ss in enumerate(OrderedStacks):\n",
    "        if RemTruckWeight >= stacking.sm[ss]:\n",
    "            #Multi Drop noch berücksichtigen\n",
    "            if LocalSolutionCoord_Stack and OrderGroup_Stack[ss] > 0:\n",
    "                MaxXPreviousGroups = max([LocalSolutionCoord_Stack[sss][1] for sss in LocalSolutionCoord_Stack.keys() if OrderGroup_Stack[sss] < OrderGroup_Stack[ss]]+[0])\n",
    "            else:\n",
    "                MaxXPreviousGroups = 0\n",
    "            BestValue = float('inf')\n",
    "            InsertStackhere = tuple(()) #Tuple hat die Informationen Orientierung, ESKey\n",
    "            #Für jede mögliche Orientierung des Stacks\n",
    "            if stacking.so[ss] == 'none':\n",
    "                if fixor == 'False':\n",
    "                    Orientations = [0,1]\n",
    "                    #Orientierungen Greedy Einschränken, z.B. für Pakete mit Maßen 1600,1200\n",
    "                    Ratios = []\n",
    "                    Ratios.append((math.floor(dataT.tw[tt] / stacking.sw[ss]) * stacking.sw[ss]) / dataT.tw[tt])\n",
    "                    Ratios.append((math.floor(dataT.tw[tt] / stacking.sl[ss]) * stacking.sl[ss]) / dataT.tw[tt])\n",
    "                    if max(Ratios) > 0.95:\n",
    "                        if Ratios[0] == Ratios[1]:\n",
    "                            if stacking.sw[ss] > stacking.sl[ss]:\n",
    "                                Orientations = [0]\n",
    "                            else:\n",
    "                                Orientations = [1]\n",
    "                        else:\n",
    "                            if stacking.sl[ss] == stacking.sw[ss]:\n",
    "                                Orientations = [0]\n",
    "                            else:\n",
    "                                Orientations = [Ratios.index(max(Ratios))]\n",
    "                else: #Hier die Weite auf kleinere Länge fixieren\n",
    "                    if stacking.sl[ss] > stacking.sw[ss]:\n",
    "                        Orientations = [0]\n",
    "                    else:\n",
    "                        Orientations = [1]                \n",
    "\n",
    "            elif stacking.so[ss] == 'lengthwise':\n",
    "                Orientations = [0]\n",
    "            else:\n",
    "                Orientations = [1]\n",
    "            for oo in Orientations:\n",
    "                #Jedes Set überprüfen in welches der Stack einsortiert werden soll\n",
    "                for es, coord in ES_Set.items():\n",
    "                    if oo == 0:\n",
    "                        LengthStack = stacking.sl[ss]\n",
    "                        WidthStack = stacking.sw[ss]\n",
    "                    else:\n",
    "                        LengthStack = stacking.sw[ss]\n",
    "                        WidthStack = stacking.sl[ss] \n",
    "\n",
    "                    #ES verbieten, wenn z.B. kein Stack über den ersten n Stacks stehen sollen\n",
    "                    KeyPackages = sorted([xx for xx, value in LocalSolutionCoord_Stack.items() if value[2] == 0], key=lambda x: LocalSolutionCoord_Stack[x][1])\n",
    "                    if SkipPack == 0 or len(KeyPackages) == 0:\n",
    "                        ThresholdLength = -1\n",
    "                    else:\n",
    "                        IdxKeyPackage = min(SkipPack, len(KeyPackages)) - 1\n",
    "                        KeyPackage = KeyPackages[IdxKeyPackage]\n",
    "                        ThresholdLength = LocalSolutionCoord_Stack[KeyPackage][1]\n",
    "                    if coord[1] > 0 and coord[0] <= ThresholdLength:\n",
    "                        pass\n",
    "                    else:\n",
    "                        #ES nur betrachten, wenn Stack überhaupt hineinpassen könnte\n",
    "                        if LengthStack <= coord[2]-coord[0] and WidthStack <= coord[3]-coord[1]:\n",
    "                            #Hier überprüfen ob Origin des ES von einem anderen Paket supportet wird\n",
    "                            Sup = False\n",
    "                            if coord[0] == 0:\n",
    "                                Sup = True\n",
    "                            else:\n",
    "                                for ss2, info in LocalSolutionCoord_Stack.items():\n",
    "                                    if info[0] == 0:\n",
    "                                        StackLength = stacking.sl[ss2]\n",
    "                                        StackWidth = stacking.sw[ss2]\n",
    "                                    else:\n",
    "                                        StackLength = stacking.sw[ss2]\n",
    "                                        StackWidth = stacking.sl[ss2]\n",
    "                                    #Support ist gewährleistet wenn x Koordinaten übereinstimmen -> Ist zwingend\n",
    "                                    if info[1] + StackLength == coord[0]:\n",
    "                                        ###Untere Kante des Pakets muss kleiner gleich Urpsung des ES sein + die Weite des Stacks UND Obere Kante des Pakets muss größer gleich Ursprung des ES sein\n",
    "                                        if info[2] <= coord[1] + WidthStack and info[2] + StackWidth >= coord[1]:\n",
    "                                            Sup = True\n",
    "                                            break\n",
    "                            if Sup == True and MaxXPreviousGroups <= coord[0]:\n",
    "                                ####Hier die imaginäre Grenze einügen. Vlt hilft das etwas? -> Soll dazu dienen, die Pakete bei niedriger 2D Volumenauslastung mehr in der Länge zu verteilen um Gewichtsconstraint besser zu approximieren\n",
    "                                if ES_Set[es][1] <= MagicBorder:\n",
    "                                    ####Hier noch überprüfen, ob Item in dieser Orientierung die Gewichtsbedingung für alle Supplier verletzen würde\n",
    "                                    LocalSolutionCoord_Stack[ss] = tuple((oo, ES_Set[es][0], ES_Set[es][1])) #Value: Orientierung von Stack, x Koordinate, y Koordinate\n",
    "                                    if wbal == 'False':\n",
    "                                        feas = WeightConstr(dataT, tt, stacking, LocalSolutionCoord_Stack)\n",
    "                                    else:\n",
    "                                        RemStacks = [] if pos1 == len(OrderedStacks)-1 else OrderedStacks[pos1+1:]\n",
    "                                        feas = WeightConstrWeightBalance(dataT, tt, stacking, LocalSolutionCoord_Stack, Volumenausnutzung, RemStacks)\n",
    "                                    del LocalSolutionCoord_Stack[ss]\n",
    "                                    if feas:\n",
    "                                        if objfunction == 'ObjWidth':\n",
    "                                           # Value = GreedyObjWidth(LengthStack, WidthStack, coord, dataT.tw[tt])\n",
    "                                            Value = GreedyObjWidth(LengthStack, coord, dataT.tl[tt])\n",
    "                                        if objfunction == 'ObjLength':\n",
    "                                            Value = GreedyObjLength(LengthStack, coord, dataT.tl[tt]) \n",
    "                                        if objfunction == 'ObjLowerLeftCorner':\n",
    "                                            Value = LowerLeftCorner(coord)\n",
    "                                        if objfunction == \"ObjMinLength\":\n",
    "                                            Value = MinLength(coord)\n",
    "                                        if Value < BestValue:\n",
    "                                            BestValue = Value\n",
    "                                            InsertStackhere = tuple((oo,es))\n",
    "\n",
    "            if InsertStackhere:\n",
    "                RemTruckWeight -= stacking.sm[ss]\n",
    "                LocalSolutionCoord_Stack[ss] = tuple((InsertStackhere[0], ES_Set[InsertStackhere[1]][0], ES_Set[InsertStackhere[1]][1])) #Value: Orientierung von Stack, x Koordinate, y Koordinate\n",
    "                if ES_Set[InsertStackhere[1]][0] + LengthStack > MaxLenght:\n",
    "                    MaxLenght = ES_Set[InsertStackhere[1]][0] + LengthStack\n",
    "                #ES updaten\n",
    "                NextItemSameGroup = True #Ist wichtig, da wir kein ES zusammenfassen wollen, wenn das nächste Item aus einer anderen Gruppe wäre, in diesem Fall könnten wir sonst die ES einschränken die die multi drop Bedingung erfüllen.\n",
    "                if pos1 == len(OrderedStacks)-1:\n",
    "                    pass\n",
    "                else:\n",
    "                    if OrderGroup_Stack[ss] != OrderGroup_Stack[OrderedStacks[pos1+1]]:\n",
    "                        NextItemSameGroup = False\n",
    "\n",
    "                if pos1 == len(OrderedStacks)-1:\n",
    "                    MinDim = min(min([stacking.sl[sss2] for sss2 in OrderedStacks[pos1:]]), min([stacking.sw[sss2] for sss2 in OrderedStacks[pos1:]]))\n",
    "                else:\n",
    "                    MinDim = min(min([stacking.sl[sss2] for sss2 in OrderedStacks[pos1+1:]]), min([stacking.sw[sss2] for sss2 in OrderedStacks[pos1+1:]]))\n",
    "                    \n",
    "                if split == \"True\":\n",
    "                    ES_Set = UpdateES(ES_Set, InsertStackhere, stacking, ss, NextItemSameGroup, MinDim, LocalSolutionCoord_Stack)\n",
    "                else:\n",
    "                    ES_Set = UpdateESMoreComplex(ES_Set, InsertStackhere, stacking, ss, MinDim)\n",
    "                \n",
    "\n",
    "    return LocalSolutionCoord_Stack, MaxLenght"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43409f",
   "metadata": {},
   "source": [
    "# Packing MIPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd65ef7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0c8533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softTimePacking2DModel(model, where):\n",
    "    if where == GRB.Callback.MIP:\n",
    "        runtime = model.cbGet(GRB.Callback.RUNTIME)\n",
    "        best = round(model.cbGet(GRB.Callback.MIP_OBJBST),4)\n",
    "        if best > model._objBest and best > model._objHeu:\n",
    "            print(f\"MIP Improvement - 2D Vol: {best} [m2] - packed 2D Vol Ratio: {best / model._tvol2DTruck} [%] - after {runtime} [s]\")                                                      #Für Fynn\n",
    "            model._objBest = best        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93b91a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_2DPPM(dataT, dataI, dataP, tt, ttIdx, stacking, timeLimit):\n",
    "    # Preprocessing\n",
    "    print(f\"2D Packing MIP with Time Limit {timeLimit} [s] in Truck {tt}\")                                                      #Für Fynn\n",
    "    \n",
    "    truckHeu, numNotPacked_Item = solve_2DPPH(dataT, dataI, dataP, tt, ttIdx, stacking)\n",
    "\n",
    "    S = stacking.S\n",
    "    UOrdered = sorted(dataT.TU[tt], key=lambda x: dataT.te[tt, x])\n",
    "    S_Supplier = {uu: [] for uu in  UOrdered}\n",
    "\n",
    "    for ss in S:\n",
    "        S_Supplier[stacking.su[ss]].append(ss)\n",
    "    tm = {uuu: min(dataT.tm[tt], max(1e-5, sum([stacking.sm[ss] for uu in UOrdered[:pos+1] for ss in S_Supplier[uu]]))) for pos, uuu in enumerate(UOrdered)}\n",
    "    \n",
    "    \n",
    "    m = Model('2D-Packing Problem')\n",
    "    \n",
    "    # Position\n",
    "    xx = tupledict()  # x Coordinate \n",
    "    yy = tupledict()  # y Coordinate \n",
    "    omega = tupledict() #  Orientation, 0: Lengthwise, 1: Widthwise\n",
    "    \n",
    "    # Dependency\n",
    "    # View of the truck from above, left for length of truck, before for width of truck\n",
    "    ll = tupledict() # i, j: i left  j \n",
    "    vv = tupledict() # i, j: i before j\n",
    "    \n",
    "    # Support\n",
    "    supS = tupledict() # i, j: i supports j\n",
    "    supW = tupledict() # i: i on wall\n",
    "    \n",
    "    # Weight\n",
    "    eje = tupledict()\n",
    "    ejr = tupledict()\n",
    "    emh = tupledict()\n",
    "    emr = tupledict()\n",
    "    emm = tupledict()\n",
    "\n",
    "    # Fill Variabels\n",
    "    for ss in S:\n",
    "        ## Position\n",
    "        xx[ss] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"x[{ss}]\")\n",
    "        yy[ss] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"y[{ss}]\") \n",
    "        for oo in range(2):\n",
    "            omega[ss, oo] = m.addVar(vtype=GRB.BINARY, name=f\"omega[{ss},{oo}]\")\n",
    "\n",
    "        ## Dependency and support\n",
    "        supW[ss] = m.addVar(vtype=GRB.BINARY, name=f\"supW[{ss}]\")\n",
    "    \n",
    "    ## Dependency and support\n",
    "    for ss1, ss2 in itertools.permutations(S, 2):\n",
    "        ll[ss1, ss2] = m.addVar(vtype=GRB.BINARY, name=f\"ll[{ss1},{ss2}]\")\n",
    "        vv[ss1, ss2] = m.addVar(vtype=GRB.BINARY, name=f\"vv[{ss1},{ss2}]\")\n",
    "        supS[ss1, ss2] = m.addVar(vtype=GRB.BINARY, name=f\"supS[{ss1},{ss2}]\")    \n",
    "    \n",
    "    ## Weight\n",
    "    for uu in UOrdered:\n",
    "        eje[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"eje[{uu}]\")\n",
    "        ejr[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"ejr[{uu}]\")\n",
    "        emh[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"emh[{uu}]\")\n",
    "        emr[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"emr[{uu}]\")\n",
    "        emm[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"emm[{uu}]\")\n",
    "        \n",
    "        \n",
    "    for ss in stacking.S:\n",
    "        print(f\"Stack {ss} with items: {stacking.I_Stack[ss]}\")         #Für Fynn\n",
    "    \n",
    "    \n",
    "    constrStartSol = []\n",
    "    SFixed = set()\n",
    "    for stack in truckHeu.Stacks:\n",
    "        SFixed.add(stack.oidx)\n",
    "        constrStartSol.append(m.addConstr(xx[stack.oidx] == stack.xo))\n",
    "        constrStartSol.append(m.addConstr(yy[stack.oidx] == stack.yo))        \n",
    "        \n",
    "    for ss in stacking.S:\n",
    "        if ss not in SFixed:\n",
    "            constrStartSol.append(m.addConstr(omega[ss, 0] + omega[ss, 1] == 0))\n",
    "        else:\n",
    "            constrStartSol.append(m.addConstr(omega[ss, 0] + omega[ss, 1] == 1))\n",
    "        \n",
    "    \n",
    "       \n",
    "      \n",
    "\n",
    "   \n",
    "    \n",
    "    # Objective\n",
    "    m.setObjective(quicksum(stacking.svol2D[ss] * (omega[ss, 0] + omega[ss, 1]) for ss in stacking.S), GRB.MAXIMIZE)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Stack in truck\n",
    "    for ss in S:\n",
    "        ## Orientation\n",
    "        ## If stack is packed, only one orientation\n",
    "        m.addConstr(omega[ss, 0] + omega[ss, 1]\n",
    "                    <= 1, name=f\"OrientationOnlyOne[{ss}]\")        \n",
    "        ## Forbid orientations for fixed stacks\n",
    "        if \"lengthwise\" == stacking.so[ss]:\n",
    "            m.addConstr(omega[ss, 1] \n",
    "                        == 0, name=f\"OrientationForbidL[{ss}]\")\n",
    "        elif \"widthwise\" == stacking.so[ss]:\n",
    "            m.addConstr(omega[ss, 0] \n",
    "                        == 0, name=f\"OrientationForbidW[{ss}]\")      \n",
    "        ## Length and width of truck considered\n",
    "        m.addConstr(xx[ss] + stacking.sl[ss] * omega[ss, 0] + stacking.sw[ss] * omega[ss, 1]\n",
    "                    <= dataT.tl[tt], name=f\"TruckLength[{ss}]\")\n",
    "        m.addConstr(yy[ss] + stacking.sw[ss] * omega[ss, 0] + stacking.sl[ss] * omega[ss, 1]\n",
    "                    <= dataT.tw[tt], name=f\"TruckWidth[{ss}]\")\n",
    "        ## If stack in truck support through wall or other stack is required\n",
    "        m.addConstr(supW[ss] + quicksum(supS[ss2, ss] for ss2 in S if ss != ss2)\n",
    "                    >= omega[ss, 0] + omega[ss, 1], name=f\"Support[{ss}]\")            \n",
    "        ## If support wall stack must be at front of truck\n",
    "        m.addConstr(xx[ss]\n",
    "                    <= dataT.tl[tt] * (1 - supW[ss]), name=f\"SupportWall[{ss}]\")   \n",
    "\n",
    "    # Relation between two stacks\n",
    "    for ss1, ss2 in itertools.permutations(S, 2):\n",
    "        ## Stacks can only support each other if both stacks are packed\n",
    "        m.addConstr(supS[ss1, ss2]\n",
    "                    <= omega[ss1, 0] + omega[ss1, 1], name=f\"SupportItems1[{ss1},{ss2}]\")   \n",
    "        m.addConstr(supS[ss1, ss2]\n",
    "                    <= omega[ss2, 0] + omega[ss2, 1], name=f\"SupportItems2[{ss1},{ss2}]\") \n",
    "        ## Stacks left of other stacks cannot overlap\n",
    "        m.addConstr(xx[ss1] + stacking.sl[ss1] * omega[ss1, 0] + stacking.sw[ss1] * omega[ss1, 1]\n",
    "                    <= xx[ss2] + dataT.tl[tt] * (1 - ll[ss1, ss2]), name=f\"OverlapLeft[{ss1},{ss2}]\")\n",
    "        ## Stacks before other stacks cannot overlap\n",
    "        m.addConstr(yy[ss1] + stacking.sw[ss1] * omega[ss1, 0] + stacking.sl[ss1] * omega[ss1, 1]\n",
    "                    <= yy[ss2] + dataT.tw[tt] * (1 - vv[ss1, ss2]), name=f\"OverlapBefore[{ss1},{ss2}]\")\n",
    "        ## Stacks have to be beside each other\n",
    "        m.addConstr(ll[ss1, ss2] + ll[ss2, ss1] + vv[ss1, ss2] + vv[ss2, ss1]  >= 1, name=f\"LeftBefore[{ss1},{ss2}]\")\n",
    "        ## Positioning between two stacks that support each other\n",
    "        m.addConstr(xx[ss1] + stacking.sl[ss1] * omega[ss1, 0] + stacking.sw[ss1] * omega[ss1, 1]\n",
    "                    <= xx[ss2] + dataT.tl[tt] * (1 - supS[ss1, ss2])  , name=f\"SupportX1[{ss1},{ss2}]\")\n",
    "        m.addConstr(xx[ss1] + stacking.sl[ss1] * omega[ss1, 0] + stacking.sw[ss1] * omega[ss1, 1]\n",
    "                    >= xx[ss2] - dataT.tl[tt] * (1 - supS[ss1, ss2])  , name=f\"SupportX2[{ss1},{ss2}]\")\n",
    "        m.addConstr(yy[ss1] + stacking.sw[ss1] * omega[ss1, 0] + stacking.sl[ss1] * omega[ss1, 1]\n",
    "                    >= yy[ss2] - dataT.tw[tt] * (1 - supS[ss1, ss2])  , name=f\"SupportY1[{ss1},{ss2}]\")\n",
    "        m.addConstr(yy[ss1]\n",
    "                    <= yy[ss2] + stacking.sw[ss2] * omega[ss2, 0] + stacking.sl[ss2] * omega[ss2, 1] + dataT.tw[tt] * (1 - supS[ss1, ss2]), name=f\"SupportY1[{ss1},{ss2}]\")\n",
    "\n",
    "    # Multi drop\n",
    "    for ss1, ss2 in itertools.permutations(S, 2):         \n",
    "        if dataT.te[tt, stacking.su[ss1]] < dataT.te[tt, stacking.su[ss2]]:\n",
    "            ## Restrict position and dependacy if supplier order is different (P4-1)\n",
    "            m.addConstr(xx[ss1]\n",
    "                        <= xx[ss2], name=f\"MultiSupplierPosition[{ss1},{ss2}]\")\n",
    "            m.addConstr(ll[ss2,ss1]\n",
    "                        <= 0, name=f\"MultiSupplierLeft[{ss1},{ss2}]\") \n",
    "\n",
    "        elif dataT.te[tt, stacking.su[ss1]] == dataT.te[tt, stacking.su[ss2]]:\n",
    "            if dataT.tke[tt, stacking.su[ss1], stacking.sk[ss1]] != 0 and dataT.tke[tt, stacking.su[ss2], stacking.sk[ss2]] != 0:\n",
    "                if dataT.tke[tt, stacking.su[ss1], stacking.sk[ss1]] < dataT.tke[tt, stacking.su[ss2], stacking.sk[ss2]]:\n",
    "                    ## Restrict position and dependacy if supplier dock order is different (P4-2)\n",
    "                    m.addConstr(xx[ss1]\n",
    "                                <= xx[ss2], name=f\"MultiSupplierDockPosition[{ss1},{ss2}]\")\n",
    "                    m.addConstr(ll[ss2, ss1]\n",
    "                                <= 0, name=f\"MultiSupplierDockLeft[{ss1},{ss2}]\")  \n",
    "\n",
    "\n",
    "            if dataT.tke[tt, stacking.su[ss1], stacking.sk[ss1]] == dataT.tke[tt, stacking.su[ss2], stacking.sk[ss2]]:\n",
    "                if stacking.sMulti[ss1] == 0 and stacking.sMulti[ss2] == 0:\n",
    "                    ## Restrict position and dependacy if plant dock order is different (P4-3)\n",
    "                    if dataT.tge[tt, dataT.tp[tt], stacking.sg[ss1][0]] < dataT.tge[tt, dataT.tp[tt], stacking.sg[ss2][0]]:\n",
    "                        m.addConstr(xx[ss1]\n",
    "                                    <= xx[ss2], name=f\"MultiPlantDockPosition[{ss1},{ss2}]\")\n",
    "                        m.addConstr(ll[ss2, ss1]\n",
    "                                    <= 0, name=f\"MultiPlantDockLeft[{ss1},{ss2}]\")\n",
    "                else:\n",
    "                    ## Multi Stack\n",
    "                    if dataT.tge[tt, dataT.tp[tt], stacking.sg[ss1][-1]] < dataT.tge[tt, dataT.tp[tt], stacking.sg[ss2][0]]:\n",
    "                        m.addConstr(xx[ss1]\n",
    "                                    <= xx[ss2], name=f\"MultiStackPosition1[{ss1},{ss2}]\")\n",
    "                        m.addConstr(ll[ss2, ss1]\n",
    "                                    <= 0, name=f\"MultiStackLeft1[{ss1},{ss2}]\")\n",
    "                    elif dataT.tge[tt, dataT.tp[tt], stacking.sg[ss1][-1]] > dataT.tge[tt, dataT.tp[tt], stacking.sg[ss2][0]]:\n",
    "                        m.addConstr(xx[ss2]\n",
    "                                    <= xx[ss1], name=f\"MultiStackPosition2[{ss1},{ss2}]\")\n",
    "                        m.addConstr(ll[ss1, ss2]\n",
    "                                    <= 0, name=f\"MultiStackLeft2[{ss1},{ss2}]\")\n",
    "                    if dataT.tge[tt, dataT.tp[tt], stacking.sg[ss1][0]] < dataT.tge[tt, dataT.tp[tt], stacking.sg[ss2][-1]]:\n",
    "                        m.addConstr(xx[ss1]\n",
    "                                    <= xx[ss2], name=f\"MultiStackPosition3[{ss1},{ss2}]\")\n",
    "                        m.addConstr(ll[ss2, ss1]\n",
    "                                    <= 0, name=f\"MultiStackLeft3[{ss1},{ss2}]\")\n",
    "                    elif dataT.tge[tt, dataT.tp[tt], stacking.sg[ss1][0]] > dataT.tge[tt, dataT.tp[tt], stacking.sg[ss2][-1]]:\n",
    "                        m.addConstr(xx[ss2]\n",
    "                                    <= xx[ss1], name=f\"MultiStackPosition4[{ss1},{ss2}]\")\n",
    "                        m.addConstr(ll[ss1, ss2]\n",
    "                                    <= 0, name=f\"MultiStackLeft4[{ss1},{ss2}]\") \n",
    "\n",
    "                        \n",
    "    #2D Volumen Constraints -> It is possible, that Stack Building failed and we try to load more than 100% of the 2D Truck Vol\n",
    "    m.addConstr(quicksum(stacking.sl[ss] * stacking.sw[ss] * (omega[ss, 0] + omega[ss, 1]) for ss in stacking.S)\n",
    "                <= dataT.tl[tt]*dataT.tw[tt], name=\"2DVolLimitTruck\")\n",
    "    \n",
    "    # Weight constraints\n",
    "    ## Wight limit truck (W1)\n",
    "    m.addConstr(quicksum(stacking.sm[ss] * (omega[ss, 0] + omega[ss, 1]) for ss in stacking.S)\n",
    "                <= dataT.tm[tt], name=\"WeightLimitTruck\")\n",
    "\n",
    "    ## Weight on axis (W2)\n",
    "    for pos, uuu in enumerate(UOrdered):\n",
    "        m.addConstr(quicksum((xx[ss] + (stacking.sl[ss] * omega[ss, 0] + stacking.sw[ss] * omega[ss, 1])/2) * stacking.sm[ss]  for uu in UOrdered[:pos+1] for ss in S_Supplier[uu]) / tm[uuu]\n",
    "                    == eje[uuu], name=f\"eje[{uuu}]\")\n",
    "        m.addConstr(dataT.ejeh[tt] + dataT.ejhr[tt] - eje[uuu]\n",
    "                    == ejr[uuu], name=f\"ejr[{uuu}]\")\n",
    "        m.addConstr((tm[uuu] * ejr[uuu] + dataT.em[tt] * dataT.ejcr[tt]) / dataT.ejhr[tt]\n",
    "                    == emh[uuu], name=f\"emh[{uuu}]\")\n",
    "        m.addConstr(tm[uuu] + dataT.em[tt] - emh[uuu]\n",
    "                    == emr[uuu], name=f\"emr[{uuu}]\")\n",
    "        m.addConstr((dataT.cm[tt] * dataT.cjfc[tt] + emh[uuu] * dataT.cjfh[tt]) / dataT.cjfm[tt]\n",
    "                    == emm[uuu], name=f\"emm[{uuu}]\")\n",
    "        \n",
    "    ## Constraint W2\n",
    "    for uu in UOrdered:\n",
    "        m.addConstr(emm[uu]\n",
    "                    <= dataT.emmm[tt], name=f\"emmm[{uu}]\")\n",
    "        m.addConstr(emr[uu]\n",
    "                    <= dataT.emmr[tt], name=f\"emmr[{uu}]\")                                \n",
    "        \n",
    "    \n",
    "    # Symmetry breaking left and before\n",
    "    for ss1, ss2 in itertools.permutations(S, 2):\n",
    "        m.addConstr(supS[ss1, ss2]\n",
    "                    <= ll[ss1, ss2], name=f\"SymmetryL[{ss1},{ss2}]\")\n",
    "        m.addConstr(supS[ss1, ss2]\n",
    "                    <= 1 - vv[ss1, ss2], name=f\"SymmetryB[{ss1},{ss2}]\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    #Funktioniert sehr gut, Achtung jedoch bei Initial Solution, diese kann eventuell infeasible sein wegen falscher Stack Reihenfolge. -> Nur Anwenden wenn Initial keine optimale Lösung bietet    \n",
    "    #Identsiche Stacks einschränken -> Homogene Stacks\n",
    "    for pos, ss1 in enumerate(S):\n",
    "        for ss2 in S[pos+1:]:\n",
    "            if stacking.sl[ss1] == stacking.sl[ss2] and stacking.sw[ss1] == stacking.sw[ss2] and stacking.so[ss1] == stacking.so[ss2] and stacking.su[ss1] == stacking.su[ss2] and stacking.sk[ss1] == stacking.sk[ss2] and stacking.sg[ss1] == stacking.sg[ss2] and stacking.sMulti[ss1] == stacking.sMulti[ss2] and stacking.sm[ss1] == stacking.sm[ss2]:\n",
    "                m.addConstr(ll[ss2, ss1] == 0)\n",
    "                m.addConstr(vv[ss2, ss1] == 0)\n",
    "                m.addConstr(xx[ss1] <= xx[ss2])\n",
    "                 \n",
    "    for ss1 in S:\n",
    "        for ss2 in S:\n",
    "            if stacking.sl[ss1] == stacking.sl[ss2] and stacking.sw[ss1] == stacking.sw[ss2] and stacking.so[ss1] == stacking.so[ss2] and stacking.su[ss1] == stacking.su[ss2] and stacking.sk[ss1] == stacking.sk[ss2] and stacking.sg[ss1] == stacking.sg[ss2] and stacking.sMulti[ss1] == stacking.sMulti[ss2] and stacking.sm[ss1] < stacking.sm[ss2]:\n",
    "                m.addConstr(ll[ss2, ss1] == 0)\n",
    "                m.addConstr(xx[ss1] <= xx[ss2])\n",
    "    #Identsiche Stacks einschränken -> Homogene Stacks    \n",
    "    \n",
    "         \n",
    "        \n",
    "        \n",
    "  \n",
    "    # Start optimization\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    m.setParam('Threads', 8)\n",
    "    m.setParam('MIPFocus', 1)\n",
    "    m._objHeu = round(sum([(stack.xe - stack.xo) * (stack.ye - stack.yo) for stack in truckHeu.Stacks]) / 1_000_000 , 5)\n",
    "    m._objBest = 0\n",
    "    m.setParam('Timelimit', timeLimit)\n",
    "    \n",
    "    # Start solution\n",
    "    m.optimize()\n",
    "    for constr in constrStartSol:\n",
    "        m.remove(constr)\n",
    "    \n",
    "    StartTimeMIP = time.perf_counter()\n",
    "    \n",
    "    SolStacksHeu = [stack.oidx for stack in truckHeu.Stacks]\n",
    "    SolStacksHeu.sort()\n",
    "    #Heuristische Startlösung\n",
    "    print(f\"MIP Improvement - 2D Vol: {m._objHeu} [m2] - packed 2D Vol Ratio: {m._objHeu / dataT.tvol2D[tt]} [%] - after {0.000000000000000000} [s] without stacks:\")          #Für Fynn \n",
    "    for ss in stacking.S:                                                                #Für Fynn\n",
    "        if ss not in SolStacksHeu:                                                       #Für Fynn\n",
    "            print(f\"Stack {ss} missing: {stacking.I_Stack[ss]}\")      #Für Fynn \n",
    "   \n",
    "    m._limitTime = timeLimit\n",
    "    m._tvol2DTruck = dataT.tvol2D[tt] #Für Fynn\n",
    "\n",
    "    \n",
    "    m.optimize(softTimePacking2DModel) \n",
    "    \n",
    "    if m.status != 3:\n",
    "        if round(m.ObjVal, 5) > m._objHeu and round(m.ObjVal, 5) > m._objBest:\n",
    "            print(f\"MIP Improvement - 2D Vol: {round(m.ObjVal, 5)} [m2] - packed 2D Vol Ratio: {round(m.ObjVal, 5) / dataT.tvol2D[tt]} [%] - after {time.perf_counter() - StartTimeMIP} [s]\")         #Für Fynn\n",
    "            pass\n",
    "    if m.status == 2: #or time.perf_counter() - StartTimeMIP < timeLimit / 2: #Die zweite Abfrage muss getan werden, falls Solver gar nicht in die MIP Nodes geht\n",
    "        print(f\"Optimal Solution confirmed after {time.perf_counter() - StartTimeMIP} [s]\")         #Für Fynn\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Solve interrupted after {time.perf_counter() - StartTimeMIP} [s]\")         #Für Fynn\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "    if m.SolCount < 1 or sum([(stack.xe - stack.xo) * (stack.ye - stack.yo) / 1_000_000 for stack in truckHeu.Stacks]) >= sum([stacking.svol2D[ss] for ss in stacking.S if round(omega[ss, 0].X) == 1 or round(omega[ss, 1].X) == 1]):\n",
    "        stackUsed = set([stack.oidx for stack in truckHeu.Stacks]) #Für Fynn\n",
    "        print(\"Stacks not packed:\")                                #Für Fynn\n",
    "        for ss in stacking.S:                                      #Für Fynn\n",
    "            if ss not in stackUsed:                                #Für Fynn\n",
    "                print(f\"Stack {ss} not in final solution with items: {stacking.I_Stack[ss]}\")                    #Für Fynn     \n",
    "                pass\n",
    "        return truckHeu, numNotPacked_Item\n",
    "    else:\n",
    "        # Create truck\n",
    "        truck = Truck(ttIdx, tt)\n",
    "        \n",
    "   #     print(\"§\" * 50)\n",
    "   #     print(\"§\" * 50)\n",
    "   #     print(\"Check weight 2D packing\" , tt, ttIdx, dataT.tm[tt])\n",
    "\n",
    "        # Create stacks\n",
    "        SOrdered = sorted(stacking.S, key=lambda x: (xx[x].X, yy[x].X))\n",
    "        for pos, ss in enumerate(SOrdered):\n",
    "            if round(omega[ss, 0].X + omega[ss, 1].X, 0) == 1:\n",
    "              #  print(\"Stack\", ss, \"weights\", stacking.sm[ss])\n",
    "                stack = Stack()\n",
    "                truck.Stacks.append(stack)\n",
    "\n",
    "                stack.idx = f\"{truck.idx}_{pos+1}\"\n",
    "                stack.oidx = ss\n",
    "                stack.code = code_stack(pos+1, tidx=truck.idx)\n",
    "                stack.xo = int(round(xx[ss].X, 0))\n",
    "                stack.yo = int(round(yy[ss].X, 0))\n",
    "                stack.zo = 0\n",
    "                stack.xe = int(round(xx[ss].X + stacking.sl[ss] * omega[ss, 0].X + stacking.sw[ss] * omega[ss, 1].X, 0))\n",
    "                stack.ye = int(round(yy[ss].X + stacking.sw[ss] * omega[ss, 0].X + stacking.sl[ss] * omega[ss, 1].X, 0))\n",
    "                stack.ze = stacking.sh[ss]\n",
    "\n",
    "                # Assign items to stack\n",
    "                height = 0\n",
    "                for pos, ii in enumerate(stacking.I_Stack[stack.oidx]):\n",
    "                    item = Item()\n",
    "                    item.idx = ii\n",
    "                    item.code = stack.code + str(pos+1)                    \n",
    "                    item.xo = stack.xo\n",
    "                    item.xe = stack.xe\n",
    "                    item.yo = stack.yo\n",
    "                    item.ye = stack.ye   \n",
    "                    item.zo = height\n",
    "                    if pos > 0:\n",
    "                        height += dataI.ih[ii] - dataI.ihn[ii]\n",
    "                    else:\n",
    "                        height += dataI.ih[ii]\n",
    "                    item.ze = height\n",
    "\n",
    "                    stack.Items.append(item)\n",
    "      #  print(\"Check weight end\")\n",
    "      #  print(\"§\" * 50)\n",
    "      #  print(\"§\" * 50)\n",
    "        # Determine items not used\n",
    "        numNotPacked_Item = defaultdict(int)\n",
    "\n",
    "        for ss in stacking.S:\n",
    "            if round(omega[ss, 0].X + omega[ss, 1].X) == 0:\n",
    "                for ii in stacking.I_Stack[ss]:\n",
    "                    numNotPacked_Item[ii] += 1\n",
    "\n",
    "       # print(\"Anzahl Items die nicht durch MIP gepackt werden konnten: \" , sum(numNotPacked_Item.values()))\n",
    "    \n",
    "        print(\"Stacks not packed:\")                          #Für Fynn\n",
    "        for ss in stacking.S:                                #Für Fynn\n",
    "            if round(omega[ss, 0].X + omega[ss, 1].X) == 0:  #Für Fynn\n",
    "                print(f\"Stack {ss} not in final solution with items: {stacking.I_Stack[ss]}\")              #Für Fynn\n",
    "                pass\n",
    "        \n",
    "        return truck, numNotPacked_Item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55024ebd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70a4b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_3DPPM(dataT, dataI, dataP, tt, ttIdx, num_Item, timeLimit):\n",
    "\n",
    "  #  print(f\"3D Packing MIP with Time Limit {timeLimit} [s] \", tt)                                                      \n",
    "    \n",
    "  #  for ii,num in num_Item.items():\n",
    "  #      print(\"Items zu packen: \" , ii, num)                                                                                         \n",
    "    \n",
    "    truckHeu, numNotPacked_Item = solve_3DPPH(dataT, dataI, dataP, tt, ttIdx, num_Item)\n",
    "    \n",
    "    # Preprocessing\n",
    "    I = sorted(num_Item)\n",
    "    UOrdered = sorted(dataT.TU[tt], key=lambda x: dataT.te[tt, x])\n",
    "    I_Supplier = {uu: [] for uu in  UOrdered}\n",
    "\n",
    "    for ii in I:\n",
    "        I_Supplier[dataI.iu[ii]].append(ii)\n",
    "    tm = {uuu: min(dataT.tm[tt] , max(1e-5, sum([dataI.im[ii] for uu in UOrdered[:pos+1] for ii in I_Supplier[uu] for _ in range(num_Item[ii])]))) for pos, uuu in enumerate(UOrdered)}\n",
    "    \n",
    "    m = Model('3D-Packing Problem')\n",
    "\n",
    "    # Position\n",
    "    xx = tupledict()  # x Coordinate \n",
    "    yy = tupledict()  # y Coordinate \n",
    "    omega = tupledict() #  Orientation, 0: Lengthwise, 1: Widthwise\n",
    "    \n",
    "    # Dependency\n",
    "    # View of the truck from above, left for length of truck, before for width of truck\n",
    "    ll = tupledict() # i, j: i left  j \n",
    "    vv = tupledict() # i, j: i before j\n",
    "    aa = tupledict() # i, j: i on top j  (on top = on top of bottom item)\n",
    "    bb = tupledict() # i: i on ground \n",
    "    \n",
    "    # Support\n",
    "    supS = tupledict() # i, j: i supports j\n",
    "    supW = tupledict() # i: i on wall\n",
    "    \n",
    "    # Weight\n",
    "    eje = tupledict()\n",
    "    ejr = tupledict()\n",
    "    emh = tupledict()\n",
    "    emr = tupledict()\n",
    "    emm = tupledict() \n",
    "    \n",
    "    # Fill Variabels\n",
    "    for ii in I:\n",
    "        for jj in range(num_Item[ii]):\n",
    "            ## Position\n",
    "            xx[ii, jj] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"x[{ii},{jj}]\")\n",
    "            yy[ii, jj] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"y[{ii},{jj}]\") \n",
    "            for oo in range(2):\n",
    "                omega[ii, jj, oo] = m.addVar(vtype=GRB.BINARY, name=f\"omega[{ii},{jj},{oo}]\")\n",
    "                \n",
    "            ## Dependency and support\n",
    "            bb[ii, jj] = m.addVar(vtype=GRB.BINARY, name=f\"bb[{ii},{jj}]\")\n",
    "            supW[ii, jj] = m.addVar(vtype=GRB.BINARY, name=f\"supW[{ii},{jj}]\")\n",
    "    \n",
    "    ## Dependency and support\n",
    "    for ii1, ii2 in itertools.product(I, repeat=2):\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            for jj2 in range(num_Item[ii2]):\n",
    "                ll[ii1, jj1, ii2, jj2] = m.addVar(vtype=GRB.BINARY, name=f\"ll[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                vv[ii1, jj1, ii2, jj2] = m.addVar(vtype=GRB.BINARY, name=f\"vv[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                aa[ii1, jj1, ii2, jj2] = m.addVar(vtype=GRB.BINARY, name=f\"aa[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                supS[ii1, jj1, ii2, jj2] = m.addVar(vtype=GRB.BINARY, name=f\"supS[{ii1},{jj1},{ii2},{jj2}]\")    \n",
    "    \n",
    "    ## Weight\n",
    "    for uu in UOrdered:\n",
    "        eje[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"eje[{uu}]\")\n",
    "        ejr[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"ejr[{uu}]\")\n",
    "        emh[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"emh[{uu}]\")\n",
    "        emr[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"emr[{uu}]\")\n",
    "        emm[uu] = m.addVar(vtype=GRB.CONTINUOUS, name=f\"emm[{uu}]\") \n",
    "        \n",
    "\n",
    "    # Objective\n",
    "    m.setObjective(quicksum(omega[ii, jj, 0] + omega[ii, jj, 1] for ii in I for jj in range(num_Item[ii])), GRB.MAXIMIZE)\n",
    "    \n",
    "    # Item in truck\n",
    "    for ii in I:\n",
    "        for jj in range(num_Item[ii]):\n",
    "            ## Orientation\n",
    "            ## If item is packed, only one orientation\n",
    "            m.addConstr(omega[ii, jj, 0] + omega[ii, jj, 1]\n",
    "                        <= 1, name=f\"OrientationOnlyOne[{ii},{jj}]\")\n",
    "            ## Forbid orientations for fixed items\n",
    "            if \"lengthwise\" == dataI.io[ii]:\n",
    "                m.addConstr(omega[ii, jj, 1] \n",
    "                            == 0, name=f\"OrientationForbidL[{ii},{jj}]\")\n",
    "            elif \"widthwise\" == dataI.io[ii]:\n",
    "                m.addConstr(omega[ii, jj, 0] \n",
    "                            == 0, name=f\"OrientationForbidW[{ii},{jj}]\")      \n",
    "            ## Length and width of truck considered\n",
    "            m.addConstr(xx[ii, jj] + dataI.il[ii] * omega[ii,jj, 0] + dataI.iw[ii] * omega[ii,jj, 1] \n",
    "                        <= dataT.tl[tt], name=f\"TruckLength[{ii},{jj}]\")\n",
    "            m.addConstr(yy[ii, jj] + dataI.iw[ii] * omega[ii,jj, 0] + dataI.il[ii] * omega[ii,jj, 1]  \n",
    "                        <= dataT.tw[tt], name=f\"TruckWidth[{ii},{jj}]\")\n",
    "            ## If item in truck support through wall or other item is required\n",
    "            m.addConstr(supW[ii, jj] + quicksum(supS[ii2, jj2, ii, jj] for ii2 in I for jj2 in range(num_Item[ii2]) if ii != ii2 or jj != jj2)\n",
    "                        >= omega[ii, jj, 0] + omega[ii, jj, 1], name=f\"Support[{ii1},{jj1}]\")            \n",
    "            ## If support wall item must be at front of truck\n",
    "            m.addConstr(xx[ii, jj]\n",
    "                        <= dataT.tl[tt] * (1 - supW[ii, jj]), name=f\"SupportWall[{ii},{jj}]\")\n",
    "   \n",
    "    # Stack building\n",
    "    for ii1 in I:\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            ## Item bottom item or on top of another item\n",
    "            m.addConstr(bb[ii1, jj1] + quicksum(aa[ii1, jj1, ii2, jj2] for ii2 in I for jj2 in range(num_Item[ii2]) if ii1 != ii2 or jj1 != jj2) \n",
    "                        == omega[ii1, jj1, 0] + omega[ii1, jj1, 1], name=f\"ItemBottomOrTop[{ii1},{jj1}]\")\n",
    "            ## Number of top items limited by max stackability of bottom item\n",
    "            m.addConstr(quicksum(aa[ii2, jj2, ii1, jj1] for ii2 in I for jj2 in range(num_Item[ii2]) if ii1 != ii2 or jj1 != jj2 )\n",
    "                        <= dataI.ism[ii1] - 1, name=f\"MaxStackability[{ii1},{jj1}]\")\n",
    "            ## Number of top items limited by weight on top of bottom item\n",
    "            m.addConstr(quicksum(dataI.im[ii2] * aa[ii2, jj2, ii1, jj1] for ii2 in I for jj2 in range(num_Item[ii2]) if ii1 != ii2 or jj1 != jj2 )\n",
    "                        <= dataT.tmm[tt, dataI.ir[ii1]] * bb[ii1, jj1], name=f\"WeightBottom[{ii1},{jj1}]\")\n",
    "            ## Number of top items limited by truck height\n",
    "            m.addConstr(quicksum((dataI.ih[ii2] - dataI.ihn[ii2]) * aa[ii2, jj2, ii1, jj1] for ii2 in I for jj2 in range(num_Item[ii2]) if ii1 != ii2 or jj1 != jj2) + dataI.ih[ii1] * bb[ii1, jj1]\n",
    "                        <= dataT.th[tt], name=f\"MaxHeight[{ii1},{jj1}]\")\n",
    "            ## Number of top items limited by truck density\n",
    "            m.addConstr(quicksum((dataI.im[ii2] / ((dataI.il[ii2] * dataI.iw[ii2]) / 1_000_000)) * aa[ii2, jj2, ii1, jj1] for ii2 in I for jj2 in range(num_Item[ii2]) if ii1 != ii2 or jj1 != jj2) + (dataI.im[ii1] / ((dataI.il[ii1] * dataI.iw[ii1]) / 1_000_000)) * bb[ii1, jj1]\n",
    "                        <= dataT.tem[tt], name=f\"TruckDensity[{ii1},{jj1}]\")\n",
    "            ## Consider max stackability 1\n",
    "            if dataI.ism[ii1] == 1:\n",
    "                ## Item must be bottom item\n",
    "                m.addConstr(bb[ii1, jj1] \n",
    "                            == omega[ii1, jj1, 0] + omega[ii1, jj1, 1], name=f\"ItemISMBottom[{ii1},{jj1}]\")\n",
    "                ## No other items on top\n",
    "                m.addConstr(quicksum(aa[ii2, jj2, ii1, jj1] for ii2 in I for jj2 in range(num_Item[ii2]) if ii1 != ii2 or jj1 != jj2) \n",
    "                            == 0, name=f\"ItemISMNoTop[{ii1},{jj1}]\")\n",
    "      \n",
    "    # Relation between two items\n",
    "    for ii1, ii2 in itertools.product(I, repeat=2):\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            for jj2 in range(num_Item[ii2]):\n",
    "                if ii1 != ii2 or jj1 != jj2:    \n",
    "                    ## Items can only be placed on top of each other if stackability code, supplier and supplier dock match\n",
    "                    if dataI.ist[ii1] != dataI.ist[ii2] or dataI.iu[ii1] != dataI.iu[ii2] or dataI.ik[ii1] != dataI.ik[ii2] or dataI.ig[ii1] != dataI.ig[ii2]:\n",
    "                        m.addConstr(aa[ii1, jj1, ii2, jj2]\n",
    "                                    == 0, name=f\"ItemOnTopMatch[{ii1},{jj1},{ii2},{jj2}]\")     \n",
    "                    ## Items only on top of item if item bottom item\n",
    "                    m.addConstr(aa[ii2, jj2, ii1, jj1] \n",
    "                                <= bb[ii1, jj1], name=f\"ItemOnTopBottomItem[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    ## X-position same if item on top of each other\n",
    "                    m.addConstr(xx[ii1, jj1] - xx[ii2, jj2]\n",
    "                                <= dataT.tl[tt] * (1 - aa[ii1, jj1, ii2, jj2]), name=f\"ItemOnTopXo1[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    m.addConstr(xx[ii1, jj1] - xx[ii2, jj2]\n",
    "                                >= - dataT.tl[tt] * (1 - aa[ii1, jj1, ii2, jj2]), name=f\"ItemOnTopXo2[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    m.addConstr((xx[ii1, jj1] + dataI.il[ii1] * omega[ii1,jj1, 0] + dataI.iw[ii1] * omega[ii1,jj1, 1]) - (xx[ii2, jj2] + dataI.il[ii2] * omega[ii2,jj2, 0] + dataI.iw[ii2] * omega[ii2,jj2, 1])\n",
    "                                <= dataT.tl[tt] * (1 - aa[ii1, jj1, ii2, jj2]), name=f\"ItemOnTopXe1[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    m.addConstr((xx[ii1, jj1] + dataI.il[ii1] * omega[ii1,jj1, 0] + dataI.iw[ii1] * omega[ii1,jj1, 1]) - (xx[ii2, jj2] + dataI.il[ii2] * omega[ii2,jj2, 0] + dataI.iw[ii2] * omega[ii2,jj2, 1])\n",
    "                                >= - dataT.tl[tt] * (1 - aa[ii1, jj1, ii2, jj2]), name=f\"ItemOnTopXe2[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    ## Y-position same if item on top of each other\n",
    "                    m.addConstr(yy[ii1, jj1] - yy[ii2, jj2]\n",
    "                                <= dataT.tw[tt] * (1 - aa[ii1, jj1, ii2, jj2]), name=f\"ItemOnTopYo1[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    m.addConstr(yy[ii1, jj1] - yy[ii2, jj2]\n",
    "                                >= - dataT.tw[tt] * (1 - aa[ii1, jj1, ii2, jj2]), name=f\"ItemOnTopYo2[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    m.addConstr((yy[ii1, jj1] + dataI.iw[ii1] * omega[ii1,jj1, 0] + dataI.il[ii1] * omega[ii1,jj1, 1]) - (yy[ii2, jj2] + dataI.iw[ii2] * omega[ii2,jj2, 0] + dataI.il[ii2] * omega[ii2,jj2, 1])\n",
    "                                <= dataT.tw[tt] * (1 - aa[ii1, jj1, ii2, jj2]), name=f\"ItemOnTopYe1[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    m.addConstr((yy[ii1, jj1] + dataI.iw[ii1] * omega[ii1,jj1, 0] + dataI.il[ii1] * omega[ii1,jj1, 1]) - (yy[ii2, jj2] + dataI.iw[ii2] * omega[ii2,jj2, 0] + dataI.il[ii2] * omega[ii2,jj2, 1])\n",
    "                                >= - dataT.tw[tt] * (1 - aa[ii1, jj1, ii2, jj2]), name=f\"ItemOnTopYe2[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    ## Items can only support each other if both items are packed\n",
    "                    m.addConstr(supS[ii1, jj1, ii2, jj2]\n",
    "                                <= omega[ii1, jj1, 0] + omega[ii1, jj1, 1], name=f\"SupportItems1[{ii1},{jj1},{ii2},{jj2}]\")   \n",
    "                    m.addConstr(supS[ii1, jj1, ii2, jj2]\n",
    "                                <= omega[ii2, jj2, 0] + omega[ii2, jj2, 1], name=f\"SupportItems2[{ii1},{jj1},{ii2},{jj2}]\") \n",
    "                    ## Item left of other items cannot overlap\n",
    "                    m.addConstr(xx[ii1, jj1] + dataI.il[ii1] * omega[ii1, jj1, 0] + dataI.iw[ii1] * omega[ii1, jj1, 1]\n",
    "                                <= xx[ii2, jj2] + dataT.tl[tt] * (1 - ll[ii1, jj1, ii2, jj2]), name=f\"OverlapLeft[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    ## Item before other items cannot overlap\n",
    "                    m.addConstr(yy[ii1, jj1] + dataI.iw[ii1] * omega[ii1, jj1, 0] + dataI.il[ii1] * omega[ii1, jj1, 1] \n",
    "                                <= yy[ii2, jj2] + dataT.tw[tt] * (1 - vv[ii1, jj1, ii2, jj2]), name=f\"OverlapBefore[{ii1},{jj1},{ii2},{jj2}]\")                 \n",
    "\n",
    "    # Multi drop\n",
    "    for ii1, ii2 in itertools.product(I, repeat=2):\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            for jj2 in range(num_Item[ii2]):\n",
    "                if ii1 != ii2 or jj1 != jj2:\n",
    "                    if dataT.te[tt, dataI.iu[ii1]] < dataT.te[tt, dataI.iu[ii2]]:\n",
    "                        ## Restrict position and dependacy if supplier order is different (P4-1)\n",
    "                        m.addConstr(xx[ii1,jj1]\n",
    "                                    <= xx[ii2,jj2], name=f\"MultiSupplierPosition[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                        m.addConstr(ll[ii2, jj2, ii1, jj1]\n",
    "                                    <= 0, name=f\"MultiSupplierLeft[{ii1},{jj1},{ii2},{jj2}]\") \n",
    "                    elif dataT.te[tt, dataI.iu[ii1]] == dataT.te[tt, dataI.iu[ii2]]:\n",
    "                        if dataT.tke[tt, dataI.iu[ii1], dataI.ik[ii1]] != 0 and dataT.tke[tt, dataI.iu[ii2], dataI.ik[ii2]] != 0:\n",
    "                            if dataT.tke[tt, dataI.iu[ii1], dataI.ik[ii1]] < dataT.tke[tt, dataI.iu[ii2], dataI.ik[ii2]]:\n",
    "                                ## Restrict position and dependacy if supplier dock order is different (P4-2)\n",
    "                                m.addConstr(xx[ii1, jj1]\n",
    "                                            <= xx[ii2, jj2], name=f\"MultiSupplierDockPosition[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                                m.addConstr(ll[ii2, jj2, ii1, jj1]\n",
    "                                            <= 0, name=f\"MultiSupplierDockLeft[{ii1},{jj1},{ii2},{jj2}]\")  \n",
    "\n",
    "                        if dataT.tke[tt, dataI.iu[ii1], dataI.ik[ii1]] == dataT.tke[tt, dataI.iu[ii2], dataI.ik[ii2]]:\n",
    "                            if dataT.tge[tt, dataT.tp[tt], dataI.ig[ii1]] < dataT.tge[tt, dataT.tp[tt], dataI.ig[ii2]]:\n",
    "                                ## Restrict position and dependacy if plant dock order is different (P4-3)\n",
    "                                m.addConstr(xx[ii1,jj1]\n",
    "                                            <= xx[ii2,jj2], name=f\"MultiPlantDockPosition[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                                m.addConstr(ll[ii2, jj2, ii1, jj1]\n",
    "                                            <= 0, name=f\"MultiPlantDockLeft[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                                #Hier verbieten wir multistack\n",
    "                                m.addConstr(aa[ii1, jj1, ii2, jj2] == 0, name=f\"ForbidMultiStack1[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                                m.addConstr(aa[ii2, jj2, ii1, jj1] == 0, name=f\"ForbidMultiStack2[{ii2},{jj2},{ii1},{jj1}]\")\n",
    "                                \n",
    "                                \n",
    "    for ii1, ii2 in itertools.product(I, repeat=2):\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            for jj2 in range(num_Item[ii2]):\n",
    "                if ii1 != ii2 or jj1 != jj2:\n",
    "                    if dataI.ist[ii1] != dataI.ist[ii2] or dataI.iu[ii1] != dataI.iu[ii2] or dataI.ik[ii1] != dataI.ik[ii2]:\n",
    "                        m.addConstr(aa[ii1, jj1, ii2, jj2] == 0, name=f\"ForbidSafety1[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                        m.addConstr(aa[ii2, jj2, ii1, jj1] == 0, name=f\"ForbidSafety2[{ii2},{jj2},{ii1},{jj1}]\")\n",
    "                        \n",
    "\n",
    "    # Weight constraints\n",
    "    ## Wight limit truck (W1)\n",
    "    m.addConstr(quicksum(dataI.im[ii] * (omega[ii, jj, 0] + omega[ii, jj, 1]) for ii in I for jj in range(num_Item[ii]))\n",
    "                <= dataT.tm[tt], name=\"WeightLimitTruck\")\n",
    "\n",
    "    ## Weight on axis (W2)\n",
    "    for pos, uuu in enumerate(UOrdered):\n",
    "        m.addConstr(quicksum((xx[ii, jj] + (dataI.il[ii] * omega[ii, jj, 0] + dataI.iw[ii] * omega[ii, jj, 1]) / 2) * dataI.im[ii]  for uu in UOrdered[:pos+1] for ii in I_Supplier[uu] for jj in range(num_Item[ii])) / tm[uuu]\n",
    "                    == eje[uuu], name=f\"eje[{uuu}]\")\n",
    "        m.addConstr(dataT.ejeh[tt] + dataT.ejhr[tt] - eje[uuu]\n",
    "                    == ejr[uuu], name=f\"ejr[{uuu}]\")\n",
    "        m.addConstr((tm[uuu] * ejr[uuu] + dataT.em[tt] * dataT.ejcr[tt]) / dataT.ejhr[tt]\n",
    "                    == emh[uuu], name=f\"emh[{uuu}]\")\n",
    "        m.addConstr(tm[uuu] + dataT.em[tt] - emh[uuu]\n",
    "                    == emr[uuu], name=f\"emr[{uuu}]\")\n",
    "        m.addConstr((dataT.cm[tt] * dataT.cjfc[tt] + emh[uuu] * dataT.cjfh[tt]) / dataT.cjfm[tt]\n",
    "                    == emm[uuu], name=f\"emm[{uuu}]\")\n",
    "        \n",
    "    ## Constraint W2\n",
    "    for uu in UOrdered:\n",
    "        m.addConstr(emm[uu]\n",
    "                    <= dataT.emmm[tt], name=f\"emmm[{uu}]\")\n",
    "        m.addConstr(emr[uu]\n",
    "                    <= dataT.emmr[tt], name=f\"emmr[{uu}]\")                                \n",
    "\n",
    "    # Symmetry breaking left and before\n",
    "    for ii1, ii2 in itertools.product(I, repeat=2):\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            for jj2 in range(num_Item[ii2]):\n",
    "                if ii1 != ii2 or jj1 != jj2:\n",
    "                    m.addConstr(supS[ii1, jj1, ii2, jj2]\n",
    "                                <= ll[ii1, jj1, ii2, jj2], name=f\"SymmetryL[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    m.addConstr(supS[ii1, jj1, ii2, jj2]\n",
    "                                <= 1 - vv[ii1, jj1, ii2, jj2], name=f\"SymmetryB[{ii1},{jj1},{ii2},{jj2}]\")             \n",
    "        \n",
    "    # Cases that cut off optimal solution                                \n",
    "    for ii1, ii2 in itertools.product(I, repeat=2):\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            for jj2 in range(num_Item[ii2]):\n",
    "                if ii1 != ii2 or jj1 != jj2:                 \n",
    "                    # Items can only be placed on top of each other if plant dock is the same, i.e. no multi stacks\n",
    "                    if dataI.ig[ii1] != dataI.ig[ii2]:\n",
    "                        m.addConstr(aa[ii1, jj1, ii2, jj2]\n",
    "                                    == 0, name=f\"ItemOnTopPlantDock[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                    # Items can only be placed on top of each other if max stackability is greater or equal\n",
    "                    if dataI.ism[ii1] < dataI.ism[ii2]:\n",
    "                        m.addConstr(aa[ii1, jj1, ii2, jj2]\n",
    "                                    == 0, name=f\"ItemOnTopISM[{ii1},{jj1},{ii2},{jj2}]\")\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "    #TODOcheck solution feasible?                      \n",
    "    for ii1, ii2 in itertools.product(I, repeat=2):\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            for jj2 in range(num_Item[ii2]):\n",
    "                if ii1 != ii2 or jj1 != jj2:\n",
    "                    m.addConstr(ll[ii1, jj1, ii2, jj2] + ll[ii2, jj2, ii1, jj1] + vv[ii1, jj1, ii2, jj2] + vv[ii2, jj2, ii1, jj1] >= bb[ii1, jj1] + bb[ii2, jj2] - 1, name=\"3_\") \n",
    "\n",
    "                        \n",
    "    ### Hier ggf. später noch -1 um Support wirklich zu gewährleisten #TODOcodeReduction oben einfügen\n",
    "\n",
    "    for ii1 in I:\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            for ii2 in I:\n",
    "                for jj2 in range(num_Item[ii2]):\n",
    "                    if ii1 != ii2 or jj1 != jj2:\n",
    "                        m.addConstr(xx[ii1,jj1] + dataI.il[ii1] * omega[ii1,jj1, 0] + dataI.iw[ii1] * omega[ii1,jj1, 1] <= xx[ii2,jj2] + dataT.tl[tt] * (1-supS[ii1, jj1, ii2, jj2])  , name=\"6_\")\n",
    "                        m.addConstr(xx[ii1,jj1] + dataI.il[ii1] * omega[ii1,jj1, 0] + dataI.iw[ii1] * omega[ii1,jj1, 1] >= xx[ii2,jj2] - dataT.tl[tt] * (1-supS[ii1, jj1, ii2, jj2])  , name=\"7_\")\n",
    "                        m.addConstr(yy[ii1,jj1] + dataI.iw[ii1] * omega[ii1,jj1, 0] + dataI.il[ii1] * omega[ii1,jj1, 1] >= yy[ii2,jj2] - dataT.tw[tt] * (1-supS[ii1, jj1, ii2, jj2])  , name=\"8_\")\n",
    "                        m.addConstr(yy[ii1,jj1] <= yy[ii2,jj2] + dataI.iw[ii2] * omega[ii2,jj2, 0] + dataI.il[ii2] * omega[ii2,jj2, 1] + dataT.tw[tt] * (1-supS[ii1, jj1, ii2, jj2])  , name=\"9_\")     \n",
    "                        \n",
    "                        \n",
    "    #Funktioniert sehr gut, Achtung jedoch bei Initial Solution, diese kann eventuell infeasible sein wegen falscher Stack Reihenfolge. -> Nur Anwenden wenn Initial keine optimale Lösung bietet    \n",
    "    #Identsiche Items einschränken -> Homogene Items\n",
    "    for ii1 in I:\n",
    "        for jj1 in range(num_Item[ii1]):\n",
    "            for ii2 in I:\n",
    "                if ii1 == ii2:\n",
    "                    for jj2 in range(num_Item[ii2]):\n",
    "                        if jj1 < jj2:\n",
    "                            m.addConstr(ll[ii2, jj2, ii1, jj1] == 0)\n",
    "                            m.addConstr(vv[ii2, jj2, ii1, jj1] == 0)\n",
    "    #Identsiche Items einschränken -> Homogene Items                         \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "    # Start optimization\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    m.setParam('Timelimit', timeLimit)\n",
    "    m.setParam('Threads', 8)\n",
    "    m.setParam('MIPFocus', 1)     \n",
    "    m._limitTime = timeLimit\n",
    "    \n",
    "    m._objHeu = 0\n",
    "    m._objBest = 0    \n",
    "    \n",
    "    m.optimize()   \n",
    "    \n",
    "    if m.SolCount < 1 or sum(truckHeu.num_Item.values()) >= sum([1 for ii in I for jj in range(num_Item[ii]) if round(omega[ii,jj, 0].X + omega[ii,jj, 1].X, 0) == 1]):\n",
    "       # print(\"Heuristische Lösung wird gewählt\")\n",
    "       # print(m.SolCount)\n",
    "       # print(truckHeu)\n",
    "       # for ii,num in numNotPacked_Item.items():\n",
    "       #     print(\"111212Nicht gepackte Items: \" , ii, num)                                                                                           \n",
    "    \n",
    "        return truckHeu, numNotPacked_Item\n",
    "    else:\n",
    "\n",
    "      #  print(\"§\" * 50)\n",
    "      #  print(\"§\" * 50)\n",
    "      #  print(\"Check weight 3D packing\" , tt, ttIdx, dataT.tm[tt])  \n",
    "        # Create truck\n",
    "        truck = Truck(ttIdx, tt)\n",
    "\n",
    "        # Create stacks\n",
    "        BI = [(ii, jj) for ii in I for jj in range(num_Item[ii]) if round(bb[ii, jj].X, 0) == 1]  # List of bottom items\n",
    "        BIOrdered = sorted(BI, key=lambda x: (xx[x].X, yy[x].X))\n",
    "\n",
    "      \n",
    "        \n",
    "        \n",
    "\n",
    "        for pos, (ii1, jj1) in enumerate(BIOrdered):\n",
    "            stack = Stack()\n",
    "            truck.Stacks.append(stack)\n",
    "\n",
    "            stack.xo = int(round(xx[ii1, jj1].X, 0))\n",
    "            stack.yo = int(round(yy[ii1, jj1].X, 0))\n",
    "            stack.zo = 0\n",
    "            stack.xe = int(round(xx[ii1, jj1].X + dataI.il[ii1] * omega[ii1, jj1, 0].X + dataI.iw[ii1] * omega[ii1, jj1, 1].X, 0))\n",
    "            stack.ye = int(round(yy[ii1, jj1].X + dataI.iw[ii1] * omega[ii1, jj1, 0].X + dataI.il[ii1] * omega[ii1, jj1, 1].X, 0))\n",
    "            stack.ze = None\n",
    "\n",
    "\n",
    "            IStack = [(ii1, jj1)]\n",
    "            IOnTop = []\n",
    "            for ii2 in I:\n",
    "                for jj2 in range(num_Item[ii2]):\n",
    "                    if ii1 != ii2 or jj1 != jj2:\n",
    "                        if aa[ii2, jj2, ii1, jj1].X >= 0.5:\n",
    "                            IOnTop.append((ii2, jj2))\n",
    "\n",
    "            # Sort items by their plant dock order and add to stack\n",
    "            IOnTop.sort(key=lambda x: dataT.tge[tt, dataT.tp[tt], dataI.ig[x[0]]])\n",
    "            IStack.extend(IOnTop)\n",
    "\n",
    "            stack.idx = f\"{truck.idx}_{pos+1}\"\n",
    "            stack.code = code_stack(pos+1, tidx=truck.idx)\n",
    "\n",
    "            # Create items\n",
    "            height = 0\n",
    "            for pos, (ii, jj) in enumerate(IStack):\n",
    "                \n",
    "               # print(\"Item\", ii, \"weights\", dataI.im[ii])\n",
    "                item = Item()            \n",
    "                item.idx = ii\n",
    "                item.code = stack.code + str(pos+1)                    \n",
    "                item.xo = stack.xo\n",
    "                item.xe = stack.xe\n",
    "                item.yo = stack.yo\n",
    "                item.ye = stack.ye   \n",
    "                item.zo = height\n",
    "                if pos > 0:\n",
    "                    height += dataI.ih[ii] - dataI.ihn[ii]\n",
    "                else:\n",
    "                    height += dataI.ih[ii]\n",
    "                item.ze = height\n",
    "\n",
    "                stack.Items.append(item)\n",
    "\n",
    "            stack.ze = height\n",
    "     #   print(\"Check weight end\")\n",
    "     #   print(\"§\" * 50)\n",
    "     #   print(\"§\" * 50)\n",
    "        # Track all items that are not packed into the truck\n",
    "        numNotPacked_Item = defaultdict(int)\n",
    "        for ii in I:\n",
    "            for jj in range(num_Item[ii]):\n",
    "                if round(omega[ii,jj, 0].X + omega[ii,jj, 1].X, 0) == 0:\n",
    "                    numNotPacked_Item[ii] += 1\n",
    "\n",
    "\n",
    "     #   for ii,num in numNotPacked_Item.items():\n",
    "     #       print(\"222jhdsfjsdgNicht gepackte Items: \" , ii, num)                                                                                           \n",
    " \n",
    "        return truck, numNotPacked_Item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138229e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Algorithm Heuristic Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "919fad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def packing_heuristic(dataT, dataI, dataO, dataP, sol, tt, assignment1):\n",
    "    usedTrucks = []        \n",
    "    num_Item = copy.deepcopy(assignment1.num_Truck_Item[tt]) \n",
    "    \n",
    "    for jj in range(assignment1.num_Truck[tt]):\n",
    "        print('-'*100)\n",
    "        # Generate Idx of truck\n",
    "        ttIdx = tt if jj == 0 else f\"Q{tt[1:]}_{jj}\"\n",
    "\n",
    "        if sum(num_Item.values()) > 0:\n",
    "            # Pack truck\n",
    "            \n",
    "            stacking = SPSolution()\n",
    "            solve_SP(dataT, dataI, stacking, tt, num_Item, dataP.t2DSP)\n",
    "            \n",
    "            if sum([stacking.svol2D[ss] for ss in stacking.S]) / dataT.tvol2D[tt] <= dataP.fStackRatio3DPP:\n",
    "                # Do 3D packing\n",
    "                print(f\"3D Packing Heuristic in Truck {tt}\")                                                    #Für Fynn \n",
    "                for ii, num in num_Item.items():\n",
    "                    print(f\"Item {ii} with: {num}\")                                                                  #Für Fynn \n",
    "                truck, num_Item = solve_3DPPH(dataT, dataI, dataP, tt, ttIdx, num_Item)\n",
    "                if sum(num_Item.values()) > 0.5:\n",
    "                    print(\"Items not packed:\")                                                      #Für Fynn\n",
    "                    for ii, num in num_Item.items():\n",
    "                        if num > 0:\n",
    "                            print(f\"Item {ii} missing: {num}\")                                          #Für Fynn\n",
    "                            pass\n",
    "                else:\n",
    "                    print(\"Heuristic packed all items\")                                          #Für Fynn\n",
    "                    pass                    \n",
    "                \n",
    "            else:\n",
    "                # Do 2D packing, stack items first\n",
    "                timeStacking = time.perf_counter()\n",
    "                Vol2DMustPacked = sum([stacking.svol2D[ss] for ss in stacking.S]) / (dataT.tvol2D[tt] * (assignment1.num_Truck[tt] - jj))\n",
    "                print(f\"2D Packing Heuristic in Truck {tt}\")                                               #Für Fynn \n",
    "                print(f\"Min2DVol: {Vol2DMustPacked * dataT.tvol2D[tt]} [m2]\")\n",
    "                for ss in stacking.S:\n",
    "                    print(f\"Stack {ss} with items: {stacking.I_Stack[ss]}\")                      #Für Fynn                \n",
    "                truck, num_Item = solve_2DPPH(dataT, dataI, dataP, tt, ttIdx, stacking, Vol2DMustPacked)\n",
    "                if sum(num_Item.values()) > 0.5:\n",
    "                    stackUsed = set([stack.oidx for stack in truck.Stacks])                      #Für Fynn\n",
    "                    print(\"Stacks not packed:\")                                                  #Für Fynn\n",
    "                    for ss in stacking.S:                                                        #Für Fynn\n",
    "                        if ss not in stackUsed:                                                  #Für Fynn\n",
    "                            print(f\"Stack {ss} missing: {stacking.I_Stack[ss]}\")                 #Für Fynn\n",
    "                            pass\n",
    "                    pass\n",
    "                else:\n",
    "                    print(\"Heuristic packed all stacks\")                                          #Für Fynn\n",
    "                    pass\n",
    "            \n",
    "            usedTrucks.append(truck)\n",
    "            if sum(truck.num_Item.values()) == 0:\n",
    "                break\n",
    "          #  print(truck)\n",
    "\n",
    "    # Update solution\n",
    "    sol.Trucks[tt] = usedTrucks\n",
    "    if usedTrucks:\n",
    "        sol.tcTransport[tt] = dataT.tc[tt] + dataT.tcPseudo[tt] * (len(usedTrucks) - 1)\n",
    "    else:\n",
    "        sol.tcTransport[tt] = 0\n",
    "    sol.tcInventory[tt] = sum([num * dataO.ic_TruckItem[tt, ii] for truck in usedTrucks for ii, num in truck.num_Item.items()])\n",
    "    \n",
    "    return num_Item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97bbf5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Algorithm MIP Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9eb5ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def packing_model(dataT, dataI, dataO, dataP, sol, tt, num_Item, truckFailed, timePerTruck):\n",
    "    \n",
    "    \n",
    "  #  print(\"num_Item Items nicht gepackt: \" , num_Item)\n",
    "  #  print(\"Truck der nicht alles aufnehmen konnte: \")\n",
    "  #  print(truckFailed)\n",
    "    \n",
    "    # First try to repack using the mathematical model\n",
    "    numNotPacked_Item = copy.deepcopy(num_Item)\n",
    "    \n",
    "    for ii, num in truckFailed.num_Item.items():\n",
    "        numNotPacked_Item[ii] += num\n",
    "    \n",
    "    print('-'*100)\n",
    "\n",
    "    if sum([(stack.xe - stack.xo) * (stack.ye - stack.yo) / 1_000_000 for stack in truckFailed.Stacks]) / dataT.tvol2D[tt] <= dataP.fHeuristicPacking:    #Fynn: Hier die IF-Bedinung durch deine Prediction ersetzen\n",
    "        stacking = SPSolution()\n",
    "        solve_SP(dataT, dataI, stacking, truckFailed.oidx, numNotPacked_Item, timePerTruck*dataP.fTime2DSP) \n",
    "        \n",
    "        if sum([stacking.svol2D[ss] for ss in stacking.S]) / dataT.tvol2D[tt] <= dataP.fStackRatio3DPP:   \n",
    "            # Do 3D packing\n",
    "            truck, numNotPacked_Item = solve_3DPPM(dataT, dataI, dataP, truckFailed.oidx, truckFailed.idx, numNotPacked_Item, timePerTruck)\n",
    "        else:\n",
    "            # Do 2D packing, stack items first\n",
    "            timeStacking = time.perf_counter()            \n",
    "            truck, numNotPacked_Item = solve_2DPPM(dataT, dataI, dataP, truckFailed.oidx, truckFailed.idx, stacking, timePerTruck)\n",
    "\n",
    "        # Check if truck weights are violated, if violated use heuristic packing\n",
    "        if truck.check_weight(dataT, dataI) and sum(truck.num_Item.values()) >= sum(truckFailed.num_Item.values()):\n",
    "            if sum(truck.num_Item.values()) > 0:\n",
    "                sol.Trucks[tt].append(truck)\n",
    "            else:\n",
    "                numNotPacked_Item = num_Item\n",
    "        else:\n",
    "            if sum(truckFailed.num_Item.values()) > 0:\n",
    "                sol.Trucks[tt].append(truckFailed)\n",
    "            numNotPacked_Item = num_Item\n",
    "           # print(\"Truck Weight Failed22222\")\n",
    "    else:\n",
    "        print(\"Heuristische Lösung wird sofort akzeptiert\")\n",
    "        sol.Trucks[tt].append(truckFailed)\n",
    "      #  print(truckFailed)\n",
    "        numNotPacked_Item = num_Item\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    # If all items could still not be packed, add additional trucks\n",
    "    usedTrucks = []\n",
    "    additionalTrucks = 0\n",
    "    numNotToPack_Item = defaultdict(int)\n",
    "\n",
    "  #  print(\"Anzahl Trucks in Lösung: \" , len(sol.Trucks[tt]))\n",
    "  #  print(\"Vor Loop numNotPacked_Item: \" , numNotPacked_Item, tt)\n",
    "    \n",
    "    while sum(numNotPacked_Item.values()) > 0:\n",
    "        print('-'*100)\n",
    " #       print(\"Neue Loop\")\n",
    " #       print(\"numNotPacked_Item in Loop: \" , numNotPacked_Item)\n",
    "        # Generate idx of truck\n",
    "        if len(sol.Trucks[tt]) == 0:\n",
    "            ttIdx = tt\n",
    "        else:\n",
    "            ttIdx = f\"Q{tt[1:]}_{len(sol.Trucks[tt])+len(usedTrucks)}\"\n",
    "\n",
    "        # Find a feasible packing that does not violate the weight constraints\n",
    "        numToPack_Item = numNotPacked_Item\n",
    "        failedTruck = 0  # Represents if in the previous iteration the truck violated the weight constraints\n",
    "\n",
    "        while True:\n",
    "            # If the weight constraints were exceeded in the previous try, reduce the number of items considered in the current try by 50% \n",
    "            if failedTruck > 0:\n",
    "                numItemsToPack = math.ceil(sum(numNotPacked_Item.values()) / (1 + failedTruck))\n",
    "                numToPack_Item = defaultdict(int)\n",
    "\n",
    "                # Determine which items will be packed, in what quantities, and which ones will not\n",
    "                for ii, num in numNotPacked_Item.items():\n",
    "                    if numItemsToPack > 0:\n",
    "                        # The maximum number of items has not been reached, pack the remaining items\n",
    "                        numToPack = min(num, numItemsToPack)\n",
    "                        numToPack_Item[ii] = numToPack\n",
    "                        numItemsToPack -= numToPack\n",
    "                        if numToPack < num:\n",
    "                            # Item cannot be completely packed, save rest for later\n",
    "                            numNotToPack_Item[ii] += num - numToPack\n",
    "                    else:\n",
    "                        # Item cannot be packed, save it for later\n",
    "                        numNotToPack_Item[ii] += num\n",
    "\n",
    "            # Pack truck\n",
    "            truck, currentNumNotPacked_Item = solve_3DPPM(dataT, dataI, dataP, tt, ttIdx, numToPack_Item, timePerTruck)\n",
    "            # Check if truck weights are violated\n",
    "            if truck.check_weight(dataT, dataI):\n",
    "                usedTrucks.append(truck)\n",
    "              #  print(truck)\n",
    "                numNotPacked_Item = currentNumNotPacked_Item\n",
    "                additionalTrucks += 1\n",
    "                sol.numPseudoTrucksPacking2 += 1   #Nur fürs Tracking, hat keinen Sinn dieser Parameter\n",
    "\n",
    "                # If Truck failed before, also include items that were not considered\n",
    "                if failedTruck > 0:\n",
    "                    for ii, num in numNotToPack_Item.items():\n",
    "                        numNotPacked_Item[ii] += num\n",
    "                    failedTruck = 0\n",
    "                    numNotToPack_Item = defaultdict(int)\n",
    "                break\n",
    "            else:\n",
    "            #    print(\"Weight Constraint wurde verletzt!\")\n",
    "                numNotPacked_Item = numToPack_Item\n",
    "                sol.numWeightViolationsAP2 += 1           #Nur fürs Tracking, hat keinen Sinn dieser Parameter\n",
    "                failedTruck += 1\n",
    "    # Update solution\n",
    "    sol.Trucks[tt].extend(usedTrucks)\n",
    "    sol.tcTransport[tt] += dataT.tcPseudo[tt] * additionalTrucks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10847a1f",
   "metadata": {},
   "source": [
    "# Start optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5f8531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_ROADEF(pathIT, pathII, pathIP, pathOT, pathOS, pathOI):\n",
    "\n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    print(f\"Start ROADEF\")\n",
    "    timeROADEF = time.perf_counter()\n",
    "    Model()\n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    \n",
    "    # Read data\n",
    "    timeStart = time.perf_counter()\n",
    "    dataP = DataParameters()\n",
    "    dataP.read_instances(pathIP)\n",
    "    dataT = DataTrucks()\n",
    "    dataT.read_instances(pathIT, dataP)\n",
    "    dataI = DataItems()\n",
    "    dataI.read_instances(pathII)\n",
    "    dataO = DataOwnData(dataT.T, dataI.I)\n",
    "  \n",
    "    print(f\"Time for optimization {dataP.tROADEF} (s)\")\n",
    "    print(\"#\" * 100)\n",
    "    print(f\"Data read\")\n",
    "    print(f\"Took \\t{format_time(time.perf_counter() - timeStart)}\")\n",
    "    print(\"#\" * 100)\n",
    "\n",
    "    # Presolve\n",
    "    print(f\"Presolve\")\n",
    "    presolve_one(dataT, dataI, dataP, dataO)\n",
    "    dataP.set_Params(dataT, dataI, dataO, math.ceil(time.perf_counter()-timeROADEF)) \n",
    "    \n",
    "    print(\"Anzahl Trucks in OPtimierungsproblem: \" , len(dataT.T))\n",
    "    print(\"Itemgruppen in AP werden eher enger gemacht: \" , dataP.TighterGroups)\n",
    "    \n",
    "    presolve_two(dataT, dataI, dataP, dataO)\n",
    "\n",
    "    # Data for reduction -> AP0, AP1\n",
    "    dataIR = DataItems()\n",
    "    dataOR = DataOwnData(dataT.T, dataIR.I)\n",
    "    \n",
    "    reduction_Items(dataT, dataI, dataO, dataP, dataIR, dataOR)\n",
    "    presolve_two(dataT, dataIR, dataP, dataOR)\n",
    "    print(\"Orinigial Anzahl: \" , len(dataI.I), sum(dataI.num_Item.values()))\n",
    "    print(\"Reduzierte Anzahl: \" , len(dataIR.I), sum(dataIR.num_Item.values())) \n",
    "    \n",
    "\n",
    "    StackBuildingAP(dataT, dataIR, dataP, dataO, dataOR)\n",
    "    dataO.tOffset2D = {tt: 0 for tt in dataT.T}\n",
    "    dataO.tOffset2DUp = {tt: 0 for tt in dataT.T}\n",
    "    dataO.tOffset3D = {tt: 0 for tt in dataT.T}\n",
    "    dataO.tOffsetM = {tt: 0 for tt in dataT.T}\n",
    "    dataO.limit_Truck = {tt: dataP.fTrucklimitAP01 for tt in dataT.T}\n",
    "    \n",
    "    print(\"#\" * 100)\n",
    "    print(\"Load Assignment 1 solution\")    \n",
    "    assignment0 = solve_AP0(dataT, dataO, dataP, dataO.limit_Truck, dataP.tAP0*0.5)    \n",
    "\n",
    "    print(\"#\" * 100)\n",
    "    timeRemain = dataP.tAP0 - (time.perf_counter() - timeStart)\n",
    "    print(\"#\" * 100)\n",
    "    print(\"Assignment 1\")\n",
    "    if timeRemain > 60:  \n",
    "        assignment1 = solve_AP1(dataT, dataI, dataO, dataOR, dataP, dataI.num_Item, timeRemain, assignment0, fixed=False)    \n",
    "    else:\n",
    "        assignment1 = solve_AP1(dataT, dataI, dataO, dataOR, dataP, dataI.num_Item, timeRemain, assignment0, fixed=True) \n",
    "        \n",
    "    print(f\"Took \\t{format_time(time.perf_counter() - timeStart)}\")\n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    \n",
    "    # First packing\n",
    "    timeStartPacking = time.perf_counter()\n",
    "    \n",
    "    numTruckToPack = sum(assignment1.num_Truck.values())\n",
    "    timeProTruck = (dataP.tROADEF - (time.perf_counter() - timeROADEF)) / numTruckToPack\n",
    "    \n",
    "    if timeProTruck < dataP.tTruckMin:\n",
    "        dataP.tSimplePacking = 0.75 * timeProTruck \n",
    "        dataP.t2DSP = 0.25 * timeProTruck\n",
    "    print(\"Simple Packing: \"  , dataP.tSimplePacking)\n",
    "    print(\"dataP.t2DSP: \"  , dataP.t2DSP)\n",
    "    \n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    print(f\"First packing\")\n",
    "    \n",
    "    ## Change data structure to sets for better look up time\n",
    "    for key, value in dataO.I_TruckGroupitems.items():\n",
    "        dataO.I_TruckGroupitems[key] = set(value)\n",
    "    \n",
    "    # Sort trucks for packing\n",
    "    sortedTrucksAP1 = sorted(assignment1.T, key=lambda x: assignment1.numItemsPerTruck[x])\n",
    "    sol = Solution()\n",
    "    sol.perfectPacking = True\n",
    "    \n",
    "    numAllNotPacked_Item = defaultdict(int)\n",
    "    \n",
    "    numNotPacked_Truck_Item = dict()\n",
    "\n",
    "    for pos, tt in enumerate(sortedTrucksAP1):\n",
    "        print()\n",
    "      #  print(\"*\"*100)\n",
    "      #  print(\"Truck: \" , tt)\n",
    "        timePerTruck = max(min(dataP.tTruckMax, (dataP.tPacking - (time.perf_counter() - timeStartPacking)) / sum([assignment1.num_Truck[ttt] for ttt in sortedTrucksAP1[pos:]])), dataP.tTruckMin)\n",
    "        timeStart = time.perf_counter()\n",
    "        \n",
    "        numNotPacked_Item = packing_heuristic(dataT, dataI, dataO, dataP, sol, tt, assignment1)      #Fynn: Hier werden die Trucks heuristisch gelöst und alles geprintet\n",
    "        \n",
    "       # print()\n",
    "        if sum(numNotPacked_Item.values()) == 0:\n",
    "            pass\n",
    "         #   print(\"Alle Items wurden von Heuristik gepackt\")\n",
    "        else:\n",
    "            pass\n",
    "         #   print(\"Heuristik konnte folgende Anzahl nicht packen: \" , sum(numNotPacked_Item.values()))\n",
    "        \n",
    "        if numNotPacked_Item:\n",
    "            numNotPacked_Truck_Item[tt] = numNotPacked_Item\n",
    "\n",
    "  #  print(\"#\" * 100)\n",
    "  #  print(\"#\" * 100)\n",
    "  #  print(f\"Number of trucks where heuristic approach did not match the assignment: {len(numNotPacked_Truck_Item)} \")\n",
    "  #  print(\"#\" * 100)\n",
    "  #  print(\"#\" * 100)\n",
    "    \n",
    "  #  print(\"Remaining Packing Time: \" , dataP.tPacking - (time.perf_counter() - timeStartPacking))\n",
    "    if len(numNotPacked_Truck_Item) > 0:\n",
    "        if (dataP.tROADEF - (time.perf_counter() - timeROADEF)) / len(numNotPacked_Truck_Item) < dataP.tTruckMin:\n",
    "            dataP.fHeuristicPacking = 0.5\n",
    "  #  dataP.fHeuristicPacking = 0.999\n",
    "  #  print(\"dataP.fHeuristicPacking: \" , dataP.fHeuristicPacking)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    for pos, tt in enumerate(numNotPacked_Truck_Item):\n",
    "        numTrucksToPack = len(numNotPacked_Truck_Item) * 2                                             ####Fynn: Beispiel 300 Truck konnten nicht gepackt werden. 100 Trucks Prediction nicht Möglich zu verbessern -> Also muss die verbleibende Zeit nur auf 200 Trucks aufgeteilt werden\n",
    "        truckFailed = sol.Trucks[tt].pop()                                                             ###Fynn: In diesem Loop geht es nur darum die Zeit anzupassen: timePerTruck\n",
    "        print()\n",
    "     #   print(\"*\"*100)\n",
    "     #   print(\"Truck: \", tt)\n",
    "        timePerTruck = max(min(dataP.tTruckMax, (dataP.tPacking - (time.perf_counter() - timeStartPacking)) / numTrucksToPack), dataP.tTruckMin)                  #####Fynn angucken: Zeit anpassen?        \n",
    "        packing_model(dataT, dataI, dataO, dataP, sol, tt, numNotPacked_Truck_Item[tt], truckFailed, timePerTruck)\n",
    "        numTrucksToPack -= 2\n",
    "            \n",
    " \n",
    "        \n",
    " #   print(\"#\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"Solution Assignment Problem 0\")\n",
    " #   assignment0.print_sol()\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"Solution Assignment Problem 1\")\n",
    " #   assignment1.print_sol()\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"Final Initial Solution\")\n",
    "    sol.revalue(dataT, dataO, round(time.perf_counter() - timeROADEF, 2))\n",
    " #   sol.print_sol()\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"#\" * 100)        \n",
    "    \n",
    "    # Identify trucks that required additional pseudo trucks\n",
    "    TTrouble = []\n",
    "    for tt, Trucks in sol.Trucks.items():\n",
    "        if len(Trucks) > assignment1.num_Truck[tt]:\n",
    "            sol.perfectPacking = False\n",
    "            TTrouble.append(tt)\n",
    "                \n",
    "       \n",
    " #   print(\"Remaining Runtime: \" ,dataP.tROADEF - (time.perf_counter() - timeROADEF))\n",
    " #   print(\"Some trucks required additional pseudo trucks\")\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)\n",
    " #   print(\"*\" * 100)   \n",
    " #   print(\"#\" * 100)  \n",
    "    \n",
    "    # Start LNS\n",
    " #   print(\"Start LNS\")\n",
    "\n",
    " #   print(\"dataP.fAPLNSTrucklimits: \" , dataP.fAPLNSTrucklimits)\n",
    " #   print(\"dataP.ReductionInfeasibleTrucks: \" , dataP.ReductionInfeasibleTrucks)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    #An dieser Stelle die Limits der Trucks runtersetzen auf den Wert dataP.fAPLNSTrucklimits\n",
    "    num_Truck_Item = {tt: {ii: 0 for ii in dataO.I_Truck[tt]} for tt in dataT.T}\n",
    "    for tt in dataT.T:\n",
    "        if tt in sol.Trucks:\n",
    "            Loaded2D = 0\n",
    "            Loaded3D = 0\n",
    "            LoadedM = 0        \n",
    "            for truck in sol.Trucks[tt]:            \n",
    "                for stack in truck.Stacks:\n",
    "                    Loaded2D += (stack.xe - stack.xo) * (stack.ye - stack.yo) / 1_000_000\n",
    "                    Loaded3D += (stack.xe - stack.xo) * (stack.ye - stack.yo) * stack.ze / 1_000_000_000\n",
    "\n",
    "                    for item in stack.Items:\n",
    "                        LoadedM += dataI.im[item.idx]\n",
    "                        num_Truck_Item[tt][item.idx] += 1\n",
    "                 \n",
    "            Loaded2D = 0\n",
    "            Loaded2DUp = 0\n",
    "            for gi in dataO.GI_Truck[tt]:\n",
    "                AmountofGroup = 0\n",
    "                for ii in dataO.I_TruckGroupitems[tt, gi]:\n",
    "                    AmountofGroup += num_Truck_Item[tt][ii]\n",
    "                Loaded2D += dataO.givol2D_TruckGroupitemsNum[tt, gi, AmountofGroup]  \n",
    "                Loaded2DUp += dataO.giVol2DUp_TruckGroupitemsNum[tt, gi, AmountofGroup]\n",
    "          \n",
    "            Loaded2D = Loaded2D / (dataT.tvol2D[tt] * len(sol.Trucks[tt]))\n",
    "            Loaded2DUp = Loaded2DUp / (dataT.tvol2D[tt] * len(sol.Trucks[tt]))\n",
    "            Loaded3D = Loaded3D / (dataT.tvol3D[tt] * len(sol.Trucks[tt]))\n",
    "            LoadedM = LoadedM / (dataT.tm[tt] * len(sol.Trucks[tt]))\n",
    "            OldLimits = max(Loaded2D, Loaded3D, LoadedM, Loaded2DUp)\n",
    "            OldLimits = min(1,OldLimits)\n",
    "            dataO.limit_Truck[tt] = max(OldLimits, dataP.fAPLNSTrucklimits)\n",
    "        else:\n",
    "            dataO.limit_Truck[tt] = min(dataO.limit_Truck[tt], dataP.fAPLNSTrucklimits)\n",
    "        \n",
    "        \n",
    "\n",
    "    timeLNS = time.perf_counter()\n",
    "    \n",
    "    timeCopy = time.perf_counter()\n",
    "    bestSol = copy.deepcopy(sol)\n",
    "  #  print(f\"Deepcopy of solution took {time.perf_counter()-timeCopy} seconds.\")\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    while not sol.perfectPacking:\n",
    "        sol.perfectPacking = True\n",
    "        \n",
    "        \n",
    "        \n",
    " #       print(\"LNS Iteration\")\n",
    " #       print(\"dataP.tROADEF: \" , dataP.tROADEF)\n",
    " #       print(\"Bisherige Laufzeit: \" , (time.perf_counter() - timeROADEF))\n",
    "        if (dataP.tROADEF - (time.perf_counter() - timeROADEF)) <= 180:\n",
    "            break\n",
    "        RemainingTimeAPLNS = min(1800, dataP.ftAPLNS * (dataP.tROADEF - (time.perf_counter() - timeROADEF)))\n",
    "   #     print(\"RemainingTimeAPLNS: \" , RemainingTimeAPLNS)\n",
    "   #     print(\"Bisherige Laufzeit: \" , (time.perf_counter() - timeROADEF))\n",
    "   #     print(\"dataP.ftAPLNS: \" , dataP.ftAPLNS)\n",
    "        assignmentLNS = solve_APLNS(dataT, dataI, dataO, dataP, sol, dataT.T, TTrouble, dataI.I, dataI.num_Item, RemainingTimeAPLNS)\n",
    "\n",
    "        # Check if enough time for LNS iteration\n",
    "        numTrucksRepack = sum([assignmentLNS.num_Truck[tt] for tt in assignmentLNS.TRepack])\n",
    "        print(\"numTrucksRepack: \" , numTrucksRepack)\n",
    "        print(\"Remaining Time: \"  , dataP.tROADEF - (time.perf_counter() - timeROADEF))\n",
    "        print(\"Faktor: \" , (dataP.tTruckMin + dataP.tSimplePacking + dataP.t2DSP + 0.1))\n",
    "        if dataP.tROADEF - (time.perf_counter() - timeROADEF) - (dataP.tTruckMin + dataP.tSimplePacking + dataP.t2DSP + 0.1) * numTrucksRepack < 0:\n",
    "            print(\"Break: Time Issue\")\n",
    "            break\n",
    "        \n",
    "        # LNS packing\n",
    "    #    print(\"#\" * 100)\n",
    "    #    print(\"#\" * 100)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    #    print(f\"First heuristic packing (LNS)\")\n",
    "\n",
    "        # Sort trucks for packing\n",
    "        sortedTrucksLNS = sorted(assignmentLNS.TRepack, key=lambda x: assignmentLNS.numItemsPerTruck[x])\n",
    "        numAllNotPacked_Item = defaultdict(int)\n",
    "\n",
    "        numNotPacked_Truck_Item = dict()\n",
    "\n",
    "\n",
    "        for pos, tt in enumerate(sortedTrucksLNS):\n",
    "            print()\n",
    "         #   print(\"*\"*100)\n",
    "         #   print(\"Truck: \" , tt)\n",
    "            timePerTruck = max(min(dataP.tTruckMax, (dataP.tROADEF - (time.perf_counter() - timeStartPacking)) / sum([assignmentLNS.num_Truck[ttt] for ttt in sortedTrucksLNS[pos:]])), dataP.tTruckMin)\n",
    "\n",
    "            numNotPacked_Item = packing_heuristic(dataT, dataI, dataO, dataP, sol, tt, assignmentLNS)       \n",
    "\n",
    "            if numNotPacked_Item:\n",
    "                numNotPacked_Truck_Item[tt] = numNotPacked_Item\n",
    "\n",
    "   #     print(\"#\" * 100)\n",
    "   #     print(\"#\" * 100)\n",
    "   #     print(f\"Number of trucks where heuristic approach did not match the assignment: {len(numNotPacked_Truck_Item)} \")\n",
    "   #     print(\"#\" * 100)\n",
    "   #     print(\"#\" * 100)\n",
    "\n",
    "\n",
    "        for pos, tt in enumerate(numNotPacked_Truck_Item):\n",
    "            numTrucksToPack = len(numNotPacked_Truck_Item) * 2\n",
    "            truckFailed = sol.Trucks[tt].pop()\n",
    "            print()\n",
    "          #  print(\"*\"*100)\n",
    "          #  print(\"Truck: \", tt)\n",
    "            timePerTruck = max(min(dataP.tTruckMax, (dataP.tROADEF - (time.perf_counter() - timeStartPacking)) / numTrucksToPack), dataP.tTruckMin) ###Fynn: Auch hier das Gleiche wie oben: Mach dir Gedanken wie die Zeitlimits richtig gesetzt werden sollten\n",
    "            packing_model(dataT, dataI, dataO, dataP, sol, tt, numNotPacked_Truck_Item[tt], truckFailed, timePerTruck)                              ###Fynn: Ist das Gleiche wie oben-> Hier in der Funktion die IF-Bedingung\n",
    "            numTrucksToPack -= 2\n",
    " \n",
    "        \n",
    "        sol.revalue(dataT, dataO, round(time.perf_counter() - timeROADEF, 2))\n",
    "        \n",
    "        if sol.info[\"Obj\"] < bestSol.info[\"Obj\"]:\n",
    "            bestSol = copy.deepcopy(sol)\n",
    "            \n",
    "        \n",
    "   #     print(\"-\" * 100)\n",
    "   #     print(\"Current Solution Assignment LNS\")\n",
    "   #     assignmentLNS.print_sol()\n",
    "   #     print()\n",
    "   #     print(\"Current Solution LNS\")\n",
    "   #     sol.print_sol()\n",
    "   #     print(\"-\" * 100)\n",
    "        \n",
    "        # Identify trucks that required additional pseudo trucks\n",
    "        TTrouble = []\n",
    "        TRemove = []\n",
    "        for tt, Trucks in sol.Trucks.items():\n",
    "            if len(Trucks) > assignmentLNS.num_Truck[tt]:\n",
    "                sol.perfectPacking = False\n",
    "                TTrouble.append(tt)\n",
    "            elif len(Trucks) == 0:\n",
    "                TRemove.append(tt)\n",
    "    #    print(\"TRemove: \" , TRemove)\n",
    "        for tt in TRemove:\n",
    "            del sol.Trucks[tt]\n",
    "        \n",
    "        \n",
    "  #  print(f\"Took \\t{format_time(time.perf_counter() - timeLNS)}\")\n",
    "  #  print(\"#\" * 100)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"*\" * 100)\n",
    "    print(\"*\" * 100)\n",
    "    print(\"*\" * 100)\n",
    "    for tt in bestSol.Trucks:\n",
    "        posDelete = len(bestSol.Trucks[tt]) + 1\n",
    "        for pos, truck in enumerate(bestSol.Trucks[tt]):\n",
    "            if len(truck.Stacks) == 0:\n",
    "                posDelete = pos\n",
    "                break\n",
    "        if posDelete < len(bestSol.Trucks[tt]) + 1:\n",
    "            print(tt , posDelete)\n",
    "        bestSol.Trucks[tt] = bestSol.Trucks[tt][:posDelete]\n",
    "        \n",
    "        \n",
    "    ################Achtung: Information:\n",
    "    #Assigmnet Lösung (die schlussendlich auch akzeptiert wird) kann die finale Lösung unterschätzen wenn z.B. AP1 Items zu Truck zuordnet, welche aber nicht vollständig gepackt werden können\n",
    "    #und Pseudotruck hinzugefügt werden muss. Im APLNS ändert sich die Zuordnung der Pakete jedoch nicht zu diesem Truck aber APLNS denkt weiterhin, dass dieser Truck keinen extra Pseudotruck benötigt.\n",
    "    #In diesem Fall wird die urpsüngliche Lösung akzeptiert und der Truck nicht nochmal gerechnet, wodruch die Objective des APLNS zu niedrig ausfällt.\n",
    "        \n",
    "         \n",
    "\n",
    "            \n",
    "    \n",
    "    print(\"Final Solution\")\n",
    "    bestSol.revalue(dataT, dataO, round(time.perf_counter() - timeROADEF, 2))\n",
    "    bestSol.print_sol()\n",
    "    print(\"*\" * 100)\n",
    "    print(\"*\" * 100)\n",
    "    print(\"*\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    print(f\"Export solution\")\n",
    "    bestSol.export(pathOI, pathOS, pathOT)\n",
    "    print(f\"End ROADEF\")\n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    "    print(\"#\" * 100)\n",
    " \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402338a4",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "617a7c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif __name__ == \"__main__\":\\n\\n    parser = argparse.ArgumentParser(description=\\'ROADEF\\')\\n    parser.add_argument(\"-ip\", \"--iParameter\", type=str, help=\\'Path to file input parameters.\\')\\n    parser.add_argument(\"-ii\", \"--iItems\", type=str, help=\\'Path to file input items.\\')\\n    parser.add_argument(\"-it\", \"--iTrucks\", type=str, help=\\'Path to file input trucks.\\')\\n    parser.add_argument(\"-oi\", \"--oItems\", type=str, help=\\'Path to file output parameters.\\')\\n    parser.add_argument(\"-os\", \"--oStacks\", type=str, help=\\'Path to file output parameters.\\')\\n    parser.add_argument(\"-ot\", \"--oTrucks\", type=str, help=\\'Path to file output parameters.\\')\\n    args = parser.parse_args()\\n\\n    start_ROADEF(args.iTrucks, args.iItems, args.iParameter, args.oTrucks, args.oStacks, args.oItems)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Für Cluster - ROADEF\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='ROADEF')\n",
    "    parser.add_argument(\"-ip\", \"--iParameter\", type=str, help='Path to file input parameters.')\n",
    "    parser.add_argument(\"-ii\", \"--iItems\", type=str, help='Path to file input items.')\n",
    "    parser.add_argument(\"-it\", \"--iTrucks\", type=str, help='Path to file input trucks.')\n",
    "    parser.add_argument(\"-oi\", \"--oItems\", type=str, help='Path to file output parameters.')\n",
    "    parser.add_argument(\"-os\", \"--oStacks\", type=str, help='Path to file output parameters.')\n",
    "    parser.add_argument(\"-ot\", \"--oTrucks\", type=str, help='Path to file output parameters.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    start_ROADEF(args.iTrucks, args.iItems, args.iParameter, args.oTrucks, args.oStacks, args.oItems)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e956f2",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a11e33ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-15T14:05:34.406378Z",
     "start_time": "2023-04-15T13:45:58.226421Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Instance:  X VA\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Start ROADEF\n",
      "Academic license - for non-commercial use only - expires 2024-07-31\n",
      "Using license file C:\\Users\\jschulte1\\gurobi.lic\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Time for optimization 3600.0 (s)\n",
      "####################################################################################################\n",
      "Data read\n",
      "Took \t00:00:00.015\n",
      "####################################################################################################\n",
      "Presolve\n",
      "Anzahl Trucks in OPtimierungsproblem:  22\n",
      "Itemgruppen in AP werden eher enger gemacht:  True\n",
      "Start Reduction\n",
      "Orinigial Anzahl:  217 665\n",
      "Reduzierte Anzahl:  69 665\n",
      "####################################################################################################\n",
      "Load Assignment 1 solution\n",
      "Changed value of parameter MIPFocus to 1\n",
      "   Prev: 0  Min: 0  Max: 3  Default: 0\n",
      "Changed value of parameter Timelimit to 323.46000000000004\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Changed value of parameter Threads to 8\n",
      "   Prev: 0  Min: 0  Max: 1024  Default: 0\n",
      "Changed value of parameter MIPGAP to 0.005\n",
      "   Prev: 0.0001  Min: 0.0  Max: inf  Default: 0.0001\n",
      "Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (win64)\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 8 threads\n",
      "Optimize a model with 306 rows, 389 columns and 1124 nonzeros\n",
      "Model fingerprint: 0xbafbcb3e\n",
      "Variable types: 44 continuous, 345 integer (22 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-01, 2e+04]\n",
      "  Objective range  [2e+01, 4e+03]\n",
      "  Bounds range     [1e+00, 3e+01]\n",
      "  RHS range        [1e+00, 3e+01]\n",
      "Presolve removed 213 rows and 234 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 93 rows, 155 columns, 468 nonzeros\n",
      "Variable types: 0 continuous, 155 integer (60 binary)\n",
      "Found heuristic solution: objective 66060.000000\n",
      "\n",
      "Root relaxation: objective 2.575098e+04, 54 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 25750.9800    0   24 66060.0000 25750.9800  61.0%     -    0s\n",
      "H    0     0                    38817.000000 25750.9800  33.7%     -    0s\n",
      "H    0     0                    37599.000000 26248.7597  30.2%     -    0s\n",
      "H    0     0                    37277.000000 26248.7597  29.6%     -    0s\n",
      "     0     0 32498.7949    0   40 37277.0000 32498.7949  12.8%     -    0s\n",
      "H    0     0                    37215.000000 32498.7949  12.7%     -    0s\n",
      "H    0     0                    35869.000000 32498.7949  9.40%     -    0s\n",
      "H    0     0                    35609.000000 32498.7949  8.73%     -    0s\n",
      "     0     0 32526.2247    0   27 35609.0000 32526.2247  8.66%     -    0s\n",
      "H    0     0                    34688.000000 32526.2247  6.23%     -    0s\n",
      "     0     0 32526.2247    0   26 34688.0000 32526.2247  6.23%     -    0s\n",
      "H    0     0                    34198.000000 32526.2247  4.89%     -    0s\n",
      "H    0     0                    33909.000000 32526.2247  4.08%     -    0s\n",
      "     0     0 32713.2263    0   33 33909.0000 32713.2263  3.53%     -    0s\n",
      "H    0     0                    33751.000000 32713.2263  3.07%     -    0s\n",
      "     0     0 32731.6049    0   40 33751.0000 32731.6049  3.02%     -    0s\n",
      "H    0     0                    33359.000000 32731.6049  1.88%     -    0s\n",
      "H    0     0                    33279.000000 32731.6049  1.64%     -    0s\n",
      "     0     0 32754.7056    0   35 33279.0000 32754.7056  1.58%     -    0s\n",
      "H    0     0                    33060.000000 32754.7056  0.92%     -    0s\n",
      "H    0     0                    33019.000000 32754.7056  0.80%     -    0s\n",
      "     0     0 32803.3542    0   27 33019.0000 32803.3542  0.65%     -    0s\n",
      "     0     0 32803.3542    0   11 33019.0000 32803.3542  0.65%     -    0s\n",
      "     0     0 32867.1626    0   14 33019.0000 32867.1626  0.46%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  Implied bound: 2\n",
      "  MIR: 3\n",
      "  StrongCG: 2\n",
      "\n",
      "Explored 1 nodes (216 simplex iterations) in 0.07 seconds\n",
      "Thread count was 8 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 33019 33019 33060 ... 35609\n",
      "\n",
      "Optimal solution found (tolerance 5.00e-03)\n",
      "Best objective 3.301900000000e+04, best bound 3.286800000000e+04, gap 0.4573%\n",
      "\n",
      "User-callback calls 174, time in user-callback 0.01 sec\n",
      "Objective AP1: 33019.0, MIP-Gap: 0.46%\n",
      "AP0 requires 15 trucks and 3 pseudo trucks.\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Assignment 1\n",
      "Changed value of parameter Timelimit to 646.7761492000001\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Changed value of parameter Threads to 8\n",
      "   Prev: 0  Min: 0  Max: 1024  Default: 0\n",
      "Changed value of parameter MIPGAP to 1e-16\n",
      "   Prev: 0.0001  Min: 0.0  Max: inf  Default: 0.0001\n",
      "Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (win64)\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 8 threads\n",
      "Optimize a model with 839 rows, 2516 columns and 14821 nonzeros\n",
      "Model fingerprint: 0xd0e13f51\n",
      "Variable types: 44 continuous, 2472 integer (1922 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-01, 3e+04]\n",
      "  Objective range  [2e+01, 2e+03]\n",
      "  Bounds range     [1e+00, 3e+01]\n",
      "  RHS range        [1e+00, 6e+01]\n",
      "Presolve removed 839 rows and 2516 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds\n",
      "Thread count was 1 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 32677 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-16)\n",
      "Best objective 3.267700000000e+04, best bound 3.267700000000e+04, gap 0.0000%\n",
      "####################################################################################################\n",
      "Hier wird die fixierte Version nochmal relaxiert um bessere Lösungen zu erhalten\n",
      "Changed value of parameter Timelimit to 646.5958414\n",
      "   Prev: 646.7761492000001  Min: 0.0  Max: inf  Default: inf\n",
      "Changed value of parameter MIPFocus to 1\n",
      "   Prev: 0  Min: 0  Max: 3  Default: 0\n",
      "Parameter MIPGAP unchanged\n",
      "   Value: 1e-16  Min: 0.0  Max: inf  Default: 0.0001\n",
      "Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (win64)\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 8 threads\n",
      "Optimize a model with 645 rows, 2516 columns and 14112 nonzeros\n",
      "Model fingerprint: 0x3c069731\n",
      "Variable types: 44 continuous, 2472 integer (1922 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-01, 3e+04]\n",
      "  Objective range  [2e+01, 2e+03]\n",
      "  Bounds range     [1e+00, 3e+01]\n",
      "  RHS range        [1e+00, 3e+01]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 32677 (0.01s)\n",
      "Loaded MIP start from previous solve with objective 32677\n",
      "\n",
      "Presolve removed 388 rows and 929 columns\n",
      "Presolve time: 0.08s\n",
      "Presolved: 257 rows, 1587 columns, 5711 nonzeros\n",
      "Found heuristic solution: objective 31975.000000\n",
      "Variable types: 0 continuous, 1587 integer (1366 binary)\n",
      "\n",
      "Root relaxation: objective 2.381513e+04, 108 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 23815.1314    0   42 31975.0000 23815.1314  25.5%     -    0s\n",
      "H    0     0                    31966.000000 23815.1314  25.5%     -    0s\n",
      "H    0     0                    31959.000000 23815.1314  25.5%     -    0s\n",
      "H    0     0                    31923.000000 23815.1314  25.4%     -    0s\n",
      "     0     0 29592.0894    0   78 31923.0000 29592.0894  7.30%     -    0s\n",
      "H    0     0                    31755.000000 29592.0894  6.81%     -    0s\n",
      "     0     0 30429.6925    0   62 31755.0000 30429.6925  4.17%     -    0s\n",
      "     0     0 30429.6925    0   59 31755.0000 30429.6925  4.17%     -    0s\n",
      "     0     0 30429.6925    0   60 31755.0000 30429.6925  4.17%     -    0s\n",
      "     0     0 30429.6925    0   62 31755.0000 30429.6925  4.17%     -    0s\n",
      "     0     0 30795.4029    0   51 31755.0000 30795.4029  3.02%     -    0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H    0     0                    31680.000000 30795.4029  2.79%     -    0s\n",
      "     0     0 30809.9175    0   41 31680.0000 30809.9175  2.75%     -    0s\n",
      "     0     0 30811.0186    0   41 31680.0000 30811.0186  2.74%     -    0s\n",
      "H    0     0                    31659.000000 30811.0186  2.68%     -    0s\n",
      "     0     0 30824.0658    0   65 31659.0000 30824.0658  2.64%     -    0s\n",
      "     0     0 30832.0840    0   49 31659.0000 30832.0840  2.61%     -    0s\n",
      "     0     0 30842.4096    0   51 31659.0000 30842.4096  2.58%     -    0s\n",
      "     0     0 30842.4096    0   52 31659.0000 30842.4096  2.58%     -    0s\n",
      "H    0     0                    31548.000000 30842.4096  2.24%     -    0s\n",
      "     0     0 30855.1314    0   71 31548.0000 30855.1314  2.20%     -    0s\n",
      "H    0     0                    31547.000000 30855.1314  2.19%     -    0s\n",
      "     0     0 30856.0957    0   72 31547.0000 30856.0957  2.19%     -    0s\n",
      "     0     0 30856.3000    0   74 31547.0000 30856.3000  2.19%     -    0s\n",
      "H    0     0                    31468.000000 30856.3000  1.94%     -    0s\n",
      "     0     0 31107.7292    0   66 31468.0000 31107.7292  1.14%     -    0s\n",
      "H    0     0                    31453.000000 31107.7292  1.10%     -    0s\n",
      "     0     0 31107.7292    0   51 31453.0000 31107.7292  1.10%     -    0s\n",
      "     0     0 31107.7292    0   62 31453.0000 31107.7292  1.10%     -    0s\n",
      "H    0     0                    31426.000000 31107.7292  1.01%     -    0s\n",
      "     0     0 31314.7347    0   53 31426.0000 31314.7347  0.35%     -    0s\n",
      "     0     0 31328.9670    0   44 31426.0000 31328.9670  0.31%     -    0s\n",
      "     0     0 31328.9735    0   36 31426.0000 31328.9735  0.31%     -    0s\n",
      "     0     0 31329.5323    0   44 31426.0000 31329.5323  0.31%     -    0s\n",
      "     0     0 31329.8410    0   65 31426.0000 31329.8410  0.31%     -    0s\n",
      "     0     0 31330.6770    0   38 31426.0000 31330.6770  0.30%     -    0s\n",
      "     0     0 31331.0347    0   41 31426.0000 31331.0347  0.30%     -    0s\n",
      "     0     0 31332.1230    0   39 31426.0000 31332.1230  0.30%     -    0s\n",
      "     0     0 31334.3551    0   48 31426.0000 31334.3551  0.29%     -    0s\n",
      "     0     0 31334.3551    0   52 31426.0000 31334.3551  0.29%     -    0s\n",
      "     0     0 31334.3551    0   54 31426.0000 31334.3551  0.29%     -    0s\n",
      "     0     0 31334.3551    0   62 31426.0000 31334.3551  0.29%     -    0s\n",
      "     0     0 31334.3551    0   60 31426.0000 31334.3551  0.29%     -    0s\n",
      "     0     2 31334.3551    0   60 31426.0000 31334.3551  0.29%     -    0s\n",
      "H   30    16                    31344.000000 31343.9285  0.00%  11.4    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 24\n",
      "  Cover: 17\n",
      "  Implied bound: 31\n",
      "  Clique: 13\n",
      "  MIR: 26\n",
      "  StrongCG: 16\n",
      "  Flow cover: 8\n",
      "  GUB cover: 3\n",
      "  Zero half: 3\n",
      "  Network: 1\n",
      "  RLT: 16\n",
      "  Relax-and-lift: 2\n",
      "\n",
      "Explored 35 nodes (1691 simplex iterations) in 0.81 seconds\n",
      "Thread count was 8 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 31344 31426 31453 ... 31923\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-16)\n",
      "Best objective 3.134400000000e+04, best bound 3.134400000000e+04, gap 0.0000%\n",
      "\n",
      "User-callback calls 550, time in user-callback 0.01 sec\n",
      "Objective AP1: 31344.0, MIP-Gap: 0.0%\n",
      "AP1 requires 18 trucks to transport 665 items. 16 trucks and 2 pseudo trucks.\n",
      "Took \t00:00:01.147\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Simple Packing:  2\n",
      "dataP.t2DSP:  1\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "First packing\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "3D Packing Heuristic in Truck P170654301\n",
      "Item 0091017300_08062023000017 with: 2\n",
      "Item 0091017300_08062023000092 with: 2\n",
      "Item 0091017300_08062023000179 with: 3\n",
      "Item 0091017300_08062023000196 with: 2\n",
      "Heuristic packed all items\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "3D Packing Heuristic in Truck P198654301\n",
      "Item 0091017300_08062023000016 with: 2\n",
      "Item 0091017300_08062023000053 with: 2\n",
      "Item 0091017300_08062023000113 with: 3\n",
      "Item 0091017300_08062023000115 with: 1\n",
      "Item 0091017300_08062023000161 with: 1\n",
      "Item 0091017300_08062023000181 with: 1\n",
      "Heuristic packed all items\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "3D Packing Heuristic in Truck P191654301\n",
      "Item 0091017300_08062023000011 with: 1\n",
      "Item 0091017300_08062023000035 with: 4\n",
      "Item 0091017300_08062023000046 with: 1\n",
      "Item 0091017300_08062023000107 with: 1\n",
      "Item 0091017300_08062023000152 with: 1\n",
      "Item 0091017300_08062023000167 with: 2\n",
      "Item 0091017300_08062023000214 with: 1\n",
      "Heuristic packed all items\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "3D Packing Heuristic in Truck P205654301\n",
      "Item 0091017300_08062023000022 with: 1\n",
      "Item 0091017300_08062023000030 with: 1\n",
      "Item 0091017300_08062023000066 with: 3\n",
      "Item 0091017300_08062023000077 with: 1\n",
      "Item 0091017300_08062023000130 with: 1\n",
      "Item 0091017300_08062023000137 with: 2\n",
      "Item 0091017300_08062023000143 with: 1\n",
      "Item 0091017300_08062023000193 with: 3\n",
      "Item 0091017300_08062023000198 with: 1\n",
      "Item 0091017300_08062023000205 with: 2\n",
      "Item 0091017300_08062023000211 with: 1\n",
      "Heuristic packed all items\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P186654301\n",
      "Min2DVol: 17.999999999999996 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000216', '0091017300_08062023000216']\n",
      "Stack 1 with items: ['0091017300_08062023000216', '0091017300_08062023000216']\n",
      "Stack 2 with items: ['0091017300_08062023000216', '0091017300_08062023000216']\n",
      "Stack 3 with items: ['0091017300_08062023000208', '0091017300_08062023000208']\n",
      "Stack 4 with items: ['0091017300_08062023000208', '0091017300_08062023000208']\n",
      "Stack 5 with items: ['0091017300_08062023000208', '0091017300_08062023000208']\n",
      "Stack 6 with items: ['0091017300_08062023000208', '0091017300_08062023000208']\n",
      "Stack 7 with items: ['0091017300_08062023000194', '0091017300_08062023000175']\n",
      "Stack 8 with items: ['0091017300_08062023000148', '0091017300_08062023000148']\n",
      "Stack 9 with items: ['0091017300_08062023000141', '0091017300_08062023000132']\n",
      "Stack 10 with items: ['0091017300_08062023000132', '0091017300_08062023000097']\n",
      "Stack 11 with items: ['0091017300_08062023000097', '0091017300_08062023000097']\n",
      "Stack 12 with items: ['0091017300_08062023000097', '0091017300_08062023000097']\n",
      "Stack 13 with items: ['0091017300_08062023000040', '0091017300_08062023000039']\n",
      "Stack 14 with items: ['0091017300_08062023000039']\n",
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P185654305\n",
      "Min2DVol: 16.872239999999994 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000125', '0091017300_08062023000100', '0091017300_08062023000086']\n",
      "Stack 1 with items: ['0091017300_08062023000086', '0091017300_08062023000026', '0091017300_08062023000051', '0091017300_08062023000006']\n",
      "Stack 2 with items: ['0091017300_08062023000041', '0091017300_08062023000032', '0091017300_08062023000006']\n",
      "Stack 3 with items: ['0091017300_08062023000032']\n",
      "Stack 4 with items: ['0091017300_08062023000188', '0091017300_08062023000188']\n",
      "Stack 5 with items: ['0091017300_08062023000111', '0091017300_08062023000085']\n",
      "Stack 6 with items: ['0091017300_08062023000085', '0091017300_08062023000085']\n",
      "Stack 7 with items: ['0091017300_08062023000085', '0091017300_08062023000085']\n",
      "Stack 8 with items: ['0091017300_08062023000085', '0091017300_08062023000085']\n",
      "Stack 9 with items: ['0091017300_08062023000085', '0091017300_08062023000062']\n",
      "Stack 10 with items: ['0091017300_08062023000062', '0091017300_08062023000062']\n",
      "Stack 11 with items: ['0091017300_08062023000062', '0091017300_08062023000062']\n",
      "Stack 12 with items: ['0091017300_08062023000062', '0091017300_08062023000037']\n",
      "Stack 13 with items: ['0091017300_08062023000037']\n",
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Packing Heuristic in Truck P199654305\n",
      "Min2DVol: 21.690299999999993 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000007', '0091017300_08062023000065', '0091017300_08062023000065']\n",
      "Stack 1 with items: ['0091017300_08062023000140', '0091017300_08062023000138', '0091017300_08062023000138', '0091017300_08062023000140']\n",
      "Stack 2 with items: ['0091017300_08062023000106', '0091017300_08062023000007', '0091017300_08062023000106']\n",
      "Stack 3 with items: ['0091017300_08062023000052', '0091017300_08062023000087', '0091017300_08062023000207']\n",
      "Stack 4 with items: ['0091017300_08062023000185', '0091017300_08062023000201', '0091017300_08062023000207']\n",
      "Stack 5 with items: ['0091017300_08062023000215', '0091017300_08062023000215']\n",
      "Stack 6 with items: ['0091017300_08062023000206', '0091017300_08062023000177']\n",
      "Stack 7 with items: ['0091017300_08062023000177', '0091017300_08062023000177']\n",
      "Stack 8 with items: ['0091017300_08062023000123', '0091017300_08062023000123']\n",
      "Stack 9 with items: ['0091017300_08062023000120', '0091017300_08062023000116']\n",
      "Stack 10 with items: ['0091017300_08062023000116', '0091017300_08062023000116']\n",
      "Stack 11 with items: ['0091017300_08062023000116', '0091017300_08062023000112']\n",
      "Stack 12 with items: ['0091017300_08062023000112', '0091017300_08062023000112']\n",
      "Stack 13 with items: ['0091017300_08062023000112', '0091017300_08062023000112']\n",
      "Stack 14 with items: ['0091017300_08062023000072', '0091017300_08062023000072']\n",
      "Stack 15 with items: ['0091017300_08062023000050', '0091017300_08062023000050']\n",
      "Stack 16 with items: ['0091017300_08062023000036', '0091017300_08062023000036']\n",
      "Stack 17 with items: ['0091017300_08062023000015']\n",
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P208654305\n",
      "Min2DVol: 21.708359999999992 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000180', '0091017300_08062023000173', '0091017300_08062023000160']\n",
      "Stack 1 with items: ['0091017300_08062023000160', '0091017300_08062023000144', '0091017300_08062023000160']\n",
      "Stack 2 with items: ['0091017300_08062023000144', '0091017300_08062023000118', '0091017300_08062023000118']\n",
      "Stack 3 with items: ['0091017300_08062023000118', '0091017300_08062023000105', '0091017300_08062023000076']\n",
      "Stack 4 with items: ['0091017300_08062023000079', '0091017300_08062023000023', '0091017300_08062023000079']\n",
      "Stack 5 with items: ['0091017300_08062023000076', '0091017300_08062023000023', '0091017300_08062023000023', '0091017300_08062023000001']\n",
      "Stack 6 with items: ['0091017300_08062023000154', '0091017300_08062023000104']\n",
      "Stack 7 with items: ['0091017300_08062023000104', '0091017300_08062023000104']\n",
      "Stack 8 with items: ['0091017300_08062023000104', '0091017300_08062023000104']\n",
      "Stack 9 with items: ['0091017300_08062023000104', '0091017300_08062023000104']\n",
      "Stack 10 with items: ['0091017300_08062023000094', '0091017300_08062023000094']\n",
      "Stack 11 with items: ['0091017300_08062023000094', '0091017300_08062023000094']\n",
      "Stack 12 with items: ['0091017300_08062023000094', '0091017300_08062023000094']\n",
      "Stack 13 with items: ['0091017300_08062023000094', '0091017300_08062023000094']\n",
      "Stack 14 with items: ['0091017300_08062023000094', '0091017300_08062023000080']\n",
      "Stack 15 with items: ['0091017300_08062023000080', '0091017300_08062023000042']\n",
      "Stack 16 with items: ['0091017300_08062023000042', '0091017300_08062023000027']\n",
      "Stack 17 with items: ['0091017300_08062023000027', '0091017300_08062023000027']\n",
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P171654305\n",
      "Min2DVol: 22.890299999999993 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000190', '0091017300_08062023000178', '0091017300_08062023000190']\n",
      "Stack 1 with items: ['0091017300_08062023000136', '0091017300_08062023000103', '0091017300_08062023000078', '0091017300_08062023000136', '0091017300_08062023000136', '0091017300_08062023000136']\n",
      "Stack 2 with items: ['0091017300_08062023000078', '0091017300_08062023000058', '0091017300_08062023000078', '0091017300_08062023000078']\n",
      "Stack 3 with items: ['0091017300_08062023000021', '0091017300_08062023000021']\n",
      "Stack 4 with items: ['0091017300_08062023000013', '0091017300_08062023000003']\n",
      "Stack 5 with items: ['0091017300_08062023000212', '0091017300_08062023000212']\n",
      "Stack 6 with items: ['0091017300_08062023000212', '0091017300_08062023000212']\n",
      "Stack 7 with items: ['0091017300_08062023000212', '0091017300_08062023000168']\n",
      "Stack 8 with items: ['0091017300_08062023000162', '0091017300_08062023000162']\n",
      "Stack 9 with items: ['0091017300_08062023000117', '0091017300_08062023000117']\n",
      "Stack 10 with items: ['0091017300_08062023000117', '0091017300_08062023000110']\n",
      "Stack 11 with items: ['0091017300_08062023000110', '0091017300_08062023000110']\n",
      "Stack 12 with items: ['0091017300_08062023000110', '0091017300_08062023000109']\n",
      "Stack 13 with items: ['0091017300_08062023000109', '0091017300_08062023000068']\n",
      "Stack 14 with items: ['0091017300_08062023000060', '0091017300_08062023000060']\n",
      "Stack 15 with items: ['0091017300_08062023000034', '0091017300_08062023000034']\n",
      "Stack 16 with items: ['0091017300_08062023000034', '0091017300_08062023000034']\n",
      "Stack 17 with items: ['0091017300_08062023000005', '0091017300_08062023000005']\n",
      "Stack 18 with items: ['0091017300_08062023000005']\n",
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P173654305\n",
      "Min2DVol: 22.90835999999999 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000197', '0091017300_08062023000176', '0091017300_08062023000176', '0091017300_08062023000176', '0091017300_08062023000197']\n",
      "Stack 1 with items: ['0091017300_08062023000176', '0091017300_08062023000163', '0091017300_08062023000163', '0091017300_08062023000176', '0091017300_08062023000176']\n",
      "Stack 2 with items: ['0091017300_08062023000163', '0091017300_08062023000147', '0091017300_08062023000147']\n",
      "Stack 3 with items: ['0091017300_08062023000093', '0091017300_08062023000031', '0091017300_08062023000091', '0091017300_08062023000031']\n",
      "Stack 4 with items: ['0091017300_08062023000091', '0091017300_08062023000067', '0091017300_08062023000091']\n",
      "Stack 5 with items: ['0091017300_08062023000031', '0091017300_08062023000031', '0091017300_08062023000031', '0091017300_08062023000031']\n",
      "Stack 6 with items: ['0091017300_08062023000164', '0091017300_08062023000150']\n",
      "Stack 7 with items: ['0091017300_08062023000127', '0091017300_08062023000119']\n",
      "Stack 8 with items: ['0091017300_08062023000119', '0091017300_08062023000119']\n",
      "Stack 9 with items: ['0091017300_08062023000119', '0091017300_08062023000119']\n",
      "Stack 10 with items: ['0091017300_08062023000119', '0091017300_08062023000101']\n",
      "Stack 11 with items: ['0091017300_08062023000101', '0091017300_08062023000101']\n",
      "Stack 12 with items: ['0091017300_08062023000101', '0091017300_08062023000083']\n",
      "Stack 13 with items: ['0091017300_08062023000083', '0091017300_08062023000083']\n",
      "Stack 14 with items: ['0091017300_08062023000083', '0091017300_08062023000057']\n",
      "Stack 15 with items: ['0091017300_08062023000057', '0091017300_08062023000057']\n",
      "Stack 16 with items: ['0091017300_08062023000057', '0091017300_08062023000057']\n",
      "Stack 17 with items: ['0091017300_08062023000057', '0091017300_08062023000057']\n",
      "Stack 18 with items: ['0091017300_08062023000057']\n",
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P192654305\n",
      "Min2DVol: 27.708360000000003 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000213', '0091017300_08062023000213']\n",
      "Stack 1 with items: ['0091017300_08062023000213', '0091017300_08062023000213']\n",
      "Stack 2 with items: ['0091017300_08062023000213', '0091017300_08062023000189']\n",
      "Stack 3 with items: ['0091017300_08062023000186', '0091017300_08062023000186']\n",
      "Stack 4 with items: ['0091017300_08062023000183', '0091017300_08062023000183']\n",
      "Stack 5 with items: ['0091017300_08062023000183', '0091017300_08062023000183']\n",
      "Stack 6 with items: ['0091017300_08062023000183', '0091017300_08062023000166']\n",
      "Stack 7 with items: ['0091017300_08062023000166', '0091017300_08062023000165']\n",
      "Stack 8 with items: ['0091017300_08062023000165', '0091017300_08062023000151']\n",
      "Stack 9 with items: ['0091017300_08062023000151', '0091017300_08062023000133']\n",
      "Stack 10 with items: ['0091017300_08062023000126', '0091017300_08062023000126']\n",
      "Stack 11 with items: ['0091017300_08062023000126', '0091017300_08062023000126']\n",
      "Stack 12 with items: ['0091017300_08062023000069', '0091017300_08062023000035']\n",
      "Stack 13 with items: ['0091017300_08062023000035', '0091017300_08062023000035']\n",
      "Stack 14 with items: ['0091017300_08062023000035', '0091017300_08062023000010']\n",
      "Stack 15 with items: ['0091017300_08062023000002', '0091017300_08062023000002']\n",
      "Stack 16 with items: ['0091017300_08062023000002']\n",
      "Stack 17 with items: ['0091017300_08062023000187', '0091017300_08062023000174', '0091017300_08062023000171']\n",
      "Stack 18 with items: ['0091017300_08062023000174', '0091017300_08062023000171', '0091017300_08062023000142']\n",
      "Stack 19 with items: ['0091017300_08062023000142', '0091017300_08062023000099', '0091017300_08062023000142']\n",
      "Stack 20 with items: ['0091017300_08062023000122', '0091017300_08062023000096', '0091017300_08062023000099', '0091017300_08062023000096']\n",
      "Stack 21 with items: ['0091017300_08062023000099', '0091017300_08062023000088', '0091017300_08062023000096', '0091017300_08062023000048']\n",
      "Stack 22 with items: ['0091017300_08062023000088', '0091017300_08062023000048', '0091017300_08062023000048']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P187654305\n",
      "Min2DVol: 28.944479999999988 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000210', '0091017300_08062023000129', '0091017300_08062023000169', '0091017300_08062023000129']\n",
      "Stack 1 with items: ['0091017300_08062023000169', '0091017300_08062023000124', '0091017300_08062023000075']\n",
      "Stack 2 with items: ['0091017300_08062023000124', '0091017300_08062023000098', '0091017300_08062023000089']\n",
      "Stack 3 with items: ['0091017300_08062023000089', '0091017300_08062023000089', '0091017300_08062023000089']\n",
      "Stack 4 with items: ['0091017300_08062023000089', '0091017300_08062023000055', '0091017300_08062023000049']\n",
      "Stack 5 with items: ['0091017300_08062023000055', '0091017300_08062023000028']\n",
      "Stack 6 with items: ['0091017300_08062023000028', '0091017300_08062023000028', '0091017300_08062023000028']\n",
      "Stack 7 with items: ['0091017300_08062023000028', '0091017300_08062023000004']\n",
      "Stack 8 with items: ['0091017300_08062023000184', '0091017300_08062023000184']\n",
      "Stack 9 with items: ['0091017300_08062023000184', '0091017300_08062023000184']\n",
      "Stack 10 with items: ['0091017300_08062023000148', '0091017300_08062023000148']\n",
      "Stack 11 with items: ['0091017300_08062023000148', '0091017300_08062023000084']\n",
      "Stack 12 with items: ['0091017300_08062023000084', '0091017300_08062023000084']\n",
      "Stack 13 with items: ['0091017300_08062023000084', '0091017300_08062023000084']\n",
      "Stack 14 with items: ['0091017300_08062023000084', '0091017300_08062023000084']\n",
      "Stack 15 with items: ['0091017300_08062023000084', '0091017300_08062023000084']\n",
      "Stack 16 with items: ['0091017300_08062023000084', '0091017300_08062023000084']\n",
      "Stack 17 with items: ['0091017300_08062023000064', '0091017300_08062023000064']\n",
      "Stack 18 with items: ['0091017300_08062023000064', '0091017300_08062023000064']\n",
      "Stack 19 with items: ['0091017300_08062023000064', '0091017300_08062023000064']\n",
      "Stack 20 with items: ['0091017300_08062023000064', '0091017300_08062023000064']\n",
      "Stack 21 with items: ['0091017300_08062023000064', '0091017300_08062023000040']\n",
      "Stack 22 with items: ['0091017300_08062023000040', '0091017300_08062023000040']\n",
      "Stack 23 with items: ['0091017300_08062023000040', '0091017300_08062023000040']\n",
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P194654305\n",
      "Min2DVol: 27.726419999999987 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000074', '0091017300_08062023000146', '0091017300_08062023000146']\n",
      "Stack 1 with items: ['0091017300_08062023000074', '0091017300_08062023000074', '0091017300_08062023000095', '0091017300_08062023000095', '0091017300_08062023000095']\n",
      "Stack 2 with items: ['0091017300_08062023000131', '0091017300_08062023000146', '0091017300_08062023000159', '0091017300_08062023000159']\n",
      "Stack 3 with items: ['0091017300_08062023000134', '0091017300_08062023000217', '0091017300_08062023000217']\n",
      "Stack 4 with items: ['0091017300_08062023000134', '0091017300_08062023000128', '0091017300_08062023000108', '0091017300_08062023000134']\n",
      "Stack 5 with items: ['0091017300_08062023000121', '0091017300_08062023000134', '0091017300_08062023000155']\n",
      "Stack 6 with items: ['0091017300_08062023000217', '0091017300_08062023000108', '0091017300_08062023000108', '0091017300_08062023000074']\n",
      "Stack 7 with items: ['0091017300_08062023000139', '0091017300_08062023000139']\n",
      "Stack 8 with items: ['0091017300_08062023000139', '0091017300_08062023000139']\n",
      "Stack 9 with items: ['0091017300_08062023000157', '0091017300_08062023000199']\n",
      "Stack 10 with items: ['0091017300_08062023000157', '0091017300_08062023000157']\n",
      "Stack 11 with items: ['0091017300_08062023000081', '0091017300_08062023000081']\n",
      "Stack 12 with items: ['0091017300_08062023000157', '0091017300_08062023000157']\n",
      "Stack 13 with items: ['0091017300_08062023000157', '0091017300_08062023000157']\n",
      "Stack 14 with items: ['0091017300_08062023000157', '0091017300_08062023000157']\n",
      "Stack 15 with items: ['0091017300_08062023000199', '0091017300_08062023000199']\n",
      "Stack 16 with items: ['0091017300_08062023000157', '0091017300_08062023000157']\n",
      "Stack 17 with items: ['0091017300_08062023000139', '0091017300_08062023000139']\n",
      "Stack 18 with items: ['0091017300_08062023000139', '0091017300_08062023000157']\n",
      "Stack 19 with items: ['0091017300_08062023000213', '0091017300_08062023000213']\n",
      "Stack 20 with items: ['0091017300_08062023000139', '0091017300_08062023000139']\n",
      "Stack 21 with items: ['0091017300_08062023000139', '0091017300_08062023000081']\n",
      "Stack 22 with items: ['0091017300_08062023000081', '0091017300_08062023000081']\n",
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P201654305\n",
      "Min2DVol: 30.162539999999986 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000191', '0091017300_08062023000191', '0091017300_08062023000191']\n",
      "Stack 1 with items: ['0091017300_08062023000191', '0091017300_08062023000170', '0091017300_08062023000170', '0091017300_08062023000191']\n",
      "Stack 2 with items: ['0091017300_08062023000170', '0091017300_08062023000135', '0091017300_08062023000135', '0091017300_08062023000073']\n",
      "Stack 3 with items: ['0091017300_08062023000135', '0091017300_08062023000063', '0091017300_08062023000073', '0091017300_08062023000073', '0091017300_08062023000063']\n",
      "Stack 4 with items: ['0091017300_08062023000063', '0091017300_08062023000047', '0091017300_08062023000047']\n",
      "Stack 5 with items: ['0091017300_08062023000033', '0091017300_08062023000012', '0091017300_08062023000033']\n",
      "Stack 6 with items: ['0091017300_08062023000020', '0091017300_08062023000020', '0091017300_08062023000020']\n",
      "Stack 7 with items: ['0091017300_08062023000020', '0091017300_08062023000012', '0091017300_08062023000012', '0091017300_08062023000020']\n",
      "Stack 8 with items: ['0091017300_08062023000008', '0091017300_08062023000008', '0091017300_08062023000008']\n",
      "Stack 9 with items: ['0091017300_08062023000172', '0091017300_08062023000172']\n",
      "Stack 10 with items: ['0091017300_08062023000172', '0091017300_08062023000172']\n",
      "Stack 11 with items: ['0091017300_08062023000172', '0091017300_08062023000172']\n",
      "Stack 12 with items: ['0091017300_08062023000172', '0091017300_08062023000172']\n",
      "Stack 13 with items: ['0091017300_08062023000172', '0091017300_08062023000116']\n",
      "Stack 14 with items: ['0091017300_08062023000116', '0091017300_08062023000061']\n",
      "Stack 15 with items: ['0091017300_08062023000061', '0091017300_08062023000061']\n",
      "Stack 16 with items: ['0091017300_08062023000061', '0091017300_08062023000061']\n",
      "Stack 17 with items: ['0091017300_08062023000061', '0091017300_08062023000044']\n",
      "Stack 18 with items: ['0091017300_08062023000018', '0091017300_08062023000018']\n",
      "Stack 19 with items: ['0091017300_08062023000018', '0091017300_08062023000018']\n",
      "Stack 20 with items: ['0091017300_08062023000018', '0091017300_08062023000018']\n",
      "Stack 21 with items: ['0091017300_08062023000018', '0091017300_08062023000018']\n",
      "Stack 22 with items: ['0091017300_08062023000018', '0091017300_08062023000018']\n",
      "Stack 23 with items: ['0091017300_08062023000018', '0091017300_08062023000015']\n",
      "Stack 24 with items: ['0091017300_08062023000015']\n",
      "Heuristic packed all stacks\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P236654305\n",
      "Min2DVol: 15.672239999999993 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000204', '0091017300_08062023000059', '0091017300_08062023000203', '0091017300_08062023000059', '0091017300_08062023000204', '0091017300_08062023000204', '0091017300_08062023000204']\n",
      "Stack 1 with items: ['0091017300_08062023000200', '0091017300_08062023000158', '0091017300_08062023000200']\n",
      "Stack 2 with items: ['0091017300_08062023000182', '0091017300_08062023000059', '0091017300_08062023000158', '0091017300_08062023000059']\n",
      "Stack 3 with items: ['0091017300_08062023000114', '0091017300_08062023000114', '0091017300_08062023000114']\n",
      "Stack 4 with items: ['0091017300_08062023000114', '0091017300_08062023000071', '0091017300_08062023000071']\n",
      "Stack 5 with items: ['0091017300_08062023000071', '0091017300_08062023000045', '0091017300_08062023000071']\n",
      "Stack 6 with items: ['0091017300_08062023000054', '0091017300_08062023000054']\n",
      "Stack 7 with items: ['0091017300_08062023000009', '0091017300_08062023000009']\n",
      "Stack 8 with items: ['0091017300_08062023000209', '0091017300_08062023000209']\n",
      "Stack 9 with items: ['0091017300_08062023000202', '0091017300_08062023000202']\n",
      "Stack 10 with items: ['0091017300_08062023000202', '0091017300_08062023000202']\n",
      "Stack 11 with items: ['0091017300_08062023000202', '0091017300_08062023000202']\n",
      "Stack 12 with items: ['0091017300_08062023000202', '0091017300_08062023000202']\n",
      "Stack 13 with items: ['0091017300_08062023000202', '0091017300_08062023000202']\n",
      "Stack 14 with items: ['0091017300_08062023000202', '0091017300_08062023000202']\n",
      "Stack 15 with items: ['0091017300_08062023000195', '0091017300_08062023000195']\n",
      "Stack 16 with items: ['0091017300_08062023000195', '0091017300_08062023000195']\n",
      "Stack 17 with items: ['0091017300_08062023000195', '0091017300_08062023000195']\n",
      "Stack 18 with items: ['0091017300_08062023000195', '0091017300_08062023000195']\n",
      "Stack 19 with items: ['0091017300_08062023000195', '0091017300_08062023000195']\n",
      "Stack 20 with items: ['0091017300_08062023000195', '0091017300_08062023000195']\n",
      "Stack 21 with items: ['0091017300_08062023000195', '0091017300_08062023000195']\n",
      "Stack 22 with items: ['0091017300_08062023000195', '0091017300_08062023000153']\n",
      "Stack 23 with items: ['0091017300_08062023000153', '0091017300_08062023000029']\n",
      "Stack 24 with items: ['0091017300_08062023000029', '0091017300_08062023000024']\n",
      "Stack 25 with items: ['0091017300_08062023000024', '0091017300_08062023000024']\n",
      "Stacks not packed:\n",
      "Stack 24 missing: ['0091017300_08062023000029', '0091017300_08062023000024']\n",
      "Stack 25 missing: ['0091017300_08062023000024', '0091017300_08062023000024']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "3D Packing Heuristic in Truck P236654305\n",
      "Item 0091017300_08062023000029 with: 1\n",
      "Item 0091017300_08062023000024 with: 3\n",
      "Heuristic packed all items\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P178654305\n",
      "Min2DVol: 23.445150000000012 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000038', '0091017300_08062023000043', '0091017300_08062023000056']\n",
      "Stack 1 with items: ['0091017300_08062023000149', '0091017300_08062023000082', '0091017300_08062023000056', '0091017300_08062023000149', '0091017300_08062023000149', '0091017300_08062023000149']\n",
      "Stack 2 with items: ['0091017300_08062023000056', '0091017300_08062023000056', '0091017300_08062023000056', '0091017300_08062023000082', '0091017300_08062023000156']\n",
      "Stack 3 with items: ['0091017300_08062023000056', '0091017300_08062023000102', '0091017300_08062023000102', '0091017300_08062023000149', '0091017300_08062023000149']\n",
      "Stack 4 with items: ['0091017300_08062023000156', '0091017300_08062023000014', '0091017300_08062023000014']\n",
      "Stack 5 with items: ['0091017300_08062023000192', '0091017300_08062023000192']\n",
      "Stack 6 with items: ['0091017300_08062023000192', '0091017300_08062023000192']\n",
      "Stack 7 with items: ['0091017300_08062023000145', '0091017300_08062023000145']\n",
      "Stack 8 with items: ['0091017300_08062023000145', '0091017300_08062023000145']\n",
      "Stack 9 with items: ['0091017300_08062023000145', '0091017300_08062023000090']\n",
      "Stack 10 with items: ['0091017300_08062023000090', '0091017300_08062023000090']\n",
      "Stack 11 with items: ['0091017300_08062023000090', '0091017300_08062023000090']\n",
      "Stack 12 with items: ['0091017300_08062023000090', '0091017300_08062023000070']\n",
      "Stack 13 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 14 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 15 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 16 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 17 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 18 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 19 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 20 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 21 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 22 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 23 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 24 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 25 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 26 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 27 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 28 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 29 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 30 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 31 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 32 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 33 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 34 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 35 with items: ['0091017300_08062023000025', '0091017300_08062023000025']\n",
      "Stack 36 with items: ['0091017300_08062023000025', '0091017300_08062023000019']\n",
      "Stack 37 with items: ['0091017300_08062023000019', '0091017300_08062023000019']\n",
      "Stack 38 with items: ['0091017300_08062023000019', '0091017300_08062023000019']\n",
      "Stacks not packed:\n",
      "Stack 7 missing: ['0091017300_08062023000145', '0091017300_08062023000145']\n",
      "Stack 8 missing: ['0091017300_08062023000145', '0091017300_08062023000145']\n",
      "Stack 9 missing: ['0091017300_08062023000145', '0091017300_08062023000090']\n",
      "Stack 10 missing: ['0091017300_08062023000090', '0091017300_08062023000090']\n",
      "Stack 11 missing: ['0091017300_08062023000090', '0091017300_08062023000090']\n",
      "Stack 12 missing: ['0091017300_08062023000090', '0091017300_08062023000070']\n",
      "Stack 15 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 16 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 17 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 18 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 19 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 20 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 21 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 22 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 23 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 24 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 25 missing: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2D Packing Heuristic in Truck P178654305\n",
      "Min2DVol: 20.39999999999999 [m2]\n",
      "Stack 0 with items: ['0091017300_08062023000145', '0091017300_08062023000145']\n",
      "Stack 1 with items: ['0091017300_08062023000145', '0091017300_08062023000145']\n",
      "Stack 2 with items: ['0091017300_08062023000145', '0091017300_08062023000090']\n",
      "Stack 3 with items: ['0091017300_08062023000090', '0091017300_08062023000090']\n",
      "Stack 4 with items: ['0091017300_08062023000090', '0091017300_08062023000090']\n",
      "Stack 5 with items: ['0091017300_08062023000090', '0091017300_08062023000070']\n",
      "Stack 6 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 7 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 8 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 9 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 10 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 11 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 12 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 13 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 14 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 15 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Stack 16 with items: ['0091017300_08062023000070', '0091017300_08062023000070']\n",
      "Heuristic packed all stacks\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Final Solution\n",
      "Objective;31344.0\n",
      "Transportation cost;27600.0\n",
      "Inventory cost;3744.0\n",
      "Runtime;11.26\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "####################################################################################################\n",
      "Export solution\n",
      "End ROADEF\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Fertig\n"
     ]
    }
   ],
   "source": [
    "typ=\"VA\" #FS\n",
    "InstanceSet = \"X\"# dataset_C_1\" #dataset_C_3\n",
    "\n",
    "print(\"Start\")\n",
    "print(\"Instance: \" , InstanceSet, typ)\n",
    "\n",
    "start_ROADEF(f\"C:/Users/jschulte1/sciebo2/ROADEF/1_Instances/{InstanceSet}/{typ}/input_trucks.csv\",\n",
    "     f\"C:/Users/jschulte1/sciebo2/ROADEF/1_Instances/{InstanceSet}/{typ}/input_items.csv\",\n",
    "     f\"C:/Users/jschulte1/sciebo2/ROADEF/1_Instances/{InstanceSet}/{typ}/input_parameters.csv\",\n",
    "     f\"C:/Users/jschulte1/sciebo2/ROADEF/3_Solutions/test/{typ}/output_trucks.csv\",\n",
    "     f\"C:/Users/jschulte1/sciebo2/ROADEF/3_Solutions/test/{typ}/output_stacks.csv\",\n",
    "     f\"C:/Users/jschulte1/sciebo2/ROADEF/3_Solutions/test/{typ}/output_items.csv\")\n",
    "\"\"\"\n",
    "test(f\"/home/daniel/ownCloud/ROADEF/1_Instances/B/{typ}/input_trucks.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/1_Instances/B/{typ}/input_items.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/1_Instances/B/{typ}/input_parameters.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/3_Solutions/test/{typ}/output_trucks.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/3_Solutions/test/{typ}/output_stacks.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/3_Solutions/test/{typ}/output_items.csv\")\n",
    "\n",
    "start_ROADEF(f\"/home/daniel/ownCloud/ROADEF/1_Instances/B/{typ}/input_trucks.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/1_Instances/B/{typ}/input_items.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/1_Instances/B/{typ}/input_parameters.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/3_Solutions/test/{typ}/output_trucks.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/3_Solutions/test/{typ}/output_stacks.csv\",\n",
    "     f\"/home/daniel/ownCloud/ROADEF/3_Solutions/test/{typ}/output_items.csv\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Fertig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd8431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2343bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#typ=\"TA2\" #FS\n",
    "#InstanceSet = \"C\"# dataset_C_1\" #dataset_C_3\n",
    "\n",
    "#dataP = DataParameters()\n",
    "#dataP.read_instances(f\"C:/Users/jschulte1/sciebo2/ROADEF/1_Instances/{InstanceSet}/{typ}/input_parameters.csv\")\n",
    "#dataT = DataTrucks()\n",
    "#dataT.read_instances(f\"C:/Users/jschulte1/sciebo2/ROADEF/1_Instances/{InstanceSet}/{typ}/input_trucks.csv\", dataP)\n",
    "#dataI = DataItems()\n",
    "#dataI.read_instances(f\"C:/Users/jschulte1/sciebo2/ROADEF/1_Instances/{InstanceSet}/{typ}/input_items.csv\")\n",
    "#dataO = DataOwnData(dataT.T, dataI.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d57d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tt = 'P072386201'\n",
    "#ttIdx = 'P072386201'\n",
    "#num_Item = {'0090038300_28022023005714': 4, '0090038300_28022023006474': 4, '0090038300_28022023007074': 1, '0090038300_28022023007484': 2, '0090038300_28022023009128': 1, '0090038300_28022023019725': 5, '0090038300_28022023020016': 3,\n",
    "#           '0090038300_28022023023277': 1, '0090038300_28022023024510': 5, '0090038300_28022023024594': 4, '0090038300_28022023024959': 5, '0090038300_28022023027142': 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630dfa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0a935c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve_3DPPH(dataT, dataI, dataP, tt, ttIdx, num_Item)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e10766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
