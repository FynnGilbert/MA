{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51595832-52a2-4469-8aee-61428a86c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "#BATCH_SIZE = 2048\n",
    "#BATCH_SIZE = 512\n",
    "PAD_SIZE = 80\n",
    "TARGET_LABELS = [\"Solved\", \"Improvement\", \"Stacks\"]\n",
    "\n",
    "SEED = 3093453"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6016c6-543d-4ede-b6dd-2a4870f324d6",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d07e7-6859-4737-9c4b-91eba870632b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cdfc5c-074f-4f7f-9f9d-39d47b43a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "sns.set(\n",
    "    context=\"talk\",\n",
    "    style=\"darkgrid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e0e78e-ece4-4159-aa86-3cd0d407c31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/fynn/Uni/MA'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd, _ = os.path.split(cwd)\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6f3329-37c6-4683-ad68-5725ed932f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 252949 files belonging to 2 classes.\n",
      "Using 202360 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 13:48:45.313450: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2023-10-22 13:48:45.313478: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-10-22 13:48:45.313481: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-10-22 13:48:45.313515: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-22 13:48:45.313533: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 252949 files belonging to 2 classes.\n",
      "Using 50589 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "samples = os.path.join(cwd, \"data\", \"2D\", \"MIP\")\n",
    "class_names = [\"interrupted\", \"solved\"]\n",
    "\n",
    "train_dataset = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory = samples,\n",
    "    labels = \"inferred\",\n",
    "    label_mode = \"binary\",\n",
    "    class_names = class_names,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    max_length = None,\n",
    "    shuffle = True,\n",
    "    seed = 3093453,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    follow_links = False\n",
    ")\n",
    "\n",
    "val_dataset = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory = samples,\n",
    "    labels = \"inferred\",\n",
    "    label_mode = \"binary\",\n",
    "    class_names = class_names,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    max_length = None,\n",
    "    shuffle = True,\n",
    "    seed = 3093453,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    follow_links = False\n",
    ")\n",
    "\n",
    "class_names = np.array(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67b7b15-cae4-480d-807b-11a180484459",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in train_dataset.take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a95fdba1-fe88-4950-b662-06ebf4803854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3984375\n"
     ]
    }
   ],
   "source": [
    "#y = pd.Series(X.numpy().astype(str)).str.extractall(\"MIP Improvement( )\")\n",
    "#y = y.groupby(y.index.get_level_values(0)).count().to_numpy()[:,0]\n",
    "#y = y == 1\n",
    "print(y.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66902747-b5e1-4f35-9f49-167482be7b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: X\n",
      "instance: CI4\n",
      "+-----------+\n",
      "2D Packing MIP with Time Limit 15.230965131974738 [s] in Truck P200400901\n",
      "Stack 0 with items: ['0090016800_14062023019916', '0090016800_14062023019916']\n",
      "Stack 1 with items: ['0090016800_14062023019916', '0090016800_14062023019916']\n",
      "Stack 2 with items: ['0090016800_14062023039466', '0090016800_14062023039466']\n",
      "Stack 3 with items: ['0090016800_14062023039466', '0090016800_14062023039466']\n",
      "Stack 4 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 5 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 6 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 7 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 8 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 9 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 10 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 11 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 12 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 13 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 14 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 15 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 16 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 17 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 18 with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "Stack 19 with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "Stack 20 with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "MIP Improvement - 2D Vol: 29.50048 [m2] - packed 2D Vol Ratio: 0.8955822707953855 [%] - after 0.0 [s] without stacks:\n",
      "Stack 19 missing: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "Stack 20 missing: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "MIP Improvement - 2D Vol: 29.5005 [m2] - packed 2D Vol Ratio: 0.8955828779599272 [%] - after 0.04369997978210449 [s]\n",
      "Solve interrupted after 15.240414516068995 [s]\n",
      "Stacks not packed:\n",
      "Stack 19 not in final solution with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "Stack 20 not in final solution with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\"raw\": X.numpy().astype(str)})\n",
    "print(df[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8b48de-cb45-4f62-99f0-9cf125c35048",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c26da7a-f0f1-4b99-b35f-519d9c9549df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Supplier code</th><th>Supplier dock</th><th>Plant code</th><th>Plant dock</th><th>Product code</th><th>Package code</th><th>Length</th><th>Width</th><th>Height</th><th>Weight</th><th>Nesting height</th><th>dataset</th><th>instance</th><th>item_id</th><th>ForcedLength</th><th>ForcedWidth</th><th>NestedHeight</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>bool</td><td>f64</td></tr></thead><tbody><tr><td>679301</td><td>null</td><td>90016900</td><td>&quot;169GB-20&quot;</td><td>&quot;760335045R&quot;</td><td>&quot;MTEM--4461&quot;</td><td>2.4</td><td>1.2</td><td>1.9</td><td>0.518208</td><td>0.045</td><td>&quot;C&quot;</td><td>&quot;BY&quot;</td><td>&quot;0090016900_270…</td><td>false</td><td>false</td><td>1.855</td></tr><tr><td>2671602</td><td>null</td><td>90016900</td><td>&quot;169GD-60&quot;</td><td>&quot;777600002R&quot;</td><td>&quot;SFDA--6614&quot;</td><td>1.6</td><td>1.2</td><td>0.93</td><td>0.38658</td><td>0.045</td><td>&quot;C&quot;</td><td>&quot;BY&quot;</td><td>&quot;0090016900_270…</td><td>false</td><td>false</td><td>0.885</td></tr><tr><td>21792913</td><td>null</td><td>90016900</td><td>&quot;GRE1&quot;</td><td>&quot;255679073R&quot;</td><td>&quot;ECA---0021&quot;</td><td>1.2</td><td>1.0</td><td>0.435</td><td>0.031828</td><td>0.0</td><td>&quot;C&quot;</td><td>&quot;BY&quot;</td><td>&quot;0090016900_270…</td><td>false</td><td>false</td><td>0.435</td></tr><tr><td>22060301</td><td>null</td><td>90016900</td><td>&quot;169GB-10&quot;</td><td>&quot;745466747R&quot;</td><td>&quot;SLI---1200&quot;</td><td>1.6</td><td>1.2</td><td>0.93</td><td>0.467056</td><td>0.045</td><td>&quot;C&quot;</td><td>&quot;BY&quot;</td><td>&quot;0090016900_270…</td><td>false</td><td>false</td><td>0.885</td></tr><tr><td>1925700</td><td>null</td><td>90016900</td><td>&quot;GRF1&quot;</td><td>&quot;682003577R&quot;</td><td>&quot;ECM---6632&quot;</td><td>2.4</td><td>2.1</td><td>1.49</td><td>0.5186</td><td>0.045</td><td>&quot;C&quot;</td><td>&quot;BY&quot;</td><td>&quot;0090016900_270…</td><td>false</td><td>false</td><td>1.445</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 17)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ Supplier  ┆ Supplier  ┆ Plant     ┆ Plant     ┆ … ┆ item_id   ┆ ForcedLen ┆ ForcedWid ┆ NestedHe │\n",
       "│ code      ┆ dock      ┆ code      ┆ dock      ┆   ┆ ---       ┆ gth       ┆ th        ┆ ight     │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ str       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i64       ┆ str       ┆ i64       ┆ str       ┆   ┆           ┆ bool      ┆ bool      ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 679301    ┆ null      ┆ 90016900  ┆ 169GB-20  ┆ … ┆ 009001690 ┆ false     ┆ false     ┆ 1.855    │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 0_2702202 ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 3000041   ┆           ┆           ┆          │\n",
       "│ 2671602   ┆ null      ┆ 90016900  ┆ 169GD-60  ┆ … ┆ 009001690 ┆ false     ┆ false     ┆ 0.885    │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 0_2702202 ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 3000071   ┆           ┆           ┆          │\n",
       "│ 21792913  ┆ null      ┆ 90016900  ┆ GRE1      ┆ … ┆ 009001690 ┆ false     ┆ false     ┆ 0.435    │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 0_2702202 ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 3000077   ┆           ┆           ┆          │\n",
       "│ 22060301  ┆ null      ┆ 90016900  ┆ 169GB-10  ┆ … ┆ 009001690 ┆ false     ┆ false     ┆ 0.885    │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 0_2702202 ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 3000183   ┆           ┆           ┆          │\n",
       "│ 1925700   ┆ null      ┆ 90016900  ┆ GRF1      ┆ … ┆ 009001690 ┆ false     ┆ false     ┆ 1.445    │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 0_2702202 ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 3000186   ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"truck-item-infos\"\n",
    "file = \"items.csv\"\n",
    "\n",
    "item_path = os.path.join(cwd, folder, file)\n",
    "items = pl.read_csv(source = item_path);\n",
    "\n",
    "items = items.lazy().with_columns([\n",
    "    (pl.col(\"Item ident\").alias(\"item_id\")),\n",
    "    (pl.col(\"Length\") / 1000), # mm to m\n",
    "    (pl.col(\"Width\") / 1000),  # mm to m\n",
    "    (pl.col(\"Height\") / 1000), # mm to m\n",
    "    (pl.col(\"Nesting height\") / 1000), # mm to m\n",
    "    (pl.col(\"Weight\") / 1000), # kg to tons\n",
    "    (pl.col(\"Forced orientation\") == \"lengthwise\").alias(\"ForcedLength\"),\n",
    "    (pl.col(\"Forced orientation\") == \"widthwise\").alias(\"ForcedWidth\"),\n",
    "    ((pl.col(\"Height\") - pl.col(\"Nesting height\")) / 1000).alias(\"NestedHeight\"),\n",
    "    pl.col(\"dataset\").str.extract(\"([A-Z])\")\n",
    "]).drop([\n",
    "    \"Forced orientation\", \"Max stackability\", \"Inventory cost\",\n",
    "    \"Earliest arrival time\", \"Latest arrival time\", \"Number of items\",\n",
    "    \"instance_id\",\n",
    "    \"Stackability code\",\n",
    "    \"Item ident\" # drop because of rename earlier\n",
    "]).unique()\n",
    "\n",
    "items.collect().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc63cfa-2e58-450c-8880-6b1bbfc96140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Supplier code</th><th>Supplier loading order</th><th>Supplier dock</th><th>Supplier dock loading order</th><th>Plant dock</th><th>Plant dock loading order</th><th>truck_id</th><th>dataset</th><th>instance</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>62059600</td><td>1</td><td>null</td><td>1</td><td>&quot;X0&quot;</td><td>1</td><td>&quot;P187721701&quot;</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr><tr><td>29908700</td><td>1</td><td>null</td><td>1</td><td>&quot;X4&quot;</td><td>1</td><td>&quot;P187730401&quot;</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr><tr><td>29908700</td><td>1</td><td>null</td><td>1</td><td>&quot;X4&quot;</td><td>1</td><td>&quot;P187730403&quot;</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr><tr><td>29908700</td><td>1</td><td>null</td><td>1</td><td>&quot;X4&quot;</td><td>1</td><td>&quot;P187730405&quot;</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr><tr><td>29908700</td><td>1</td><td>null</td><td>1</td><td>&quot;X4&quot;</td><td>1</td><td>&quot;P187730407&quot;</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌────────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬─────────┬──────────┐\n",
       "│ Supplier   ┆ Supplier   ┆ Supplier  ┆ Supplier  ┆ … ┆ Plant     ┆ truck_id  ┆ dataset ┆ instance │\n",
       "│ code       ┆ loading    ┆ dock      ┆ dock      ┆   ┆ dock      ┆ ---       ┆ ---     ┆ ---      │\n",
       "│ ---        ┆ order      ┆ ---       ┆ loading   ┆   ┆ loading   ┆ str       ┆ str     ┆ str      │\n",
       "│ i64        ┆ ---        ┆ str       ┆ order     ┆   ┆ order     ┆           ┆         ┆          │\n",
       "│            ┆ i64        ┆           ┆ ---       ┆   ┆ ---       ┆           ┆         ┆          │\n",
       "│            ┆            ┆           ┆ i64       ┆   ┆ i64       ┆           ┆         ┆          │\n",
       "╞════════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═════════╪══════════╡\n",
       "│ 62059600   ┆ 1          ┆ null      ┆ 1         ┆ … ┆ 1         ┆ P18772170 ┆ A       ┆ AS       │\n",
       "│            ┆            ┆           ┆           ┆   ┆           ┆ 1         ┆         ┆          │\n",
       "│ 29908700   ┆ 1          ┆ null      ┆ 1         ┆ … ┆ 1         ┆ P18773040 ┆ A       ┆ AS       │\n",
       "│            ┆            ┆           ┆           ┆   ┆           ┆ 1         ┆         ┆          │\n",
       "│ 29908700   ┆ 1          ┆ null      ┆ 1         ┆ … ┆ 1         ┆ P18773040 ┆ A       ┆ AS       │\n",
       "│            ┆            ┆           ┆           ┆   ┆           ┆ 3         ┆         ┆          │\n",
       "│ 29908700   ┆ 1          ┆ null      ┆ 1         ┆ … ┆ 1         ┆ P18773040 ┆ A       ┆ AS       │\n",
       "│            ┆            ┆           ┆           ┆   ┆           ┆ 5         ┆         ┆          │\n",
       "│ 29908700   ┆ 1          ┆ null      ┆ 1         ┆ … ┆ 1         ┆ P18773040 ┆ A       ┆ AS       │\n",
       "│            ┆            ┆           ┆           ┆   ┆           ┆ 7         ┆         ┆          │\n",
       "└────────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴─────────┴──────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"trucks.csv\"\n",
    "\n",
    "truck_path = os.path.join(cwd, folder, file)\n",
    "\n",
    "truck_clms = [\"Id truck\", \"dataset\", \"instance\",\n",
    "              \"Supplier code\", \"Supplier dock\", \"Plant dock\",\n",
    "              \"Supplier loading order\", \"Supplier dock loading order\", \"Plant dock loading order\",\n",
    "             ]\n",
    "\n",
    "truck_stops = (\n",
    "    pl.read_csv(source = truck_path, columns = truck_clms)\n",
    "    .lazy()\n",
    "    .unique()\n",
    "    .rename({\"Id truck\": \"truck_id\"})\n",
    "    .sort([\"dataset\", \"instance\", \"truck_id\"])\n",
    "    .with_columns([pl.col(\"dataset\").str.extract(\"(\\w)\")])\n",
    ")\n",
    "truck_stops.collect().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e492480-4e8d-4534-8029-096c64ec1da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>truck_id</th><th>Length</th><th>Width</th><th>Weight</th><th>dataset</th><th>instance</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;P187721701&quot;</td><td>14.94</td><td>2.5</td><td>24.0</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr><tr><td>&quot;P187730401&quot;</td><td>14.94</td><td>2.5</td><td>24.0</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr><tr><td>&quot;P187730403&quot;</td><td>14.94</td><td>2.5</td><td>24.0</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr><tr><td>&quot;P187730405&quot;</td><td>14.94</td><td>2.5</td><td>24.0</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr><tr><td>&quot;P187730407&quot;</td><td>14.94</td><td>2.5</td><td>24.0</td><td>&quot;A&quot;</td><td>&quot;AS&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌────────────┬────────┬───────┬────────┬─────────┬──────────┐\n",
       "│ truck_id   ┆ Length ┆ Width ┆ Weight ┆ dataset ┆ instance │\n",
       "│ ---        ┆ ---    ┆ ---   ┆ ---    ┆ ---     ┆ ---      │\n",
       "│ str        ┆ f64    ┆ f64   ┆ f64    ┆ str     ┆ str      │\n",
       "╞════════════╪════════╪═══════╪════════╪═════════╪══════════╡\n",
       "│ P187721701 ┆ 14.94  ┆ 2.5   ┆ 24.0   ┆ A       ┆ AS       │\n",
       "│ P187730401 ┆ 14.94  ┆ 2.5   ┆ 24.0   ┆ A       ┆ AS       │\n",
       "│ P187730403 ┆ 14.94  ┆ 2.5   ┆ 24.0   ┆ A       ┆ AS       │\n",
       "│ P187730405 ┆ 14.94  ┆ 2.5   ┆ 24.0   ┆ A       ┆ AS       │\n",
       "│ P187730407 ┆ 14.94  ┆ 2.5   ┆ 24.0   ┆ A       ┆ AS       │\n",
       "└────────────┴────────┴───────┴────────┴─────────┴──────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"trucks.csv\"\n",
    "\n",
    "truck_path = os.path.join(cwd, folder, file)\n",
    "\n",
    "truck_clms = [\"Id truck\", \"dataset\", \"instance\",\n",
    "              \"Length\", \"Width\", \"Max weight\",\n",
    "             ]\n",
    "\n",
    "truck_dims = (\n",
    "    pl.read_csv(source = truck_path, columns = truck_clms)\n",
    "    .lazy()\n",
    "    .unique()\n",
    "    .rename({\"Id truck\": \"truck_id\", \"Max weight\": \"Weight\"})\n",
    "    .sort([\"dataset\", \"instance\", \"truck_id\"])\n",
    "    .with_columns([pl.col(\"dataset\").str.extract(\"(\\w)\")])\n",
    ")\n",
    "\n",
    "truck_dims = truck_dims.with_columns([\n",
    "    (pl.col(\"Length\") / 1000),\n",
    "    (pl.col(\"Width\") / 1000),\n",
    "    (pl.col(\"Weight\") / 1000),\n",
    "])\n",
    "\n",
    "truck_dims.collect().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4904732-a116-4f7d-a5c1-8d17caf2a558",
   "metadata": {},
   "source": [
    "## Preprocessing Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9335a9-2bd8-41f7-ba46-909dee42efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.preprocessing import extract_raw_data, explode_instances_into_stacks, explode_stacks_into_items\n",
    "from utils.preprocessing import join_items, group_items_by_stack, join_truck_loading_order, append_truck_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f191cc73-619b-4f7e-9f1d-2ed53bca5583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1.38, 1.15, ..., False, '1-1-2', False],\n",
       "       [0, 1.38, 1.15, ..., False, '1-1-2', False],\n",
       "       [0, 1.358, 1.153, ..., False, '1-1-2', False],\n",
       "       ...,\n",
       "       [1023, 1.6, 1.2, ..., False, '1-1-2', False],\n",
       "       [1023, 1.6, 1.2, ..., False, '1-1-2', False],\n",
       "       [1023, 13.5, 2.44, ..., False, '0-0-0', True]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = (\n",
    "    df.lazy()\n",
    "    .pipe(extract_raw_data)\n",
    "    .pipe(explode_instances_into_stacks)\n",
    "    .pipe(explode_stacks_into_items)\n",
    "    .pipe(join_items, items)\n",
    "    .pipe(group_items_by_stack)\n",
    "    .pipe(join_truck_loading_order, truck_stops)\n",
    "    .pipe(append_truck_info, truck_dims)\n",
    "    .collect()\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4c5abbd-dbdb-49a6-a47b-a8c47618b916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 80, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tensor_representation(X, packing_clm=6):\n",
    "\n",
    "    # add columns for Length and Width Remainder\n",
    "    X = np.append(X, np.zeros((X.shape[0], 2)), axis=1)\n",
    "    \n",
    "    indices = np.unique(X[:, 0])\n",
    "    indices = np.sort(indices)\n",
    "\n",
    "    # (batch_size, ?, features)\n",
    "    X = np.array([X[X[:,0] == idx] for idx in indices], dtype = \"object\")\n",
    "\n",
    "    # replace the packing order with the stop index (i.e 1-1-1 and 1-1-2 turn to 0 and 1, respectively)\n",
    "    #packing_clm = min([i for i, clm in enumerate(df.columns) if clm == \"packing_order\"])\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        packing_order = x[:,packing_clm]\n",
    "        stops = np.unique(packing_order)\n",
    "        stops = np.sort(stops)\n",
    "        stops = {stop: j for j, stop in enumerate(stops)}\n",
    "        stops = [stops[order] for order in packing_order]\n",
    "        X[i][:,packing_clm] = stops\n",
    "\n",
    "    # pad the variable length number of stacks into fixed\n",
    "    #  (batch_size, pad_size, features)\n",
    "    X = tf.keras.utils.pad_sequences(X, maxlen=PAD_SIZE, padding = \"post\", dtype=\"float64\")\n",
    "    # drop the index column (batch_size, pad_len, n_features)\n",
    "    X = X[:,:,1:].astype(float)\n",
    "\n",
    "    # Add Length and width Remainder\n",
    "    for xx in X:\n",
    "        truck_width = max(xx[:,1])\n",
    "        # Length Remainder\n",
    "        xx[:,-2] = truck_width % xx[:,0]\n",
    "        # Width Remainder\n",
    "        xx[:,-1] = truck_width % xx[:,1]\n",
    "    \n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "c = get_tensor_representation(XX)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2a99a4e-67bb-42ed-ac51-d1391e3825ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.6  ,  1.2  ,  0.448,  0.   ,  0.   ,  1.   ,  0.   ,  0.9  ,\n",
       "         0.1  ],\n",
       "       [ 1.2  ,  1.   ,  0.543,  0.   ,  0.   ,  1.   ,  0.   ,  0.1  ,\n",
       "         0.5  ],\n",
       "       [14.94 ,  2.5  , 24.   ,  0.   ,  0.   ,  0.   ,  1.   ,  2.5  ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[1, :, :].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dab19ec-58a3-4088-a89b-934e01616d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additional_labels(df: pl.DataFrame) -> dict[str: np.array]:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = \"MIP Improvement - 2D Vol: \\d*\\.\\d* \\[m2\\] - packed 2D Vol Ratio\\: \\d*\\.\\d* \\[\\%\\] - after \\d*\\.\\d* \\[s\\]\"\n",
    "    mip_improvements = df[\"raw\"].str.extract_all(pattern)#.list[-1][2]\n",
    "\n",
    "    # mip_improvements: pl.Series[list[str]]\n",
    "    # with entries according to the pattern, i.e all MIP improvement rows\n",
    "    \n",
    "    y_num_improvements = mip_improvements.list.len()-1\n",
    "    \n",
    "    y_improvement = y_num_improvements > 0\n",
    "\n",
    "    y_packed_area_ratio = mip_improvements.list[-1].str.extract(\"\\: (\\d*\\.\\d*) \\[\\%\\]\").cast(pl.Float32)\n",
    "\n",
    "    y_packed_area = mip_improvements.list[-1].str.extract(\"- 2D Vol: (\\d*\\.\\d*) \\[m2\\]\").cast(pl.Float32)\n",
    "\n",
    "    y_last_update = mip_improvements.list[-1].str.extract(\"- after (\\d*\\.\\d*) \\[s\\]\").cast(pl.Float32)\n",
    "\n",
    "\n",
    "    # missing stacks:\n",
    "    y_stack_not_included = np.zeros((len(df), PAD_SIZE), dtype=float)\n",
    "    pattern = \"Stack (\\d*) not in final solution with items:\"\n",
    "    x = df[\"raw\"].str.extract_all(pattern).map_elements(lambda x: [int(i.split(\" \")[1]) for i in x])\n",
    "    \n",
    "    for i, missing_stacks in enumerate(x):\n",
    "        for j in missing_stacks:\n",
    "            y_stack_not_included[i, j] +=1\n",
    "\n",
    "\n",
    "    y = [\n",
    "        #y_num_improvements.to_numpy(),\n",
    "        y_improvement.to_numpy().astype(int),\n",
    "        #y_packed_area_ratio.to_numpy(),\n",
    "        #y_packed_area.to_numpy(),\n",
    "        #y_last_update.to_numpy(),\n",
    "        y_stack_not_included\n",
    "    ]\n",
    "    \n",
    "    return y\n",
    "\n",
    "#pattern = \"Stack (\\d*) not in final solution with items:\"\n",
    "#df[\"raw\"].str.extract_all(pattern).apply(lambda x: [i.split(\" \")[1] for i in x])\n",
    "#x = df[\"raw\"].str.extract_all(pattern).map_elements(lambda x: [int(i.split(\" \")[1]) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bafa29a5-dc95-42ea-b83c-71eb6033d6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4873046875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"MIP Improvement - 2D Vol: \\d*\\.\\d* \\[m2\\] - packed 2D Vol Ratio\\: \\d*\\.\\d* \\[\\%\\] - after \\d*\\.\\d* \\[s\\]\"\n",
    "mip_improvements = df[\"raw\"].str.extract_all(pattern)#.list[-1][2]\n",
    "y_num_improvements = mip_improvements.list.len()-1\n",
    "y_improvement = y_num_improvements > 0\n",
    "y_improvement.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40b87667-6312-4513-8242-501990e1deac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0159912109375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_stack_not_included = np.zeros((BATCH_SIZE, PAD_SIZE), dtype=float)\n",
    "pattern = \"Stack (\\d*) not in final solution with items:\"\n",
    "x = df[\"raw\"].str.extract_all(pattern).map_elements(lambda x: [int(i.split(\" \")[1]) for i in x])\n",
    "    \n",
    "for i, missing_stacks in enumerate(x):\n",
    "    for j in missing_stacks:\n",
    "        y_stack_not_included[i, j] +=1\n",
    "\n",
    "y_stack_not_included.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f1958a1-dd25-4c43-9c32-fd9ae6e0eea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pattern = \"2D Packing MIP with Time Limit (\\d*\\.?\\d*) \\[s\\]\"\n",
    "x = df[\"raw\"].str.extract(pattern).cast(pl.Float32)\n",
    "plt.hist(x, bins=np.arange(0, 31, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c124bd32-2e6d-49c5-8860-26ab6cb216f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polars_transformation(X_batch, y_batch) -> (np.array, np.array):\n",
    "    \"\"\"\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    X: np.array[float32]\n",
    "        3D Feature Tensor of shape (Batch_size, Pad_size, n_features=7)\n",
    "\n",
    "        - Batch_size: Truck Optimization Instances\n",
    "        - Pad_size: Stacks (or Trucks), padded up to create tensors\n",
    "        - n_features: Length, Width, Weight, L/W Forced Orientation\n",
    "                      packing order, is_truck\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pl.DataFrame({\"raw\": X_batch.numpy().astype(str)})\n",
    "    \n",
    "    X = (\n",
    "        df.lazy()\n",
    "        .pipe(extract_raw_data)\n",
    "        .pipe(explode_instances_into_stacks)\n",
    "        .pipe(explode_stacks_into_items)\n",
    "        .pipe(join_items, items)\n",
    "        .pipe(group_items_by_stack)\n",
    "        .pipe(join_truck_loading_order, truck_stops)\n",
    "        .pipe(append_truck_info, truck_dims)\n",
    "        .collect()\n",
    "        .to_numpy()\n",
    "    )\n",
    "\n",
    "    X = get_tensor_representation(X)\n",
    "\n",
    "    # fill final column with bool for stack not in initial solution\n",
    "    pattern = \"Stack (\\d*) missing:\"\n",
    "    x = df[\"raw\"].str.extract_all(pattern).map_elements(lambda x: [int(i.split(\" \")[1]) for i in x])\n",
    "\n",
    "    for i, missing_stacks in enumerate(x):\n",
    "        for j in missing_stacks:\n",
    "            X[i, j, 6] +=1\n",
    "\n",
    "    \n",
    "    # extract the time limit\n",
    "    pattern = \"2D Packing MIP with Time Limit (\\d*\\.?\\d*) \\[s\\]\"\n",
    "    x_time_limit = df[\"raw\"].str.extract(pattern).cast(pl.Float32).to_numpy()\n",
    "\n",
    "    y_batch = y_batch.numpy()\n",
    "    y_batch = [y_batch]\n",
    "    y_extra = get_additional_labels(df)\n",
    "    y_batch += y_extra\n",
    "\n",
    "    X = [X, x_time_limit]\n",
    "    \n",
    "    return X, y_batch\n",
    "\n",
    "cx, cy = polars_transformation(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2235d83-51e0-4c01-84e7-c04cb712ced5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.38 ,  1.15 ,  1.062,  0.   ,  0.   ,  1.   ,  0.   ,  1.06 ,\n",
       "         0.14 ],\n",
       "       [ 1.38 ,  1.15 ,  1.062,  0.   ,  0.   ,  1.   ,  0.   ,  1.06 ,\n",
       "         0.14 ],\n",
       "       [ 1.358,  1.153,  0.748,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.748,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.748,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.748,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.748,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.748,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.748,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.748,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.748,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.722,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.722,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.722,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.722,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.722,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.722,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.358,  1.153,  0.722,  0.   ,  0.   ,  1.   ,  0.   ,  1.082,\n",
       "         0.134],\n",
       "       [ 1.37 ,  0.93 ,  0.691,  0.   ,  0.   ,  1.   ,  0.   ,  1.07 ,\n",
       "         0.58 ],\n",
       "       [ 1.37 ,  0.93 ,  0.691,  0.   ,  0.   ,  1.   ,  1.   ,  1.07 ,\n",
       "         0.58 ],\n",
       "       [ 1.37 ,  0.93 ,  0.691,  0.   ,  0.   ,  1.   ,  1.   ,  1.07 ,\n",
       "         0.58 ],\n",
       "       [13.5  ,  2.44 , 24.   ,  0.   ,  0.   ,  0.   ,  1.   ,  2.44 ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx[0][0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b05dd03-d074-4b11-9ac6-5cf34e1fc0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: X\n",
      "instance: CI4\n",
      "+-----------+\n",
      "2D Packing MIP with Time Limit 15.230965131974738 [s] in Truck P200400901\n",
      "Stack 0 with items: ['0090016800_14062023019916', '0090016800_14062023019916']\n",
      "Stack 1 with items: ['0090016800_14062023019916', '0090016800_14062023019916']\n",
      "Stack 2 with items: ['0090016800_14062023039466', '0090016800_14062023039466']\n",
      "Stack 3 with items: ['0090016800_14062023039466', '0090016800_14062023039466']\n",
      "Stack 4 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 5 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 6 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 7 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 8 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 9 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 10 with items: ['0090016800_14062023031152', '0090016800_14062023031152']\n",
      "Stack 11 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 12 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 13 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 14 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 15 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 16 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 17 with items: ['0090016800_14062023025658', '0090016800_14062023025658']\n",
      "Stack 18 with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "Stack 19 with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "Stack 20 with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "MIP Improvement - 2D Vol: 29.50048 [m2] - packed 2D Vol Ratio: 0.8955822707953855 [%] - after 0.0 [s] without stacks:\n",
      "Stack 19 missing: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "Stack 20 missing: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "MIP Improvement - 2D Vol: 29.5005 [m2] - packed 2D Vol Ratio: 0.8955828779599272 [%] - after 0.04369997978210449 [s]\n",
      "Solve interrupted after 15.240414516068995 [s]\n",
      "Stacks not packed:\n",
      "Stack 19 not in final solution with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n",
      "Stack 20 not in final solution with items: ['0090016800_14062023038996', '0090016800_14062023038996']\n"
     ]
    }
   ],
   "source": [
    "print(df[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "137caf45-ac93-49a3-8a23-7dab7eb1dcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_stack_not_included = np.zeros((len(df), PAD_SIZE), dtype=float)\n",
    "pattern = \"Stack (\\d*) missing:\"\n",
    "x = df[\"raw\"].str.extract_all(pattern).map_elements(lambda x: [int(i.split(\" \")[1]) for i in x])\n",
    "x    \n",
    "#for i, missing_stacks in enumerate(x):\n",
    "#    for j in missing_stacks:\n",
    "#        y_stack_not_included[i, j] +=1\n",
    "plt.hist(x.list.len(), bins = np.arange(0, 11, 1)-0.5);\n",
    "plt.xlabel(\"Stacks Missing\"); # If no stacks were missing, we would have the optimal solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bff52-d516-4e59-adc3-dc6879865197",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba3a13-e18c-42b5-a652-e98181cfadef",
   "metadata": {},
   "source": [
    "## Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb0d9d3a-8089-45e8-8510-d5692a1239f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Layer Dropout of 5.0% resulting in a total Dropout of 30.0% over 7 encoders\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = cx[0].shape[-1]\n",
    "\n",
    "# number of encoder blocks\n",
    "n_blocks = 7 #6\n",
    "num_heads = 4\n",
    "key_dim = int(N_FEATURES/num_heads)\n",
    "use_bias = True # If true the convergence seems to be much faster/sooner. But with false, it picks up pace later\n",
    "## Encoder dropout in total and per layer\n",
    "total_encoder_dropout = 0.3\n",
    "encoder_dropout = 1-(1-total_encoder_dropout)**(1/n_blocks)\n",
    "print(f\"Encoder Layer Dropout of {encoder_dropout:.1%} resulting in a total Dropout of {total_encoder_dropout:.1%} over {n_blocks} encoders\")\n",
    "\n",
    "\n",
    "# number of fully connected layers with droput\n",
    "#fully_connected_units = [] # [16]\n",
    "#fully_connected_dropout_rate = 0.5\n",
    "\n",
    "# activation function\n",
    "activation = \"gelu\" # \"relu\" \"gelu\" \"selu\" \"swish\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Learning Rate\n",
    "initial_lr = 10e-3 # 10e-3\n",
    "lr_decay = 0.7 # 0.9\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate = initial_lr)\n",
    "#optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "# Loss Function\n",
    "#loss_fn = tf.keras.losses.BinaryCrossentropy(name=\"binary_crossentropy\",)\n",
    "\n",
    "# Focal Loss gamma:\n",
    "\n",
    "loss_solved = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "    gamma=3,\n",
    "    alpha = 1-y.numpy().mean(),\n",
    "    name='solved_focal_loss'\n",
    ")\n",
    "\n",
    "loss_improvement = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "    gamma=2,\n",
    "    #alpha = 0.56,\n",
    "    alpha = 1-y_improvement.mean(),\n",
    "    name='improvement_focal_loss'\n",
    ")\n",
    "\n",
    "\n",
    "loss_stacks = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "    gamma=6,\n",
    "    alpha = 1-y_stack_not_included.mean(),\n",
    "    name='stacks_focal_loss'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81273159-358d-465f-ba74-d6ea72a07e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_objects = [\n",
    "    loss_solved,\n",
    "    loss_improvement,\n",
    "    loss_stacks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90033cb5-930e-447d-b6e6-b0a917dc15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_losses = [tf.keras.metrics.Mean(name=target) for target in TARGET_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e3e5121-bd70-407e-89eb-d7cae6c21c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics: list[list[tf.keras.metrics]] = [\n",
    "    [\n",
    "        tf.keras.metrics.Precision(name = \"PRC\"),\n",
    "        tf.keras.metrics.Recall(name = \"SNS\"),\n",
    "        tf.keras.metrics.AUC(curve='PR', name=\"AUC\"),\n",
    "        tf.keras.metrics.BinaryAccuracy(name = \"ACC\")\n",
    "    ],\n",
    "    [\n",
    "        tf.keras.metrics.Precision(name = \"PRC\"),\n",
    "        tf.keras.metrics.Recall(name = \"SNS\"),\n",
    "        tf.keras.metrics.AUC(curve='PR', name=\"AUC\"),\n",
    "        tf.keras.metrics.BinaryAccuracy(name = \"ACC\")\n",
    "    ],\n",
    "    [\n",
    "        tf.keras.metrics.Precision(name = \"PRC\"),\n",
    "        tf.keras.metrics.Recall(name = \"SNS\"),\n",
    "        tf.keras.metrics.AUC(curve='PR', name=\"AUC\"),\n",
    "        tf.keras.metrics.BinaryAccuracy(name = \"ACC\")\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2172818-ab30-45a6-a332-0062ac6574e7",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b5ba812-571a-4e1e-bedc-ce5bb0abd56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Masking, BatchNormalization, MultiHeadAttention, LayerNormalization, Dropout\n",
    "from tensorflow.keras.layers import Add, Dense, Input, Reshape, Permute, Lambda, Concatenate\n",
    "\n",
    "from utils.DNN.model_layers import TransformerEncoder\n",
    "\n",
    "#help(Masking)\n",
    "#help(MultiHeadAttention)\n",
    "#help(Reshape)\n",
    "#help(Dropout)\n",
    "#help(Lambda)\n",
    "#help(Concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b3f6f99-9f5c-4a06-98d8-a9b1b199fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model using the functional API:\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "# Input\n",
    "input_stack_level = Input(shape=(PAD_SIZE, N_FEATURES), name=\"StackLevelInputFeatures\")\n",
    "input_time_limit = Input(shape=(1), name=\"TimeLimitInput\")\n",
    "inputs = [input_stack_level, input_time_limit]\n",
    "\n",
    "\n",
    "# Masking padded input\n",
    "masking_layer = Masking(\n",
    "    mask_value=0,\n",
    "    input_shape=(PAD_SIZE, N_FEATURES),\n",
    "    dtype=tf.float16, # float, # tf.float16\n",
    "    name=\"MaskingLayer\"\n",
    ")\n",
    "x = masking_layer(input_stack_level)\n",
    "\n",
    "#batch_norm_layer = BatchNormalization(name=\"BatchNormalizationLayer\")\n",
    "#x = batch_norm_layer(masking_layer)\n",
    "\n",
    "\n",
    "# Encoder Block\n",
    "for i in range(1, n_blocks+1):\n",
    "    # Self attention with add and layer norm\n",
    "    self_attention_layer = TransformerEncoder(\n",
    "        num_heads=num_heads, key_dim=key_dim,\n",
    "        dropout=encoder_dropout,               # Hyperparameter\n",
    "        use_bias=use_bias,                     # usually False, but technically Hyperparameter\n",
    "        idx = i,\n",
    "        activation=activation,\n",
    "        units = N_FEATURES,\n",
    "        use_PreLN=True\n",
    "    )\n",
    "    x = self_attention_layer(x)\n",
    "\n",
    "\n",
    "self_attention_layer_solved = TransformerEncoder(\n",
    "        num_heads=num_heads, key_dim=key_dim,\n",
    "        dropout=encoder_dropout,               # Hyperparameter\n",
    "        use_bias=use_bias,                     # usually False, but technically Hyperparameter\n",
    "        idx = \"solved\",\n",
    "        activation=activation,\n",
    "        units = N_FEATURES,\n",
    "        use_PreLN=True\n",
    "    )\n",
    "attention_solved = self_attention_layer_solved(x)\n",
    "\n",
    "self_attention_layer_improvement = TransformerEncoder(\n",
    "        num_heads=num_heads, key_dim=key_dim,\n",
    "        dropout=encoder_dropout,               # Hyperparameter\n",
    "        use_bias=use_bias,                     # usually False, but technically Hyperparameter\n",
    "        idx = \"improvement\",\n",
    "        activation=activation,\n",
    "        units = N_FEATURES,\n",
    "        use_PreLN=True\n",
    "    )\n",
    "attention_improvement = self_attention_layer_improvement(x)\n",
    "\n",
    "self_attention_layer_stacks = TransformerEncoder(\n",
    "        num_heads=num_heads, key_dim=key_dim,\n",
    "        dropout=encoder_dropout,               # Hyperparameter\n",
    "        use_bias=use_bias,                     # usually False, but technically Hyperparameter\n",
    "        idx = \"stacks\",\n",
    "        activation=activation,\n",
    "        units = N_FEATURES,\n",
    "        use_PreLN=True\n",
    "    )\n",
    "attention_stacks = self_attention_layer_stacks(x)\n",
    "\n",
    "\n",
    "# After Attention, reduce to single dimension\n",
    "add_across_dim = Lambda(\n",
    "    lambda x: K.sum(x, axis=1)/PAD_SIZE**1,\n",
    "    output_shape=lambda s: (s[0], s[2]),\n",
    "    name = \"ReduceStackDimensionViaSummation\"\n",
    ")\n",
    "\n",
    "attention_solved = add_across_dim(attention_solved)\n",
    "attention_improvement = add_across_dim(attention_improvement)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reshape = Lambda(lambda x: tf.squeeze(x), name=\"Output\")\n",
    "\n",
    "# Pipe Attention directly into missing stack prediction:\n",
    "\n",
    "output_stacks = Dense(1, activation='sigmoid', name = \"PredictionStacks\")\n",
    "xx = output_stacks(attention_stacks)\n",
    "output_stacks = reshape(xx)\n",
    "\n",
    "\n",
    "\n",
    "# Standardize the Time Limit\n",
    "# - The time limit ranges from 0 to 30,\n",
    "# - (tl - 15)/5 should roughly normalize\n",
    "\n",
    "normalize_time_limit = Lambda(\n",
    "    lambda x: (x-15)/5,\n",
    "    #output_shape=lambda s: (s[0], s[2]),\n",
    "    name = \"NormalizeTimeLimit\"\n",
    ")\n",
    "input_time_limit = normalize_time_limit(input_time_limit)\n",
    "concatenate_layer_solved = Concatenate(axis=-1, name=f\"ConcatenateLayer\")\n",
    "#x = concatenate_layer_solved([x, input_time_limit])\n",
    "\n",
    "\n",
    "# Fully Connected Layer + Droput\n",
    "#for i, units in enumerate(fully_connected_units):\n",
    "#    \n",
    "#    full_connected_layer = Dense(units=units, activation=activation,name=f\"FullyConnectedLayer-{i+1}\")\n",
    "#    x = full_connected_layer(x)\n",
    "#\n",
    "#    dropout_layer = Dropout(fully_connected_dropout_rate,\n",
    "#                            name = f\"FullyConnectedDropoutLayer-{i+1}\")\n",
    "#    x = dropout_layer(x)\n",
    "\n",
    "\n",
    "x = concatenate_layer_solved([attention_solved, input_time_limit])\n",
    "fully_connected_layer_solved = Dense(units=N_FEATURES+1, activation=activation,name=f\"FullyConnectedLayerSolved\")\n",
    "xx = fully_connected_layer_solved(x)\n",
    "output_solved = Dense(1, activation='sigmoid', name = \"PredictionSolved\")\n",
    "xx = output_solved(xx)\n",
    "output_solved = reshape(xx)\n",
    "\n",
    "\n",
    "x = concatenate_layer_solved([attention_improvement, input_time_limit])\n",
    "fully_connected_layer_improvement = Dense(units=N_FEATURES+1, activation=activation,name=f\"FullyConnectedLayerImprovement\")\n",
    "xx = fully_connected_layer_improvement(x)\n",
    "output_improvement = Dense(1, activation='sigmoid', name = \"PredictionImprovement\")\n",
    "xx = output_improvement(xx)\n",
    "output_improvement = reshape(xx)\n",
    "\n",
    "\n",
    "outputs = [output_solved, output_improvement, output_stacks]\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=inputs,\n",
    "    #outputs=x,\n",
    "    outputs=outputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "004fc449-cbc8-494b-b6f1-da408c3f8068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
       " array([0.37035456, 0.38050157, 0.13236131, ..., 0.3532409 , 0.52524936,\n",
       "        0.23744483], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
       " array([0.91566974, 0.8821784 , 0.7501772 , ..., 0.86288136, 0.9679719 ,\n",
       "        0.862529  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1024, 80), dtype=float32, numpy=\n",
       " array([[0.7851473 , 0.7851473 , 0.8381007 , ..., 0.93139035, 0.93139035,\n",
       "         0.93139035],\n",
       "        [0.92145497, 0.92145497, 0.92145497, ..., 0.88871866, 0.88871866,\n",
       "         0.88871866],\n",
       "        [0.99071455, 0.9914259 , 0.9914259 , ..., 0.0127687 , 0.0127687 ,\n",
       "         0.0127687 ],\n",
       "        ...,\n",
       "        [0.9968965 , 0.9193263 , 0.91932964, ..., 0.8841413 , 0.8841413 ,\n",
       "         0.8841413 ],\n",
       "        [0.9868535 , 0.9868535 , 0.9868535 , ..., 0.9557026 , 0.9557026 ,\n",
       "         0.9557026 ],\n",
       "        [0.9984654 , 0.9984654 , 0.9984654 , ..., 0.998675  , 0.998675  ,\n",
       "         0.998675  ]], dtype=float32)>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1c0313b-3fe0-498b-925f-3547fcd860af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " StackLevelInputFeatures (I  [(None, 80, 9)]              0         []                            \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " MaskingLayer (Masking)      (None, 80, 9)                0         ['StackLevelInputFeatures[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " transformer_encoder (Trans  (None, 80, 9)                429       ['MaskingLayer[0][0]']        \n",
      " formerEncoder)                                                                                   \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Tra  (None, 80, 9)                429       ['transformer_encoder[0][0]'] \n",
      " nsformerEncoder)                                                                                 \n",
      "                                                                                                  \n",
      " transformer_encoder_2 (Tra  (None, 80, 9)                429       ['transformer_encoder_1[0][0]'\n",
      " nsformerEncoder)                                                   ]                             \n",
      "                                                                                                  \n",
      " transformer_encoder_3 (Tra  (None, 80, 9)                429       ['transformer_encoder_2[0][0]'\n",
      " nsformerEncoder)                                                   ]                             \n",
      "                                                                                                  \n",
      " transformer_encoder_4 (Tra  (None, 80, 9)                429       ['transformer_encoder_3[0][0]'\n",
      " nsformerEncoder)                                                   ]                             \n",
      "                                                                                                  \n",
      " transformer_encoder_5 (Tra  (None, 80, 9)                429       ['transformer_encoder_4[0][0]'\n",
      " nsformerEncoder)                                                   ]                             \n",
      "                                                                                                  \n",
      " transformer_encoder_6 (Tra  (None, 80, 9)                429       ['transformer_encoder_5[0][0]'\n",
      " nsformerEncoder)                                                   ]                             \n",
      "                                                                                                  \n",
      " transformer_encoder_7 (Tra  (None, 80, 9)                429       ['transformer_encoder_6[0][0]'\n",
      " nsformerEncoder)                                                   ]                             \n",
      "                                                                                                  \n",
      " TimeLimitInput (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " transformer_encoder_8 (Tra  (None, 80, 9)                429       ['transformer_encoder_6[0][0]'\n",
      " nsformerEncoder)                                                   ]                             \n",
      "                                                                                                  \n",
      " ReduceStackDimensionViaSum  (None, 9)                    0         ['transformer_encoder_7[0][0]'\n",
      " mation (Lambda)                                                    , 'transformer_encoder_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " NormalizeTimeLimit (Lambda  (None, 1)                    0         ['TimeLimitInput[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ConcatenateLayer (Concaten  (None, 10)                   0         ['ReduceStackDimensionViaSumma\n",
      " ate)                                                               tion[0][0]',                  \n",
      "                                                                     'NormalizeTimeLimit[0][0]',  \n",
      "                                                                     'ReduceStackDimensionViaSumma\n",
      "                                                                    tion[1][0]',                  \n",
      "                                                                     'NormalizeTimeLimit[0][0]']  \n",
      "                                                                                                  \n",
      " FullyConnectedLayerSolved   (None, 10)                   110       ['ConcatenateLayer[0][0]']    \n",
      " (Dense)                                                                                          \n",
      "                                                                                                  \n",
      " FullyConnectedLayerImprove  (None, 10)                   110       ['ConcatenateLayer[1][0]']    \n",
      " ment (Dense)                                                                                     \n",
      "                                                                                                  \n",
      " transformer_encoder_9 (Tra  (None, 80, 9)                429       ['transformer_encoder_6[0][0]'\n",
      " nsformerEncoder)                                                   ]                             \n",
      "                                                                                                  \n",
      " PredictionSolved (Dense)    (None, 1)                    11        ['FullyConnectedLayerSolved[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " PredictionImprovement (Den  (None, 1)                    11        ['FullyConnectedLayerImproveme\n",
      " se)                                                                nt[0][0]']                    \n",
      "                                                                                                  \n",
      " PredictionStacks (Dense)    (None, 80, 1)                10        ['transformer_encoder_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " Output (Lambda)             None                         0         ['PredictionStacks[0][0]',    \n",
      "                                                                     'PredictionSolved[0][0]',    \n",
      "                                                                     'PredictionImprovement[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4542 (17.74 KB)\n",
      "Trainable params: 4542 (17.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_ = model(cx) # just check if it works\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dfadaf-029c-49d3-81f3-664967ff38b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training Process Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1911b3da-221c-4414-9358-7fee5a42a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_decay(epoch: int, initial_lr:float=10e-3, lr_decay:float=0.9) -> float:\n",
    "    \"\"\"\n",
    "    Exponential decay learning rate schedule\n",
    "    \"\"\"\n",
    "    return initial_lr * lr_decay**lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf804408-85ea-4824-8a74-fb9feb1807f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, losses, all_metrics=None, training:bool=True):\n",
    "    \n",
    "    metrics = \"\\t\\t\\t\\t\\t\\t\\t\\t\\t\".join([f\"{TARGET_LABELS[i]:<12}\\tLoss: {losses[i].result():.4f}\" + \"\\t\".join([f\"{m.name:>10}: {m.result():.2%}\" for m in metrics])\n",
    "                                         for i, metrics in enumerate(all_metrics)])\n",
    "    \n",
    "    if training:\n",
    "        prefix=\"Training\"\n",
    "    else:\n",
    "        prefix=\"Validation\"\n",
    "    \n",
    "    print(f\"\\r{prefix}-Iteration: {iteration+1:0>3}/{total:<1000}\" + metrics,\n",
    "          end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71f44dd2-a301-4c37-919b-5a93fbe6c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def model_pass(inputs, targets, training):\n",
    "    \"\"\"\n",
    "    Usual Tensorflow model passing of inputs throught the network.\n",
    "    If in training mode, the optimizier can apply the gradients\n",
    "    observed with GradientTape to the model parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        outputs = model(inputs, training=training)\n",
    "        losses = [l(t, o) for l,o,t in zip(loss_objects, outputs, targets)]\n",
    "        \n",
    "        if training:\n",
    "            gradients = tape.gradient(losses, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        for i, mean_loss in enumerate(mean_losses):\n",
    "            mean_loss(losses[i])\n",
    "        \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "555d2a8e-ff78-42a9-871c-fabbc1da5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(dataset, all_metrics:list[list[tf.keras.metrics]], epoch:int, history:pd.DataFrame, training:bool=True):\n",
    "    \"\"\"\n",
    "    Single epoch, running several training steps over a dataset\n",
    "    \"\"\"\n",
    "\n",
    "    for step, (X_batch, y_batch) in enumerate(dataset):\n",
    "        \n",
    "        X_batch, y_batch = polars_transformation(X_batch, y_batch)\n",
    "        \n",
    "        outputs = model_pass(X_batch, y_batch, training=training)\n",
    "        #mean_loss(loss)\n",
    "        \n",
    "        for i, metrics in enumerate(all_metrics):\n",
    "            for metric in metrics:\n",
    "                metric(y_batch[i].reshape(-1), outputs[i].numpy().reshape(-1))\n",
    "    \n",
    "        print_status_bar(step, len(dataset), mean_losses, all_metrics, training=training)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    for i, metrics in enumerate(all_metrics):\n",
    "        for metric in metrics:\n",
    "            data = pd.DataFrame({\n",
    "                \"Epoch\": [epoch],\n",
    "                \"Target\": [TARGET_LABELS[i]],\n",
    "                \"Metric\": [metric.name if training else f\"Val-\"+metric.name],\n",
    "                \"Value\": [float(metric.result())],\n",
    "            })\n",
    "            history = pd.concat([history, data])\n",
    "            metric.reset_states()\n",
    "\n",
    "    for i, mean_loss in enumerate(mean_losses):\n",
    "        data = pd.DataFrame({\n",
    "            \"Epoch\": [epoch],\n",
    "            \"Target\": [TARGET_LABELS[i]],\n",
    "            \"Metric\": [\"Loss\" if training else f\"Val-\"+\"Loss\"],\n",
    "            \"Value\": [float(mean_loss.result())],\n",
    "        })\n",
    "        history = pd.concat([history, data])\n",
    "        mean_loss.reset_states()\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ef915-1e01-42dd-b423-71593e828fcf",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8175650-b296-4222-b028-ecb715c458c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clms = [\"Epoch\", \"Target\", \"Metric\", \"Value\"]\n",
    "track = pd.DataFrame(columns = clms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464563b0-8ebe-4448-9105-a25ed5e36383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 13:49:15.516823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-Iteration: 198/198                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Solved      \tLoss: 0.0688       PRC: 72.25%\t       SNS: 55.07%\t       AUC: 75.03%\t       ACC: 74.18%\t\t\t\t\t\t\t\t\tImprovement \tLoss: 0.1738       PRC: 61.93%\t       SNS: 57.19%\t       AUC: 61.74%\t       ACC: 63.11%\t\t\t\t\t\t\t\t\tStacks      \tLoss: 0.0383       PRC: 15.80%\t       SNS: 22.51%\t       AUC: 9.93%\t       ACC: 96.86%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j4/qmf6qmvd1gv0nctgx3m6jm3r0000gn/T/ipykernel_41786/4137319759.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  history = pd.concat([history, data])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation-Iteration: 050/50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Solved      \tLoss: 0.0570       PRC: 83.04%\t       SNS: 60.69%\t       AUC: 83.86%\t       ACC: 79.74%\t\t\t\t\t\t\t\t\tImprovement \tLoss: 0.1498       PRC: 67.76%\t       SNS: 62.05%\t       AUC: 72.36%\t       ACC: 68.08%\t\t\t\t\t\t\t\t\tStacks      \tLoss: 0.0015       PRC: 43.83%\t       SNS: 24.38%\t       AUC: 25.51%\t       ACC: 98.30%\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 002/100\n",
      "Training-Iteration: 198/198                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Solved      \tLoss: 0.0549       PRC: 81.86%\t       SNS: 64.58%\t       AUC: 84.88%\t       ACC: 80.57%\t\t\t\t\t\t\t\t\tImprovement \tLoss: 0.1411       PRC: 71.27%\t       SNS: 66.61%\t       AUC: 77.31%\t       ACC: 71.50%\t\t\t\t\t\t\t\t\tStacks      \tLoss: 0.0013       PRC: 48.75%\t       SNS: 36.64%\t       AUC: 34.28%\t       ACC: 98.38%\n",
      "\n",
      "Validation-Iteration: 050/50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Solved      \tLoss: 0.0535       PRC: 81.05%\t       SNS: 68.93%\t       AUC: 86.07%\t       ACC: 81.51%\t\t\t\t\t\t\t\t\tImprovement \tLoss: 0.1318       PRC: 77.41%\t       SNS: 64.70%\t       AUC: 81.10%\t       ACC: 74.36%\t\t\t\t\t\t\t\t\tStacks      \tLoss: 0.0012       PRC: 40.50%\t       SNS: 41.53%\t       AUC: 33.56%\t       ACC: 98.10%\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 003/100\n",
      "Training-Iteration: 198/198                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Solved      \tLoss: 0.0523       PRC: 83.43%\t       SNS: 66.52%\t       AUC: 86.32%\t       ACC: 81.76%\t\t\t\t\t\t\t\t\tImprovement \tLoss: 0.1267       PRC: 76.07%\t       SNS: 71.08%\t       AUC: 83.06%\t       ACC: 75.74%\t\t\t\t\t\t\t\t\tStacks      \tLoss: 0.0012       PRC: 48.77%\t       SNS: 34.93%\t       AUC: 34.30%\t       ACC: 98.38%\n",
      "\n",
      "Validation-Iteration: 050/50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Solved      \tLoss: 0.0513       PRC: 86.33%\t       SNS: 65.37%\t       AUC: 87.00%\t       ACC: 82.38%\t\t\t\t\t\t\t\t\tImprovement \tLoss: 0.1187       PRC: 76.25%\t       SNS: 75.76%\t       AUC: 85.67%\t       ACC: 77.36%\t\t\t\t\t\t\t\t\tStacks      \tLoss: 0.0012       PRC: 51.25%\t       SNS: 26.56%\t       AUC: 34.68%\t       ACC: 98.43%\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 004/100\n",
      "Training-Iteration: 198/198                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Solved      \tLoss: 0.0507       PRC: 84.18%\t       SNS: 68.18%\t       AUC: 87.27%\t       ACC: 82.56%\t\t\t\t\t\t\t\t\tImprovement \tLoss: 0.1193       PRC: 77.40%\t       SNS: 74.12%\t       AUC: 85.20%\t       ACC: 77.51%\t\t\t\t\t\t\t\t\tStacks      \tLoss: 0.0011       PRC: 49.99%\t       SNS: 33.98%\t       AUC: 36.81%\t       ACC: 98.41%\n",
      "\n",
      "Validation-Iteration: 050/50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Solved      \tLoss: 0.0497       PRC: 88.70%\t       SNS: 64.43%\t       AUC: 88.01%\t       ACC: 82.85%\t\t\t\t\t\t\t\t\tImprovement \tLoss: 0.1131       PRC: 81.08%\t       SNS: 73.14%\t       AUC: 87.15%\t       ACC: 79.21%\t\t\t\t\t\t\t\t\tStacks      \tLoss: 0.0011       PRC: 55.35%\t       SNS: 30.31%\t       AUC: 40.31%\t       ACC: 98.50%\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 005/100\n",
      "Training-Iteration: 177/198                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Solved      \tLoss: 0.0486       PRC: 85.12%\t       SNS: 70.32%\t       AUC: 88.47%\t       ACC: 83.60%\t\t\t\t\t\t\t\t\tImprovement \tLoss: 0.1135       PRC: 78.69%\t       SNS: 75.91%\t       AUC: 86.82%\t       ACC: 78.90%\t\t\t\t\t\t\t\t\tStacks      \tLoss: 0.0010       PRC: 55.50%\t       SNS: 33.14%\t       AUC: 41.74%\t       ACC: 98.51%"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "#for epoch in range(11, 16):\n",
    "    \n",
    "    print(f\"Epoch {epoch:0>3}/{ n_epochs:0>3}\")\n",
    "\n",
    "    track = run_epoch(train_dataset, all_metrics, epoch=epoch, history=track, training=True)\n",
    "    track = run_epoch(val_dataset, all_metrics, epoch=epoch, history=track, training=False)\n",
    "\n",
    "    print(\"-\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c961887-1831-43e7-98a7-51b71bf3bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = track.pivot_table(values = [\"Value\"], columns=[\"Metric\"], index=[\"Epoch\", \"Target\"]).reset_index().set_index(\"Epoch\", drop=True)\n",
    "clms = history.columns\n",
    "history.columns = [clm[i>=1] for i, clm in enumerate(clms)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb1501-21f7-4ef2-96a7-af4205bf0d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "clms = history.columns\n",
    "\n",
    "fig, ax = plt.subplots(len(TARGET_LABELS), 2, figsize=(16, 9*len(TARGET_LABELS)))\n",
    "\n",
    "colors = [\"cyan\", \"orange\", \"forestgreen\", \"purple\"]\n",
    "\n",
    "for i, target in enumerate(TARGET_LABELS):\n",
    "    history.loc[(history.Target == target), (~clms.str.contains(\"Val-\"))&(~clms.str.contains(\"Loss\"))]\\\n",
    "        .plot(ax=ax[i, 0], ls = \"--\", color = colors, label = \"Training\")\n",
    "    history.loc[(history.Target == target), (clms.str.contains(\"Val-\"))&(~clms.str.contains(\"Loss\"))]\\\n",
    "        .plot(ax=ax[i, 0], lw = 3, color = colors, label = \"Validation\")\n",
    "    ax[i, 0].set(ylabel = target)\n",
    "\n",
    "    # Plot the loss\n",
    "    history.loc[(history.Target == target), (~clms.str.contains(\"Val-\"))&(clms.str.contains(\"Loss\"))]\\\n",
    "        .plot(ax=ax[i, 1], ls = \"--\", color = \"red\", label = \"Training\")\n",
    "    history.loc[(history.Target == target), (clms.str.contains(\"Val-\"))&(clms.str.contains(\"Loss\"))]\\\n",
    "        .plot(ax=ax[i, 1], lw = 3, color = \"red\", label = \"Validation\")\n",
    "    ax[i, 1].set(yscale = \"log\")\n",
    "\n",
    "ax[0, 0].set(title=\"Metrics\")\n",
    "ax[0, 1].set(title=\"Loss\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb1d76-f599-4e84-97b5-2c0c76f86adf",
   "metadata": {},
   "source": [
    "Tradeoff between Sensitivity and Precision can be seen very good here.\n",
    "Most likely explanation:\n",
    "- the bias of the final layer before the sigmoid has changed drastically.\n",
    "- if the bias increases, predicted probabilities increase. This means more found solved cases and higher Sensitivity\n",
    "- if the bias decreases, predicted probabilities decrease. This means less found solved cases, only the more certain cases. Higher Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faec77f-ae28-426c-9a59-867235bddd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    #to_file,\n",
    "    show_shapes=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
