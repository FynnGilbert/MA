{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51595832-52a2-4469-8aee-61428a86c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "\n",
    "PAD_SIZE = 80\n",
    "TARGET_LABELS = [\n",
    "    \"Improvement\",\n",
    "    \"Solved\",\n",
    "    #\"AreaRatio\",\n",
    "    #\"Stacks\"\n",
    "]\n",
    "\n",
    "SEED = 3093453"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6016c6-543d-4ede-b6dd-2a4870f324d6",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d07e7-6859-4737-9c4b-91eba870632b",
   "metadata": {},
   "source": [
    "## Load Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cdfc5c-074f-4f7f-9f9d-39d47b43a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Random Seeds\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "# Cosmetics\n",
    "np.set_printoptions(\n",
    "    edgeitems=30,\n",
    "    linewidth=100_000,\n",
    "    suppress=True\n",
    "    )\n",
    "\n",
    "sns.set(\n",
    "    context=\"talk\",\n",
    "    style=\"darkgrid\"\n",
    ")\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd, _ = os.path.split(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6f3329-37c6-4683-ad68-5725ed932f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 489623 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 09:47:24.591914: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-02-18 09:47:24.591950: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-02-18 09:47:24.591953: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-02-18 09:47:24.591991: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-18 09:47:24.592020: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 116586 files belonging to 1 classes.\n",
      "Found 104591 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "train_samples = os.path.join(cwd, \"data\", \"train\") # 116586 + 489623 = 606209\n",
    "val_samples = os.path.join(cwd, \"data\", \"validation\")\n",
    "test_samples = os.path.join(cwd, \"data\", \"test\")\n",
    "\n",
    "train_dataset = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory = train_samples,\n",
    "    labels = None,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    max_length = None,\n",
    "    shuffle = True,\n",
    "    seed = SEED,\n",
    ")\n",
    "\n",
    "val_dataset = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory = val_samples,\n",
    "    labels = None,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    max_length = None,\n",
    "    shuffle = True,\n",
    "    seed = SEED,\n",
    ")\n",
    "\n",
    "test_dataset = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory = test_samples,\n",
    "    labels = None,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    max_length = None,\n",
    "    shuffle = True,\n",
    "    seed = SEED,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "826af314-8afd-42b4-8f8a-ee856de2cbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"dataset: B\\ninstance: MA2\\n+-----------+\\n2D Packing MIP with Time Limit 15 [s] in Truck P355037001\\nStack 0 with items: ['0090016200_26102022000265', '0090016200_26102022000255']\\nStack 1 with items: ['0090016200_26102022012372', '0090016200_26102022012372', '0090016200_26102022017816']\\nStack 2 with items: ['0090016200_26102022006635', '0090016200_26102022002470', '0090016200_26102022013378']\\nStack 3 with items: ['0090016200_26102022015271', '0090016200_26102022007589', '0090016200_26102022015271']\\nStack 4 with items: ['0090016200_26102022001327', '0090016200_26102022001327']\\nStack 5 with items: ['0090016200_26102022015678', '0090016200_26102022004493', '0090016200_26102022015678']\\nStack 6 with items: ['0090016200_26102022019753', '0090016200_26102022019604', '0090016200_26102022019753']\\nStack 7 with items: ['0090016200_26102022016002', '0090016200_26102022016002', '0090016200_26102022016002']\\nStack 8 with items: ['0090016200_26102022012624', '0090016200_26102022012624', '0090016200_26102022012624']\\nStack 9 with items: ['0090016200_26102022012349', '0090016200_26102022005486', '0090016200_26102022012349']\\nStack 10 with items: ['0090016200_26102022005397', '0090016200_26102022004907', '0090016200_26102022004907']\\nStack 11 with items: ['0090016200_26102022004907', '0090016200_26102022004907', '0090016200_26102022004907']\\nStack 12 with items: ['0090016200_26102022002956', '0090016200_26102022002956']\\nStack 13 with items: ['0090016200_26102022019225', '0090016200_26102022018164']\\nStack 14 with items: ['0090016200_26102022005238', '0090016200_26102022013531']\\nStack 15 with items: ['0090016200_26102022010499']\\nStack 16 with items: ['0090016200_26102022005330', '0090016200_26102022014316']\\nStack 17 with items: ['0090016200_26102022009118', '0090016200_26102022009118']\\nStack 18 with items: ['0090016200_26102022016498', '0090016200_26102022016498']\\nStack 19 with items: ['0090016200_26102022009118', '0090016200_26102022016971']\\nMIP Improvement - 2D Vol: 29.59025 [m2] - packed 2D Vol Ratio: 0.8983075288403158 [%] - after 0.0 [s] without stacks:\\nStack 18 missing: ['0090016200_26102022016498', '0090016200_26102022016498']\\nStack 19 missing: ['0090016200_26102022009118', '0090016200_26102022016971']\\nSolve interrupted after 15.004909181967378 [s]\\nStacks not packed:\\nStack 18 not in final solution with items: ['0090016200_26102022016498', '0090016200_26102022016498']\\nStack 19 not in final solution with items: ['0090016200_26102022009118', '0090016200_26102022016971']\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for X in train_dataset:\n",
    "    print(X[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f41606-8269-494a-ad53-37f171c58f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1024,), dtype=float32, numpy=array([0.1016925 , 0.05063021, 0.09620732, 0.13915849, 0.07468122, 0.08084244, 0.10040158, 0.1904068 , 0.10051888, 0.19854283, 0.05282331, 0.30105102, 0.13895583, 0.05172676, 0.32969034, 0.06921673, 0.0953989 , 0.07358468, 0.14644444, 0.18393576, 0.04237008, 0.27540982, 0.09653914, 0.10091072, 0.11468732, 0.1838488 , 0.2464481 , 0.0770328 , 0.08755022, 0.11839706, ..., 0.06739527, 0.05154616, 0.10746813, 0.14574862, 0.16861719, 0.06739527, 0.04553735, 0.06739527, 0.08925319, 0.1604681 , 0.05282331, 0.07103825, 0.1340437 , 0.3114754 , 0.05379111, 0.05282331, 0.05282331, 0.0627116 , 0.16854733, 0.16787148, 0.10510015, 0.10040158, 0.06739527, 0.16612023, 0.12908137, 0.05153793, 0.10432971, 0.10509837, 0.05282331, 0.09029752], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unpacked_area(X):\n",
    "    y = tf.strings.split(X, \"MIP Improvement\")\n",
    "    y = tf.map_fn(len, y, dtype=tf.int32)\n",
    "    y = y > 2 # more than one MIP improvement. also split adds one item, therefore larger 2\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    #X = tf.strings.split(X, \"MIP Improvement - 2D Vol: \")[:,1:2]\n",
    "    X = tf.strings.split(X, \"- packed 2D Vol Ratio: \")[:,1:2]\n",
    "    #X = tf.strings.split(X, \"- after 0.0 [s] without stacks:\")[:,0:1]\n",
    "    X = tf.strings.split(X, \" \")[:,:,:1]\n",
    "    X = tf.squeeze(X, axis=(1,2))\n",
    "    X = tf.strings.to_number(X, out_type=tf.float32)\n",
    "    X = 1-X\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "#y = get_intial_area(X)\n",
    "#y\n",
    "XX, y = get_unpacked_area(X)\n",
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdb6c83-6e4d-49b3-9a41-5741133ec819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/fynn/Uni/MA/.venv/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(get_unpacked_area)#.take(1).get_single_element()\n",
    "val_dataset = val_dataset.map(get_unpacked_area)\n",
    "test_dataset = test_dataset.map(get_unpacked_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bff52-d516-4e59-adc3-dc6879865197",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5cff80-cd9a-496a-9817-e5448043380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0 (0.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Model, layers\n",
    "\n",
    "# Build a shallow model that just parrots the input of the extracted 2D Volume\n",
    "## I am still not over the fact that you call the area the 2D Volume...\n",
    "\n",
    "input_layer = layers.Input(shape=(1))\n",
    "model = Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=input_layer\n",
    ")\n",
    "model.summary()\n",
    "#model.predict(mapped_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed1db0e-dd15-4357-9766-09af3a762d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics= [\n",
    "        tf.keras.metrics.SpecificityAtSensitivity(0.6565), #sns for training set\n",
    "        tf.keras.metrics.Precision(name = \"PRC\", thresholds=.1),\n",
    "        tf.keras.metrics.Recall(name = \"SNS\", thresholds=.1),\n",
    "        tf.keras.metrics.AUC(curve='PR', name=\"AUC\"),\n",
    "        #tf.keras.metrics.F1Score(average=\"weighted\", name=\"F1\", ),\n",
    "        tf.keras.metrics.BinaryAccuracy(name = \"ACC\", threshold=.1)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff129d5-7ffa-4a0e-876c-a62314181f84",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d875d698-f042-4ba7-877b-0fee1dfa3b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 09:47:34.142586: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - 20s 42ms/step - loss: 1.0502 - specificity_at_sensitivity: 0.6283 - PRC: 0.6287 - SNS: 0.6565 - AUC: 0.6109 - ACC: 0.6532\n",
      "114/114 [==============================] - 4s 28ms/step - loss: 1.0095 - specificity_at_sensitivity: 0.6094 - PRC: 0.5974 - SNS: 0.6565 - AUC: 0.6281 - ACC: 0.6400\n",
      "103/103 [==============================] - 3s 27ms/step - loss: 1.0217 - specificity_at_sensitivity: 0.5973 - PRC: 0.6047 - SNS: 0.6258 - AUC: 0.6422 - ACC: 0.6434\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    test_dataset\n",
    "]:\n",
    "    model.fit(dataset);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5801e778-ef42-4f06-9445-acc1e960cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6423\n",
      "0.6256\n",
      "0.6151\n"
     ]
    }
   ],
   "source": [
    "def F1_score(sns, prc):\n",
    "    return 2*(sns*prc) / (sns+prc)\n",
    "\n",
    "for pair in [\n",
    "    (0.6287, 0.6565),\n",
    "    (0.5974, 0.6565),\n",
    "    (0.6047, 0.6258)\n",
    "]:\n",
    "    print(round(F1_score(*pair), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c14c50e5-fb3a-4252-acf0-68ebdc225597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2* 0.3221 * 0.3742 /(0.3221 +0.3742)\n",
    "# = 0.3462008329742927\n",
    "\n",
    "# Ignore Keras F1 score, as scores do not comply with the F1 formula\n",
    "# no matter which of the average are choosen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
